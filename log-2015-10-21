Script started on Wed Oct 21 10:54:56 2015
bash: /path/to/your/virtualenvwrapper.sh: No such file or directory
[?1034hbash-3.2$ vi word2
word2phrase    word2phrase.c  word2vec       word2vec.c     
bash-3.2$ vi word2vec.c
[?1049h[?1h=[1;25r[?12;25h[?12l[?25h[27m[m[H[2J[?25l[25;1H"word2vec.c" 703L, 30219C[>c[1;1H//  Copyright 2013 Google Inc. All Rights Reserved.
//
//  Licensed under the Apache License, Version 2.0 (the "License");
//  you may not use this file except in compliance with the License.
//  You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
//  Unless required by applicable law or agreed to in writing, software
//  distributed under the License is distributed on an "AS IS" BASIS,
//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//  See the License for the specific language governing permissions and
//  limitations under the License.

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <pthread.h>

#define MAX_STRING 100 /* 最大文字数は100字まで */
#define EXP_TABLE_SIZE 1000
#define MAX_EXP 6
#define MAX_SENTENCE_LENGTH 1000[1;1H[?12l[?25h[?25l[25;1H[K[25;1H:[?12l[?25hset number[?25l[1;1H[93m  1 [m//  Copyright 2013 Google Inc. All Rights Reserved.
[93m  2 [m//
[93m  3 [m//  Licensed under the Apache License, Version 2.0 (the "License");
[93m  4 [m//  you may not use this file except in compliance with the License.
[93m  5 [m//  You may obtain a copy of the License at
[93m  6 [m//
[93m  7 [m//      http://www.apache.org/licenses/LICENSE-2.0
[93m  8 [m//
[93m  9 [m//  Unless required by applicable law or agreed to in writing, software
[93m 10 [m//  distributed under the License is distributed on an "AS IS" BASIS,
[93m 11 [m//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.[12;1H[93m 12 [m//  See the License for the specific language governing permissions and
[93m 13 [m//  limitations under the License.
[93m 14 
 15 [m#include <stdio.h>
[93m 16 [m#include <stdlib.h>
[93m 17 [m#include <string.h>
[93m 18 [m#include <math.h>
[93m 19 [m#include <pthread.h>
[93m 20 
 21 [m#define MAX_STRING 100 /* 最大文字数は100字まで */
[93m 22 [m#define EXP_TABLE_SIZE 1000
[93m 23 [m#define MAX_EXP 6
[93m 24 [m#define MAX_SENTENCE_LENGTH 1000[1;5H[?12l[?25h[?25l[25;1H[K[25;1H:[?12l[?25h200[?25l[27m[m[H[2J[1;1H[93m191 [m  }
[93m192 [m  fflush(stdout);
[93m193 [m  min_reduce++;
[93m194 [m}
[93m195 
196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffmaa[7;1H[93m    [mn木を作成 */
[93m197 [m// Frequent words will have short uniqe binary codes /* 高頻度の単語に短い一[9;1H[93m    [m意的な2進数を割当る */
[93m198 [mvoid CreateBinaryTree() { /* void関数CreateBinaryTree() */
[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];
[93m200 [m  char code[MAX_CODE_LENGTH]; /* char型code[最大コード長MAX_CODE_LENGTH] */
[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long lonn[14;1H[93m    [mg)); /* long long型ポインタcount =  */
[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long loo[16;1H[93m    [mng));
[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[18;1H[93m    [mng long));
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn;
[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15;
[93m206 [m  pos1 = vocab_size - 1;
[93m207 [m  pos2 = vocab_size;
[93m208 [m  // Following algorithm constructs the Huffman tree by adding one node at aa[24;1H[93m    [m time /* Huffman木 */[12;7H[?12l[?25h[13;7H[15;7H[17;7H[19;7H[?25l[56C for (a = vocab_sii[20;1H[93m    [mze; a < vocab_size * 2; a++) count[a] = 1e15;[20;50H[K[21;2H[93m05
206
207[m[76Caa[24;1H[93m [19;63H[?12l[?25h[?25l[m[25;1H:! man 'for'[?1l>[?12l[?25h[?1049l
[No write since last change]
[?1049h[?1h=
BUILTIN(1)                BSD General Commands Manual               BUILTIN(1)

[1mNAME[0m
     [1mbuiltin[0m, [1m![0m, [1m%[0m, [1m.[0m, [1m:[0m, [1m@[0m, [1m{[0m, [1m}[0m, [1malias[0m, [1malloc[0m, [1mbg[0m, [1mbind[0m, [1mbindkey[0m, [1mbreak[0m,
     [1mbreaksw[0m, [1mbuiltins[0m, [1mcase[0m, [1mcd[0m, [1mchdir[0m, [1mcommand[0m, [1mcomplete[0m, [1mcontinue[0m, [1mdefault[0m,
     [1mdirs[0m, [1mdo[0m, [1mdone[0m, [1mecho[0m, [1mechotc[0m, [1melif[0m, [1melse[0m, [1mend[0m, [1mendif[0m, [1mendsw[0m, [1mesac[0m, [1meval[0m,
     [1mexec[0m, [1mexit[0m, [1mexport[0m, [1mfalse[0m, [1mfc[0m, [1mfg[0m, [1mfiletest[0m, [1mfi[0m, [1mfor[0m, [1mforeach[0m, [1mgetopts[0m,
     [1mglob[0m, [1mgoto[0m, [1mhash[0m, [1mhashstat[0m, [1mhistory[0m, [1mhup[0m, [1mif[0m, [1mjobid[0m, [1mjobs[0m, [1mkill[0m, [1mlimit[0m,
     [1mlocal[0m, [1mlog[0m, [1mlogin[0m, [1mlogout[0m, [1mls-F[0m, [1mnice[0m, [1mnohup[0m, [1mnotify[0m, [1monintr[0m, [1mpopd[0m,
     [1mprintenv[0m, [1mpushd[0m, [1mpwd[0m, [1mread[0m, [1mreadonly[0m, [1mrehash[0m, [1mrepeat[0m, [1mreturn[0m, [1msched[0m, [1mset[0m,
     [1msetenv[0m, [1msettc[0m, [1msetty[0m, [1msetvar[0m, [1mshift[0m, [1msource[0m, [1mstop[0m, [1msuspend[0m, [1mswitch[0m,
     [1mtelltc[0m, [1mtest[0m, [1mthen[0m, [1mtime[0m, [1mtimes[0m, [1mtrap[0m, [1mtrue[0m, [1mtype[0m, [1mulimit[0m, [1mumask[0m,
     [1munalias[0m, [1muncomplete[0m, [1munhash[0m, [1munlimit[0m, [1munset[0m, [1munsetenv[0m, [1muntil[0m, [1mwait[0m,
     [1mwhere[0m, [1mwhich[0m, [1mwhile[0m -- shell built-in commands

[1mSYNOPSIS[0m
     [1mbuiltin[0m [[1m-options[0m] [[4margs[24m [4m...[24m]

[1mDESCRIPTION[0m
     Shell builtin commands are commands that can be executed within the run-
     ning shell's process.  Note that, in the case of csh(1) builtin commands,
     the command is executed in a subshell if it occurs as any component of a
     pipeline except the last.
:[K[K:[K[K:[K[K
:[K[K[HM
[25;1H[K:[K[K[HM[1m~[0m
[25;1H[K:[K[K[HM[1m~[0m
[25;1H[K:[K[K[HM[1m~[0m
[25;1H[K:[K[K[HM[1m~[0m
[25;1H[K:[K[K[HM[1m~[0m
[25;1H[K:[K[K[HM[1m~[0m
[25;1H[K:[K[K[HM[1m~[0m
[25;1H[K:[K[K[HM[1m~[0m
[25;1H[K:[K[K[?1l>[?1049l
Press ENTER or type command to continue[?1049h[?1h=[27m[m[H[2J[?25l[1;1H[93m191 [m  }
[93m192 [m  fflush(stdout);
[93m193 [m  min_reduce++;
[93m194 [m}
[93m195 
196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffmaa[7;1H[93m    [mn木を作成 */
[93m197 [m// Frequent words will have short uniqe binary codes /* 高頻度の単語に短い一[9;1H[93m    [m意的な2進数を割当る */
[93m198 [mvoid CreateBinaryTree() { /* void関数CreateBinaryTree() */
[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];
[93m200 [m  char code[MAX_CODE_LENGTH]; /* char型code[最大コード長MAX_CODE_LENGTH] */
[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long lonn[14;1H[93m    [mg)); /* long long型ポインタcount =  */
[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long loo[16;1H[93m    [mng));
[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[18;1H[93m    [mng long));
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn; for (a = vocab_sii[20;1H[93m    [mze; a < vocab_size * 2; a++) count[a] = 1e15;
[93m205 [m  pos1 = vocab_size - 1;
[93m206 [m  pos2 = vocab_size;
[93m207 [m  // Following algorithm constructs the Huffman tree by adding one node at aa[24;1H[93m    [m time /* Huffman木 */[19;63H[?12l[?25h[?25l[17Cii[20;1H[93m [m[48C pos1 = vocab_size - 1;[21;9Hs2[12Ce;[21;25H[K[22;6H // Following algorithm constructs the Huffman tree by adding one node at aa[23;1H[93m   [m[1C time /* Huffman木 */[23;26H[K[24;1H[93m207[m[1C  for (a = 0; a < vocab_size - 1; a++) {[20;50H[?12l[?25h[?25l[23C pos2 =  [21;1H[93m    [mvocab_size;[21;16H[K[22;2H[93m05[m[76Caa[23;1H[93m 
206[20;73H[?12l[?25h[?25l[m[7C  [21;1H[93m [m[14C // Following algorithm constructs the Huffman tree by adding onee[22;1H[93m   [m[1C node at a time /* Huffman木 */[22;36H[K[23;1H[93m205[m[1C  for (a = 0; a < vocab_size - 1; a++) {[24;6H   // First, find two smallest nodes 'min1, min2'[21;16H[?12l[?25h[?25l[64Cee[22;1H[93m [m[34C for (a = 0; a < vocab_size - 1; a++) {[23;6H   // First, find two smallest nodes 'min1, min2'[24;8H if (pos1 >= 0) {[24;25H[K[22;36H[?12l[?25h[?25l[39C // Fii[23;1H[93m    [mrst, find two smallest nodes 'min1, min2'[23;46H[K[24;2H[93m05[22;75H[?12l[?25h[?25l[m // Fii[23;1H[93m [m[44C if (pos1 >= 0) {[24;8H   if (count[pos1] < count[pos2]) {[23;46H[?12l[?25h[?25l

1 more line; before #7  2 seconds ago[23;47H[K[24;8H if (pos1 >= 0) {[24;25H[K[22;75H[?12l[?25h[?25l[25;22H6  4[22;76H[K[23;1H[93m205 [m    // First, find two smallest nodes 'min1, min2'[24;2H[93m06[22;36H[?12l[?25h[?25l[m[25;22H5  7[22;37H[K[23;6H for (a = 0; a < vocab_size - 1; a++) {[23;45H[K[24;8H // First, find two smallest nodes 'min1, min2'[21;16H[?12l[?25h[?25l[25;22H4  8[21;17H[K[22;1H[93m205[m[1C  // Following algorithm constructs the Huffman tree by adding one node at aa[23;1H[93m   [m[1C time /* Huffman木 */[23;26H[K[24;6H for (a = 0; a < vocab_size - 1; a++) {[24;45H[K[20;73H[?12l[?25h[?25l[25;22H3  10 seconds ago[20;74H[K[21;1H[93m205 [m  pos2 = vocab_size;[22;2H[93m06[m[76Caa[23;1H[93m 
207[20;50H[?12l[?25h[?25l[m[25;22H2  11[20;51H[K[21;9Hs1[12Ce - 1;[22;6H pos2 = vocab_size;[22;25H[K[23;1H[93m207[m[1C  // Following algorithm constructs the Huffman tree by adding one node at aa[24;1H[93m   [m[1C time /* Huffman木 */[24;26H[K[19;63H[?12l[?25h[?25l[25;22H1  26[19;64H[K[20;1H[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15;[21;2H[93m06
207
208[m[76Caa[24;1H[93m [19;7H[?12l[?25h[?25l[m[25;1HAlready at oldest change[25;25H[K[19;7H[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[20;7H[21;7H[22;7H[23;7H[?25l[1;24r[24;1H
[1;25r[24;1H[93m209 [m  for (a = 0; a < vocab_size - 1; a++) {[25;1H[K[24;7H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m210 [m    // First, find two smallest nodes 'min1, min2'[24;7H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m211 [m    if (pos1 >= 0) {[24;7H[?12l[?25h[23;7H[22;7H[20;7H[19;7H[18;7H[17;7H[16;7H[14;7H[12;7H[10;7H[9;7H[8;7H[7;7H[8;7H[9;7H[10;7H[12;7H[14;7H[16;7H[14;7H[12;7H[10;7H[9;7H[8;7Hlong long a, b, i, [9;26H[?25l[10;26H[46m([11C)[m[41Cnn[11;1H[93m [10;26H[?12l[?25h[?25l[m([11C)[41Cnn[11;1H[93m [10;27H[?12l[?25h[mlong lon[12;35H[14;35H[12;35H[14;35H[12;35Hng [?25l[12;27H[46m([11C)[m[40Coo[13;1H[93m [12;39H[?12l[?25h[?25l[m[12;27H([11C)[40Coo[13;1H[93m [12;40H[?12l[?25h[mcallo[?25lc[46m([m[33Coo[13;1H[93m [m[6C[46m)[12;46H[?12l[?25h[?25l[m([33Coo[13;1H[93m [m[6C)[12;47H[?12l[?25hvocab_size * 2 + 1, sizeo[14;72H[16;62H[17;68H[18;28H[19;24H[20;72H[22;44H[23;54H[24;24H[?25l[1;24r[24;1H
[1;25r[24;1H[93m212 [m      if (count[pos1] < count[pos2]) {[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m213 [m[7C min1i = pos1;[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m214 [m[7C pos1--;
[93m215 [m      } else {[23;19H[?12l[?25h[24;18H[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m216 [m[7C min1i = pos2;
[93m217 [m[7C pos2++;[23;25H[?12l[?25h[24;19H[?25l[1;24r[24;1H
[1;25r[21;18H[46m{[m


[93m218 [m      [46m}[?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[20;18H{[23;11H}
[93m219 [m    } else {[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m220 [m      min1i = pos2;[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m221 [m      pos2++;
[93m222 [m    }[23;17H[?12l[?25h[?25l[21;16H[46m{[24;9H}[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[19;16H{[22;9H}
[93m223 [m    if (pos1 >= 0) {
[93m224 [m      if (count[pos1] < count[pos2]) {[23;24H[?12l[?25h[24;42H[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m225 [m[7C min2i = pos1;
[93m226 [m[7C pos1--;[23;25H[?12l[?25h[24;19H[?25l[1;24r[24;1H
[1;25r[24;1H[93m227 [m      } else {[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m228 [m[7C min2i = pos2;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m229 [m[7C pos2++;[?12l[?25h[23;25H[22;18H[21;19H[20;25H[?25l[19;42H[46m{[22;11H}[19;42H[?12l[?25h[?25l[m{[22;11H}[18;24H[?12l[?25h[?25l[14;16H[46m{[17;9H}[?12l[?25h[?25l[m[14;16H{[17;9H}[16;17H[?12l[?25h[15;23H[?25l[14;16H[46m{[17;9H}[14;16H[?12l[?25h[?25l[10;18H{[13;11H}[m[14;16H{[17;9H}[13;11H[?12l[?25h[?25l[10;18H{[13;11H}[12;19H[?12l[?25h[11;25H[?25l[10;18H[46m{[13;11H}[10;18H[?12l[?25h[?25l[m{[13;11H}[9;19H[?12l[?25h[8;25H[?25l[7;42H[46m{[10;11H}[7;42H[?12l[?25h[?25l[6;24H{[m[7;42H{[10;11H}[14;9H[46m}[6;24H[?12l[?25h[?25l[m{[14;9H}[5;54H[?12l[?25h[4;44H[2;72H[1;24H[?25l[1;24r[1;1H[L[1;25r[1;1H[93m206 [m  pos1 = vocab_size - 1;[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15;[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn;[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[2;1H[93m    [mng long));[1;72H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long loo[2;1H[93m    [mng));[1;72H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof[46m([mlong lonn[2;1H[93m    [mg[46m)[m); /* long long型ポインタcount =  */[1;72H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m200 [m  char code[MAX_CODE_LENGTH]; /* char型code[最大コード長MAX_CODE_LENGTH] */[2;72H([7Cnn[3;1H[93m [m[4C)[1;72H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m198 [mvoid CreateBinaryTree() { /* void関数CreateBinaryTree() */[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m197 [m// Frequent words will have short uniqe binary codes /* 高頻度の単語に短い一[2;1H[93m    [m意的な2進数を割当る */[1;71H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffmaa[2;1H[93m    [mn木を作成 */[1;72H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);
[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argg[3;1H[93m    [mv[i + 1]);
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(aa[5;1H[93m    [mrgv[i + 1]);
[93m691 [m  if ((i = ArgPos((char *)"-iter", argc, argv)) > 0) iter = atoi(argv[i + 1]][7;1H[93m    [m);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(aa[9;1H[93m    [mrgv[i + 1]);
[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[[[11;1H[93m    [mi + 1]);
[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_woo[13;1H[93m    [mrd));
[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));
[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {
[93m698 [m    expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precc[18;1H[93m    [mompute the exp() table
[93m699 [m    expTable[i] = expTable[i] / (expTable[i] + 1);[18C // Precc[20;1H[93m    [mompute f(x) = x / (x + 1)
[93m700 [m  }
[93m701 [m  TrainModel();
[93m702 [m  return 0;
[93m703 [m}[?12l[?25h[?25l
:[?12l[?25h200[?25l[27m[m[H[2J[1;1H[93m191 [m  }
[93m192 [m  fflush(stdout);
[93m193 [m  min_reduce++;
[93m194 [m}
[93m195 
196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffmaa[7;1H[93m    [mn木を作成 */
[93m197 [m// Frequent words will have short uniqe binary codes /* 高頻度の単語に短い一[9;1H[93m    [m意的な2進数を割当る */
[93m198 [mvoid CreateBinaryTree() { /* void関数CreateBinaryTree() */
[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];
[93m200 [m  char code[MAX_CODE_LENGTH]; /* char型code[最大コード長MAX_CODE_LENGTH] */
[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long lonn[14;1H[93m    [mg)); /* long long型ポインタcount =  */
[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long loo[16;1H[93m    [mng));
[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[18;1H[93m    [mng long));
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn;
[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15;
[93m206 [m  pos1 = vocab_size - 1;
[93m207 [m  pos2 = vocab_size;
[93m208 [m  // Following algorithm constructs the Huffman tree by adding one node at aa[24;1H[93m    [m time /* Huffman木 */[12;7H[?12l[?25h[13;7H[15;7H[17;7H[15;7H[13;7H[12;7H[13;7Hlong long *count =[?25l [46m([11C)[m[41Cnn[14;1H[93m [13;26H[?12l[?25h[?25l[m([11C)[41Cnn[14;1H[93m [13;27H[?12l[?25h[mlon[15;30H[17;30H[15;30Hng long [?25l[15;27H[46m([11C)[m[40Coo[16;1H[93m [15;39H[?12l[?25h[?25l[m[15;27H([11C)[40Coo[16;1H[93m [15;40H[?12l[?25h[mcallo[?25lc[46m([m[33Coo[16;1H[93m [m[6C[46m)[15;46H[?12l[?25h[?25l[m([33Coo[16;1H[93m [m[6C)[15;47H[?12l[?25hv[13;48H[15;48H[?25l[46m([m[33Coo[16;1H[93m [m[6C[46m)[15;46H[?12l[?25h[?25l[m([33Coo[16;1H[93m [m[6C)[15;45H[?12l[?25h[?25l[15;27H[46m([11C)[m[40Coo[16;1H[93m [15;39H[?12l[?25h[?25l[m[15;27H([11C)[40Coo[16;1H[93m [15;38H[?12l[?25h[?25l[m[46m([11C)[m[40Coo[16;1H[93m [15;27H[?12l[?25h[?25l[m([11C)[40Coo[16;1H[93m [15;26H[?12l[?25h[13;23H[m =[?25l [46m([11C)[m[41Cnn[14;1H[93m [13;26H[?12l[?25h[?25l[m([11C)[41Cnn[14;1H[93m [13;27H[?12l[?25h[14;42H[m=[?25l[25;1H[1m-- INSERT --[14;40H[?12l[?25h[?25l[m */[14;42H[K[14;39H[?12l[?25h[?25l  */[14;41H[K[14;38H[?12l[?25h[?25l */[14;40H[K[14;37H[?12l[?25h[?25ltに */[?12l[?25h[?25lv */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_s */[?12l[?25h[?25lsi */[?12l[?25h[?25liz */[?12l[?25h[?25lz3 */[?12l[?25h[?25lz */[14;51H[K[14;48H[?12l[?25h[?25lze */[?12l[?25h[?25l  */[?12l[?25h[?25l * */[?12l[?25h[?25l*2 */[?12l[?25h[?25l* */[14;54H[K[14;51H[?12l[?25h[?25l  */[?12l[?25h[?25l 2 */[?12l[?25h[?25l  */[?12l[?25h[?25l * */[?12l[?25h[?25l*1 */[?12l[?25h[?25l(vocab_size * 2 *1 */[14;40H[?12l[?25hvocab_size * 2 *[?25l* 1 */[?12l[?25h1[?25l[14;39H[46m([m[17C1[46m)[m */[?12l[?25h[?25l[14;39H([18C) [?12l[?25h*[?25l* /[?12l[?25h[?25l*/[14;62H[K[14;61H[?12l[?25h[?25l*(/[?12l[?25h[?25l[46m()[m/[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l* [46m()[m/[?12l[?25h[?25l[1C[?12l[?25h[?25l[46m([ms[46m)[m/[?12l[?25h[?25lsi[46m)[m/[?12l[?25h[?25liz[46m)[m/[?12l[?25h[?25lze[46m)[m/[?12l[?25h[?25leo[46m)[m/[?12l[?25h[?25lof[46m)[m/[?12l[?25h[?25l[14;62H(sizeof[46m()[m/[?12l[?25h[?25l[14;62H[46m([msizeof()[46m)[m/[?12l[?25h[?25l[14;62H(sizeof[46m()[m)[?12l[?25h[?25l[14;62H[46m([msizeof()[46m)[?12l[?25h[?25l[m[14;62H(sizeof[46m()[m/[14;72H[K[14;70H[?12l[?25h[?25l[14;62H[46m([msizeof[46m)[m/[14;71H[K[14;69H[?12l[?25h[?25lo[46m)[m/[14;70H[K[14;68H[?12l[?25h[?25le[46m)[m/[14;69H[K[14;67H[?12l[?25h[?25lz[46m)[m/[14;68H[K[14;66H[?12l[?25h[?25li[46m)[m/[14;67H[K[14;65H[?12l[?25h[?25ls[46m)[m/[14;66H[K[14;64H[?12l[?25h[?25l[46m()[m/[14;65H[K[14;63H[?12l[?25h[?25l[46m([ml[46m)[m/[?12l[?25h[?25llo[46m)[m/[?12l[?25h[?25lon[46m)[m/[?12l[?25h[?25lng[46m)[m/[?12l[?25h[?25lg [46m)[m/[?12l[?25h[?25l l[46m)[m/[?12l[?25h[?25llo[46m)[m/[?12l[?25h[?25lon[46m)[m/[?12l[?25h[?25lng[46m)[m/[?12l[?25h[?25l[1C[?12l[?25h[?25l[14;62H([9C)分/[?12l[?25h[?25lの/[?12l[?25h[?25l[15;24r[15;1H[L[1;25r[14;77Hメモ [15;1H[93m    [mリ/[24;1H[94m@                                                                               [15;7H[?12l[?25h[?25l[mを/[?12l[?25h[?25l確保/[?12l[?25h[?25l /[?12l[?25h[?25l */[?12l[?25h[17;10H[?25l[16;46H[46m([m[33Coo[17;1H[93m [m[6C[46m)[?12l[?25h[?25l[m[16;46H([33Coo[17;1H[93m [m[6C);[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*_[?12l[?25h[?25l[17;15H[K[17;15H[?12l[?25h[?25l*/[?12l[?25h[?25l  */[?12l[?25h[?25l l */[?12l[?25h[?25llo */[?12l[?25h[?25lon */[?12l[?25h[?25lng */[?12l[?25h[?25l  */[?12l[?25h[?25l l */[?12l[?25h[?25llo */[?12l[?25h[?25lon */[?12l[?25h[?25lng */[?12l[?25h[?25lg型 */[?12l[?25h[?25lポインタ */[?12l[?25h[?25lb */[?12l[?25h[?25lbn */[?12l[?25h[?25lna */[?12l[?25h[?25ln */[17;38H[K[17;35H[?12l[?25h[?25lb */[17;37H[K[17;34H[?12l[?25h[?25lbi */[?12l[?25h[?25lin */[?12l[?25h[?25lna */[?12l[?25h[?25lar */[?12l[?25h[?25lry */[?12l[?25h[?25lyに */[?12l[?25h[19;15H[17;41H[2C[?25l[18;24r[18;1H[L[1;25r[17;41H(vocab_size * 2 * 1) * (long long)分のメ [18;1H[93m    [mモ     */[?12l[?25h[?25l リを確保 */[?12l[?25h[?25lj */[?12l[?25h[?25ljj */[?12l[?25h[?25lj */[18;23H[K[18;20H[?12l[?25h[?25l */[18;22H[K[18;19H[?12l[?25h[20;15H[?25l[19;51H[46m([m[28Coo[20;1H[93m [m[11C[46m)[?12l[?25h[?25l[m[19;51H([28Coo[20;1H[93m [m[11C);[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l [?12l[?25h[?25l[?12l[?25h[?25l*/[?12l[?25h[?25l  */[?12l[?25h[?25l l */[?12l[?25h[?25llo */[?12l[?25h[?25lon */[?12l[?25h[?25lng */[?12l[?25h[?25l  */[?12l[?25h[?25l l */[?12l[?25h[?25llo */[?12l[?25h[?25lon */[?12l[?25h[?25lng */[?12l[?25h[?25lg型 */[?12l[?25h[?25lポインタ */[?12l[?25h[?25lp */[?12l[?25h[?25lpa */[?12l[?25h[?25lar */[?12l[?25h[?25lre */[?12l[?25h[?25len */[?12l[?25h[?25lnt */[?12l[?25h[?25lt_ */[?12l[?25h[?25l_n */[?12l[?25h[?25lno */[?12l[?25h[?25lod */[?12l[?25h[?25lde */[?12l[?25h[?25leに */[?12l[?25h[?25l[21;24r[21;1H[L[1;25r[20;51H(vocab_size * 2 * 1) * (long ll[21;1H[93m    [mong)分のメモ     */[?12l[?25h[?25l リを確保 */[?12l[?25h[?25l リを確保 */[21;31H[K[21;20H[?12l[?25h[?25l リを確保 */[21;30H[K[21;19H[?12l[?25h[?25l リを確保 */[21;29H[K[21;18H[?12l[?25h[?25lリを確保 */[21;28H[K[21;17H[?12l[?25h[18;17H[15;16H[18;17H[?25l リを確保 */[18;21H[K[18;10H[?12l[?25h[?25l リを確保 */[18;20H[K[18;9H[?12l[?25h[?25l リを確保 */[18;19H[K[18;8H[?12l[?25h[?25lリを確保 */[18;18H[K[18;7H[?12l[?25h[2C[21;7H[22;63H[23;69H[22;63H[25;1H[K[22;62H[?25l[?12l[?25h[?25l


/[?12l[?25hvocab[?25l[23;16H[?12l[?25h[?25l

?[22;51H[?12l[?25h[?25l


[22;23H[?12l[?25h[?25l


[20;52H[?12l[?25h[?25l[25;1H[19;52H[?12l[?25h[?25l[25;1H[17;42H[?12l[?25h[?25l[25;1H[16;47H[?12l[?25h[?25l[25;1H[14;40H[?12l[?25h[?25l[25;1H[13;46H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m190 [m    vocab_hash[hash] = a;[25;1H[K[1;9H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m189 [m    while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;[25;1H[K[1;60H[?12l[?25h[?25l[25;1H?vocab[1;16H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m188 [m    hash = GetWordHash(vocab[a].word);[25;1H[K[1;28H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[2L[1;25r[1;1H[93m186 [m  for (a = 0; a < vocab_size; a++) {
[93m187 [m    // Hash will be re-computed, as it is not actual[24;1H[94m@                                                                               [m[25;1H[K[1;23H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m185 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[25;1H[K[1;45H[?12l[?25h[?25l[25;1H?vocab[1;23H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m184 [m  vocab_size = b;[23;1H[94m@                                                                               [24;1H@                                                                               [m[25;1H[K[1;7H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m183 [m  } else free(vocab[a].word);[25;1H[K[1;19H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[2L[1;25r[1;1H[93m181 [m    vocab[b].word = vocab[a].word;
[93m182 [m    b++;[23;1H[94m@                                                                               [24;1H@                                                                               [m[25;1H[K[1;25H[?12l[?25h[?25l[25;1H?vocab[1;9H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m180 [m    vocab[b].cn = vocab[a].cn;[25;1H[K[1;23H[?12l[?25h[?25l[25;1H?vocab[1;9H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m179 [m  for (a = 0; a < vocab_size; a++) if (vocab[a].cn > min_reduce) {[25;1H[K[1;44H[?12l[?25h[?25l[25;1H?vocab[1;23H[?12l[?25h[?25l[25;1H[1;24r[1;1H[4L[1;25r[1;1H[93m175 [m// Reduces the vocabulary by removing infrequent tokens
[93m176 [mvoid ReduceVocab() {
[93m177 [m  int a, b = 0;
[93m178 [m  unsigned int hash;[24;1H[94m@                                                                               [m[25;1H[K[1;20H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[4L[1;25r[1;1H[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 [m[25;1H[K[1;9H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));[25;1H[K[1;9H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m169 [m  for (a = 0; a < vocab_size; a++) {[25;1H[K[1;23H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[3L[1;25r[1;1H[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struu[2;1H[93m    [mct vocab_word));
[93m168 [m  // Allocate memory for the binary tree construction[25;1H[K[2;8H[?12l[?25h[?25l[25;1H?vocab[1;52H[?12l[?25h[?25l[25;1H[1;44H[?12l[?25h[?25l[25;1H[1;23H[?12l[?25h[?25l[25;1H[1;7H[?12l[?25h[?25l[25;1H[1;24r[1;1H[3L[1;25r[1;1H[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }[25;1H[K[1;26H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m163 [m      vocab_hash[hash] = a;[25;1H[K[1;11H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;[25;1H[K[1;62H[?12l[?25h[?25l[25;1H?vocab[1;18H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m161 [m      hash=GetWordHash(vocab[a].word);[25;1H[K[1;28H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[4L[1;25r[1;1H[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /*  [4;1H[93m    [mハッシュを */[25;1H[K[1;35H[?12l[?25h[?25l[25;1H?vocab[1;16H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m157 [m      vocab_size--; /* vocab_sizeから1引く */[25;1H[K[1;28H[?12l[?25h[?25l[25;1H?vocab[1;11H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未[2;1H[93m    [m満かつaが0でない時 */[25;1H[K[1;57H[?12l[?25h[?25l[25;1H?vocab[1;14H[?12l[?25h[?25l[25;1H/[1;57H[?12l[?25h[?25l[25;1H[3;11H[?12l[?25h[?25l[25;1H[3;28H[?12l[?25h[?25l[25;1H[4;16H[?12l[?25h[?25l[25;1H[4;35H[?12l[?25h[?25l[25;1H[8;28H[?12l[?25h[?25l[25;1H[9;18H[?12l[?25h[?25l[25;1H[9;62H[?12l[?25h[?25l[25;1H?[9;18H[?12l[?25h[?25l[25;1H[8;28H[?12l[?25h[?25l[25;1H[4;35H[?12l[?25h[?25l[25;1H[4;16H[?12l[?25h[?25l[25;1H[3;28H[?12l[?25h[?25l[25;1H[3;11H[?12l[?25h[?25l[25;1H[1;57H[?12l[?25h[?25l[25;1H[1;14H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[2;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */[25;1H[K[2;40H[?12l[?25h[?25l[25;1H?vocab[1;80H[?12l[?25h[?25l[25;1H[1;24r[1;1H[3L[1;25r[1;1H[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {[25;1H[K[1;14H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[25;1H[K[1;45H[?12l[?25h[?25l[25;1H?vocab[1;23H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);;[2;1H[93m    [m/* vocab[1]のアドレス，vocab_size -1， */[25;1H[K[2;28H[?12l[?25h[?25l[25;1H?vocab[2;8H[?12l[?25h[?25l[25;1H[1;54H[?12l[?25h[?25l[25;1H[1;24H[?12l[?25h[?25l[25;1H[1;14H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替え[2;1H[93m    [mて文字列</s>を先頭に保つ */[24;1H[94m@                                                                               [m[25;1H[K[1;19H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[5L[1;25r[1;1H[93m145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用い[2;1H[93m    [mて頻度順に並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;[25;1H[K[1;18H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[3L[1;25r[1;1H[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 [m[24;1H[94m@                                                                               [m[25;1H[K[1;56H[?12l[?25h[?25l[25;1H?vocab[1;25H[?12l[?25h[?25l[25;1H[1;24r[1;1H[5L[1;25r[1;1H[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 
140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {[24;1H[94m@                                                                               [m[25;1H[K[1;14H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m136 [m  vocab_hash[hash] = vocab_size - 1;[25;1H[K[1;26H[?12l[?25h[?25l[25;1H?vocab[1;7H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;[24;1H[94m@                                                                               [m[25;1H[K[1;58H[?12l[?25h[?25l[25;1H?vocab[1;14H[?12l[?25h[?25l[25;1H[1;24r[1;1H[4L[1;25r[1;1H[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struu[2;1H[93m    [mct vocab_word)); /*  */
[93m133 [m  }
[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */[25;1H[K[2;8H[?12l[?25h[?25l[25;1H?vocab[1;53H[?12l[?25h[?25l[25;1H[1;46H[?12l[?25h[?25l[25;1H[1;25H[?12l[?25h[?25l[25;1H[1;9H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */[25;1H[K[1;36H[?12l[?25h[?25l[25;1H?vocab[1;9H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size[94m>>[m[2;1H[93m    [m以上の時 */[25;1H[K[1;66H[?12l[?25h[?25l[25;1H?vocab[1;50H[?12l[?25h[?25l[25;1H[1;29H[?12l[?25h[?25l[25;1H[1;11H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */
[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */[25;1H[K[1;24H[?12l[?25h[?25l[25;1H?vocab[1;7H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */[25;1H[K[1;42H[?12l[?25h[?25l[25;1H?vocab[1;36H[?12l[?25h[?25l[25;1H[1;13H[?12l[?25h[?25l[25;1H[1;7H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコ[94m>>[m[2;1H[93m    [mピー */[25;1H[K[1;54H[?12l[?25h[?25l[25;1H?vocab[1;48H[?12l[?25h[?25l[25;1H[1;20H[?12l[?25h[?25l[25;1H[1;14H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個[2;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */[25;1H[K[2;53H[?12l[?25h[?25l[25;1H?vocab[2;47H[?12l[?25h[?25l[25;1H[1;13H[?12l[?25h[?25l[25;1H[1;7H[?12l[?25h[?25l[25;1H[1;24r[1;1H[7L[1;25r[1;1H[93m121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[3;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[5;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[7;1H[93m    [mきい場合はlenghに最大文字数を代入 */[25;1H[K[1;27H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[11L[1;25r[1;1H[93m113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語[94m>>[m[2;1H[93m    [m彙中での単語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[4;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル[7;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 [m[25;1H[K[1;50H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[6L[1;25r[1;1H[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sii[2;1H[93m    [mzeを返す */
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 [m[25;1H[K[1;68H[?12l[?25h[?25l[25;1H?vocab[1;29H[?12l[?25h[?25l[25;1H[1;24r[1;1H[3L[1;25r[1;1H[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]][2;1H[93m    [m; /* 文字列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返[94m>>[m[3;1H[93m    [mす */[24;1H[94m@                                                                               [m[25;1H[K[2;60H[?12l[?25h[?25l[25;1H?vocab[2;28H[?12l[?25h[?25l[25;1H[2;22H[?12l[?25h[?25l[25;1H[1;65H[?12l[?25h[?25l[25;1H[1;33H[?12l[?25h[?25l[25;1H[1;27H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m106 [m    if (vocab_hash[hash] == -1) return -1; /* vocab_hash[hash]が-1の時-1を返 [2;1H[93m    [mす */[24;1H[94m@                                                                               [m[25;1H[K[1;51H[?12l[?25h[?25l[25;1H?vocab[1;13H[?12l[?25h[?25l[25;1H[1;24r[1;1H[7L[1;25r[1;1H[93m102 [m// Returns position of a word in the vocabulary; if the word is not found, rr[2;1H[93m    [meturns -1 /* 語彙中の単語の位置を返す(単語が語彙中に無い場合は-1を返す) */
[93m103 [mint SearchVocab(char *word) { /* char型ポインタwordを引数に持つint型関数Searr[4;1H[93m    [mchVocab() */
[93m104 [m  unsigned int hash = GetWordHash(word); /* 符号無int型hashにwordのhash値を[94m>>[m[6;1H[93m    [m代入 */
[93m105 [m  while (1) { /* 無限ループ */[24;1H[94m@                                                                               [m[25;1H[K[1;42H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[5L[1;25r[1;1H[93m 98 [m  hash = hash % vocab_hash_size; /* hashにhashをvocab_hash_sizeの剰余を代入  [2;1H[93m    [m*/
[93m 99 [m  return hash; /* hashを返す */
[93m100 [m}
[93m101 [m[24;1H[94m@                                                                               [m[25;1H[K[1;53H[?12l[?25h[?25l[25;1H?vocab[1;21H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[2;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[4;1H[93m    [m);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boo[18;1H[93m    [mundaries /* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見[94m>>[m[19;1H[93m    [mなす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポイン[21;1H[93m    [mタfinが引数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にル[94m>>[m[24;1H[93m    [mープ終了 */[13;34H[?12l[?25h[?25l[25;1H?vocab[13;18H[?12l[?25h[?25l[25;1H[11;21H[?12l[?25h[?25l[25;1H[6;16H[?12l[?25h[?25l[25;1H[3;63H[?12l[?25h[?25l[25;1H[3;23H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m 36 [m};
[93m 37 
 38 [mchar train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[4;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */
[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[6;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */
[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocabを宣言  [8;1H[93m    [m*/
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[10;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [13;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[15;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {[13;27H[?12l[?25h[?25l[25;1H?vocab[13;11H[?12l[?25h[?25l[25;1H[12;38H[?12l[?25h[?25l[25;1H[12;15H[?12l[?25h[?25l[25;1H[11;38H[?12l[?25h[?25l[25;1H[11;10H[?12l[?25h[?25l[25;1H[7;69H[?12l[?25h[?25l[25;1H[7;49H[?12l[?25h[?25l[25;1H[7;24H[?12l[?25h[?25l[25;1H[7;12H[?12l[?25h[?25l[25;1H[6;23H[?12l[?25h[?25l[25;1H[6;6H[?12l[?25h[?25l[25;1H[5;44H[?12l[?25h[?25l[25;1H[5;15H[?12l[?25h[?25l[25;1H[1;24r[1;1H[5L[1;25r[1;1H[93m 32 [mstruct vocab_word {
[93m 33 [m  long long cn; /* long long型(64 bit符号付整数型) cn */
[93m 34 [m  int *point; /* int型ポインタpointを宣言 */
[93m 35 [m  char *word, *code, codelen; /* char型(1 byte文字型)codelenとポインタword， [5;1H[93m    [mcodeを宣言 */[25;1H[K[1;12H[?12l[?25h[?25l[25;1H?vocab[1;24r[1;1H[L[1;25r[1;1H[93m 31 [m/* 構造体型struct vocab_wordを宣言 */[25;1H[K[1;23H[?12l[?25h[?25l[25;1H/vocab[2;12H[?12l[?25h[?25l[25;1H[11;15H[?12l[?25h[?25l[25;1H[11;44H[?12l[?25h[?25l[25;1H[12;6H[?12l[?25h[?25l[25;1H[12;23H[?12l[?25h[?25l[25;1H[13;12H[?12l[?25h[?25l[25;1H[13;24H[?12l[?25h[?25l[25;1H[13;49H[?12l[?25h[?25l[25;1H[13;69H[?12l[?25h[?25l[25;1H[17;10H[?12l[?25h[?25l[25;1H[17;38H[?12l[?25h[?25l[25;1H[18;15H[?12l[?25h[?25l[25;1H[18;38H[?12l[?25h[?25l[25;1H[19;11H[?12l[?25h[?25l[25;1H[19;27H[?12l[?25h[?25l[25;1H[1;24r[1;1H[14M[1;25r[11;1H[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[21;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[23;1H[93m    [m);
[93m 59 [m  i = 0;[25;1H[K[22;23H[?12l[?25h[?25l


/vocab[22;63H[?12l[?25h[?25l


[1;24r[1;1H[2M[1;25r[23;1H[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {[25;1H[K[23;16H[?12l[?25h[?25l

/vocab[1;24r[1;1H[5M[1;25r[20;1H[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }[25;1H[K[23;21H[?12l[?25h[?25l

/vocab[1;24r[24;1H
[1;25r[24;1H[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;[25;1H[K[24;18H[?12l[?25h[?25l
/vocab[24;34H[?12l[?25h[?25l
[27m[m[H[2J[1;1H[93m 90 [m  }
[93m 91 [m  word[a] = 0;
[93m 92 [m}
[93m 93 
 94 [m// Returns hash value of a word /* 単語のhash値を返す */
[93m 95 [mint GetWordHash(char *word) { /* char型ポインタwordを引数に持つint型関数GetWW[7;1H[93m    [mordHash */
[93m 96 [m  unsigned long long a, hash = 0; /* 符号無long long型a, hash */
[93m 97 [m  for (a = 0; a < strlen(word); a++) hash = hash * 257 + word[a]; /* aが文字 [10;1H[93m    [m列wordの文字長未満の時hashにhash * 257 + word[a]を代入 */
[93m 98 [m  hash = hash % vocab_hash_size; /* hashにhashをvocab_hash_sizeの剰余を代入  [12;1H[93m    [m*/
[93m 99 [m  return hash; /* hashを返す */
[93m100 [m}
[93m101 
102 [m// Returns position of a word in the vocabulary; if the word is not found, rr[17;1H[93m    [meturns -1 /* 語彙中の単語の位置を返す(単語が語彙中に無い場合は-1を返す) */
[93m103 [mint SearchVocab(char *word) { /* char型ポインタwordを引数に持つint型関数Searr[19;1H[93m    [mchVocab() */
[93m104 [m  unsigned int hash = GetWordHash(word); /* 符号無int型hashにwordのhash値を[94m>>[m[21;1H[93m    [m代入 */
[93m105 [m  while (1) { /* 無限ループ */
[93m106 [m    if (vocab_hash[hash] == -1) return -1; /* vocab_hash[hash]が-1の時-1を返[24;1H[93m    [mす */[11;21H[?12l[?25h[?25l[25;1H/vocab[11;53H[?12l[?25h[?25l[25;1H[16;42H[?12l[?25h[?25l[25;1H[23;13H[?12l[?25h[?25l

[23;51H[?12l[?25h[?25l

[1;24r[1;1H[3M[1;25r[22;1H[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]][23;1H[93m    [m; /* 文字列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返[94m>>[m[24;1H[93m    [mす */[25;1H[K[22;27H[?12l[?25h[?25l


/vocab[22;33H[?12l[?25h[?25l


[22;65H[?12l[?25h[?25l


[23;22H[?12l[?25h[?25l

[23;28H[?12l[?25h[?25l

[23;60H[?12l[?25h[?25l

[1;24r[1;1H[2M[1;25r[23;1H[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sii[24;1H[93m    [mzeを返す */[25;1H[K[23;29H[?12l[?25h[?25l

/vocab[23;68H[?12l[?25h[?25l

[1;24r[1;1H[7M[1;25r[18;1H[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語[94m>>[m[23;1H[93m    [m彙中での単語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Re[24;1H[94m@                                                                               [m[25;1H[K[22;50H[?12l[?25h[?25l


/vocab[1;24r[1;1H[9M[1;25r[15;1H[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[16;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル [19;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */[25;1H[K[24;27H[?12l[?25h[?25l
/vocab[1;24r[1;1H[8M[1;25r[17;1H[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[18;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[20;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[22;1H[93m    [mきい場合はlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個[24;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */[25;1H[K[23;7H[?12l[?25h[?25l

/vocab[23;13H[?12l[?25h[?25l

[24;47H[?12l[?25h[?25l
[24;53H[?12l[?25h[?25l
[1;24r[1;1H[2M[1;25r[23;1H[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコ[94m>>[m[24;1H[93m    [mピー */[25;1H[K[23;14H[?12l[?25h[?25l

/vocab[23;20H[?12l[?25h[?25l

[23;48H[?12l[?25h[?25l

[23;54H[?12l[?25h[?25l

[1;24r[24;1H
[1;25r[24;1H[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */[25;1H[K[24;7H[?12l[?25h[?25l
/vocab[24;13H[?12l[?25h[?25l
[24;36H[?12l[?25h[?25l
[24;42H[?12l[?25h[?25l
[1;24r[24;1H
[1;25r[24;1H[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */[25;1H[K[24;7H[?12l[?25h[?25l
/vocab[24;24H[?12l[?25h[?25l
[1;24r[1;1H[4M[1;25r[21;1H[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */
[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size[94m>>[m[23;1H[93m    [m以上の時 */
[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */[25;1H[K[22;11H[?12l[?25h[?25l


:[?12l[?25h200[?25l[27m[m[H[2J[1;1H[93m191 [m  }
[93m192 [m  fflush(stdout);
[93m193 [m  min_reduce++;
[93m194 [m}
[93m195 
196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffmaa[7;1H[93m    [mn木を作成 */
[93m197 [m// Frequent words will have short uniqe binary codes /* 高頻度の単語に短い一[9;1H[93m    [m意的な2進数を割当る */
[93m198 [mvoid CreateBinaryTree() { /* void関数CreateBinaryTree() */
[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];
[93m200 [m  char code[MAX_CODE_LENGTH]; /* char型code[最大コード長MAX_CODE_LENGTH] */
[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long lonn[14;1H[93m    [mg)); /* long long型ポインタcountに(vocab_size * 2 * 1) * (long long)分のメモ [15;1H[93m    [mリを確保 */
[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long loo[17;1H[93m    [mng)); /* long long型ポインタbinaryに(vocab_size * 2 * 1) * (long long)分のメ [18;1H[93m    [mモリを確保 */
[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[20;1H[93m    [mng long)); /* long long型ポインタparent_nodeに(vocab_size * 2 * 1) * (long ll[21;1H[93m    [mong)分のメモリを確保 */
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn;
[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15;
[93m206 [m  pos1 = vocab_size - 1;[12;7H[?12l[?25h[13;7H[16;7H[19;7H[22;7H[23;7H[22;7Hfor[?25l [46m([26C)[22;11H[?12l[?25h[?25l[m([26C)[22;12H[?12l[?25ha = 0; a < vocab_size; a+[?25l[22;11H[46m([26C)[?12l[?25h[?25l[m[22;11H([26C)[?12l[?25h coun[?25lt[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h = voca[?25lb[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h.cn[?25l


[1m-- INSERT --[22;63H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[25;1H[K[22;69H[?25l[?12l[?25h[?25l


/[?12l[?25hcount[?25l[23;53H[?12l[?25h[?25l

?[22;40H[?12l[?25h[?25l


[14;32H[?12l[?25h[?25l[25;1H[13;18H[?12l[?25h[?25l[25;1H/[14;32H[?12l[?25h[?25l[25;1H[22;40H[?12l[?25h[?25l


[23;53H[?12l[?25h[22;53Hca[?25lb[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h.cn; /* [?25l


[1m-- INSERT --[22;68H[?12l[?25h[?25l[m c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25l ポインタcount  [23;1H[93m    [m*/[23;7H[K[24;2H[93m05[m[2C for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15;[22;75H[?12l[?25h[19;75H[22;75Hcount[?25lt[94m>>[m[23;1H[93m    [mに */[?12l[?25h[?25lv */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb[ */[?12l[?25h[?25l[a */[?12l[?25h[?25l[46m[[ma[46m][m */[?12l[?25h[?25l[a]. */[?12l[?25h[?25l.c */[?12l[?25h[?25lcn */[?12l[?25h[?25lnを */[?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[m[a][?12l[?25h[22;79Hn[23;5H[22;79H[2C[2Ccoun[23;5H[2Cvo[22;79H[23;5H[22;79H[23;5H[2Cvoca[?25lb[46m[[ma[46m][?12l[?25h[?25l[[?12l[?25h[?25l[ma[?12l[?25h[?25l[1C[?12l[?25h[?25l[a].[?12l[?25hcn[2C[?25l代入 */[?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[m[a][?12l[?25h[?25lのにvocab[a].cnを代入 */[23;7H[?12l[?25h[?25laにvocab[a].cnを代入 */[23;8H[?12l[?25h[?25la番目にvocab[a].cnを代入 */[23;12H[?12l[?25h[?25l[2Cにvocab[a].cnを代入 */[23;14H[?12l[?25h[24;69H[23;14H[?25l[19;51H[46m([m[28Coo[20;1H[93m [m[11C[46m)[m[66Cll[21;1H[93m [20;14H[?12l[?25h[?25l[m[19;51H([28Coo[20;1H[93m [m[11C)[66Cll[21;1H[93m [23;14H[?12l[?25h[?25l[m[19;51H[46m([m[28Coo[20;1H[93m [m[11C[46m)[m[66Cll[21;1H[93m [20;14H[?12l[?25h[?25l[m[19;51H([28Coo[20;1H[93m [m[11C)[66Cll[21;1H[93m [20;15H[?12l[?25h[m /* long long[2C[2C[2C[2C[2Cp[23;36H[?25l[46m[[ma[46m][?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[m[a][?12l[?25h[22;79H [?25l aポインタcountt[23;1H[93m [22;68H[?12l[?25h[?25l[ma<ポインタcounn[23;1H[93m    [mtのa番目ににvocab[a].cnを代入 */[22;69H[?12l[?25h[?25laポインタcountt[23;1H[93m    [mのa番目ににvocab[a].cnを代入 */[23;36H[K[22;68H[?12l[?25h[?25l ポインタcount[94m>>[m[23;1H[93m [22;67H[?12l[?25h[?25l[m 0ポインタcountt[23;1H[93m [22;68H[?12l[?25h[?25l[m0<ポインタcounn[23;1H[93m    [mtのa番目ににvocab[a].cnを代入 */[22;69H[?12l[?25h[?25l<-ポインタcouu[23;1H[93m    [mntのa番目ににvocab[a].cnを代入 */[22;70H[?12l[?25h[?25l<ポインタcounn[23;1H[93m    [mtのa番目ににvocab[a].cnを代入 */[23;37H[K[22;69H[?12l[?25h[?25l<=ポインタcouu[23;1H[93m    [mntのa番目ににvocab[a].cnを代入 */[22;70H[?12l[?25h[?25l=aポインタcoo[23;1H[93m    [muntのa番目ににvocab[a].cnを代入 */[22;71H[?12l[?25h[?25la<ポインタcc[23;1H[93m    [mountのa番目ににvocab[a].cnを代入 */[22;72H[?12l[?25h<=a<[?25laポインタcoo[23;1H[93m    [muntのa番目ににvocab[a].cnを代入 */[23;39H[K[22;71H[?12l[?25h[?25l=ポインタcouu[23;1H[93m    [mntのa番目ににvocab[a].cnを代入 */[23;38H[K[22;70H[?12l[?25h[?25l<ポインタcounn[23;1H[93m    [mtのa番目ににvocab[a].cnを代入 */[23;37H[K[22;69H[?12l[?25h[?25l0ポインタcountt[23;1H[93m    [mのa番目ににvocab[a].cnを代入 */[23;36H[K[22;68H[?12l[?25h[?25l ポインタcount[94m>>[m[23;1H[93m [22;67H[?12l[?25h[2C[2C[2C[2C[mcoun[23;5H[2Ca[?25l0a番目ににvocab[a].cnを代入 */[23;8H[?12l[?25h[?25l0<a番目ににvocab[a].cnを代入 */[23;9H[?12l[?25h[?25l<=a番目ににvocab[a].cnを代入 */[23;10H[?12l[?25ha[?25la<番目ににvocab[a].cnを代入 */[23;12H[?12l[?25h[?25l<v番目ににvocab[a].cnを代入 */[23;13H[?12l[?25h[?25lvo番目ににvocab[a].cnを代入 */[23;14H[?12l[?25h[?25loc番目ににvocab[a].cnを代入 */[23;15H[?12l[?25h[?25lca番目ににvocab[a].cnを代入 */[23;16H[?12l[?25h[?25lab番目ににvocab[a].cnを代入 */[23;17H[?12l[?25h[?25lb_番目ににvocab[a].cnを代入 */[23;18H[?12l[?25h[?25l_s番目ににvocab[a].cnを代入 */[23;19H[?12l[?25h[?25lsi番目ににvocab[a].cnを代入 */[23;20H[?12l[?25h[?25liz番目ににvocab[a].cnを代入 */[23;21H[?12l[?25h[?25lze番目ににvocab[a].cnを代入 */[23;22H[?12l[?25h<=[?25l0 <=a<vocab_size番目ににvocab[a].cnを代入 */[23;9H[?12l[?25h<=[?25l= a<vocab_size番目ににvocab[a].cnを代入 */[23;12H[?12l[?25ha[?25la <vocab_size番目ににvocab[a].cnを代入 */[23;14H[?12l[?25h<v[?25l< vocab_size番目ににvocab[a].cnを代入 */[23;16H[?12l[?25h[24;69H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l[1;24r[24;1H
[1;25r[23;72H インタcoo[24;1H[93m    [munt>    の0 <= a < vocab_size番目ににvocab[a].cn */[?12l[?25h[?25lnを代入 */[?12l[?25h[25;1H[K[24;57H[?25l[?12l[?25h[?25l
1 change; before #39  4 seconds ago[23;72H  */ [23;77H[K[24;1H[93m206 [m  pos1 = vocab_size - 1;[24;29H[K[23;73H[?12l[?25h[?25l[25;20H8  21 seconds ago[23;70H[K[23;68H[?12l[?25h[?25l

/count[25;7H[K[25;1H[1;24r[1;1H[8M[1;25r[17;1H[93m207 [m  pos2 = vocab_size;
[93m208 [m  // Following algorithm constructs the Huffman tree by adding one node at aa[19;1H[93m    [m time /* Huffman木 */
[93m209 [m  for (a = 0; a < vocab_size - 1; a++) {
[93m210 [m    // First, find two smallest nodes 'min1, min2'
[93m211 [m    if (pos1 >= 0) {
[93m212 [m      if (count[pos1] < count[pos2]) {
[93m213 [m[7C min1i = pos1;[25;1H[K[23;15H[?12l[?25hcoun[23;5H  [?25l

[1m-- INSERT --[m[23;8H < vocab_size番目ににvocab[a].cnを代入   if (count[pos1] < count[pos2]) {[23;46H[?12l[?25h[25;1H[K[23;44H[?25l[?12l[?25h[?25l

1 change; before #40  3 seconds ago[23;8H   if (count[pos1] < count[pos2]) { [23;44H[K[23;8H[?12l[?25h[24;8H[?25l[1;24r[24;1H
[1;25r[24;1H[93m214 [m[7C pos1--;[25;1H[K[24;8H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m215 [m      } else {[24;8H[?12l[?25h[?25l
1 change; before #37  32 seconds ago[12;14H<vocab_size番目ににvocab[a].cnを代入 */[12;53H[K[12;15H[?12l[?25hv[?25l[25;11Hafter #37  43 seconds ago[25;36H[K[12;14H< vocab_size番目ににvocab[a].cnを代入 */[12;15H[?12l[?25h[?25l[25;18H40  19[21;8H < vocab_size番目ににvocab[a].cnを代入   if (count[pos1] < count[pos2]) {[21;8H[?12l[?25h[?25l[25;11Hbefore #40  25 seconds ago[21;8H   if (count[pos1] < count[pos2]) { [21;44H[K[21;8H[?12l[?25h[20;8H[19;8H[18;8H[16;8H[15;8H[14;8H[13;5H[63C[?25l[25;1H[1m-- INSERT --[m[25;13H[K[13;69H[?12l[?25h[?25l [?12l[?25h[?25l ?[?12l[?25h[?25l[13;70H[K[13;70H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l[14;24r[14;1H[L[1;25r[13;72H ポインタ[14;1H[93m    [mcount>    の0 <= a < vocab_size番目ににvocab[a].cnを代入[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[m[a][?12l[?25hvocab_size[?25le 番目ににvocab[a].cnを代入 */[14;37H[?12l[?25h[?25l *番目ににvocab[a].cnを代入 */[14;38H[?12l[?25h[?25l* 番目ににvocab[a].cnを代入 */[14;39H[?12l[?25h[?25l 2番目ににvocab[a].cnを代入 */[14;40H[?12l[?25h[?25l <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;67H[K[14;17H[?12l[?25h[?25lv <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;18H[?12l[?25h[?25lvo <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;19H[?12l[?25h[?25loc <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;20H[?12l[?25h[?25lca <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;21H[?12l[?25h[?25lab <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;22H[?12l[?25h[?25lb_ <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;23H[?12l[?25h[?25l_s <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;24H[?12l[?25h[?25lsi <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;25H[?12l[?25h[?25liz <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;26H[?12l[?25h[?25lze <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;27H[?12l[?25h [?25l のvocab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;76H[K[14;14H[?12l[?25h[?25l のvocab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;75H[K[14;13H[?12l[?25h[?25l のvocab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;74H[K[14;12H[?12l[?25h[?25l>のvocab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;73H[K[14;11H[?12l[?25h[?25ltのvocab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */[14;72H[K[14;10H[?12l[?25h[15;29H[14;10H[12;10H[?25l[11;78Hnの [12;1H[93m    [m0 <= a < vocab_size番目に[2Cvocab[a].cnを代入 */[12;52H[K[11;79H[?12l[?25h[?25lnt[94m>>[m[12;1H[93m    [mの0 <= a < vocab_size番目[2Cにvocab[a].cnを代入 */[12;5H[?12l[?25h[14;5H[15;29H[16;25H[15;29H[16;25H[18;5H[16;25H[18;5H time /* Huffman[2C *Huffman[2C[?25lを */[?12l[?25h[?25l構成する */[?12l[?25h[?25lアルゴリズム */[?12l[?25h[?25l ノードHuffman木を構成するアルゴリズム */[18;20H[?12l[?25h[?25lをHuffman木を構成するアルゴリズム */[18;22H[?12l[?25h[?25laHuffman木を構成するアルゴリズム */[18;23H[?12l[?25h[?25la回Huffman木を構成するアルゴリズム */[18;25H[?12l[?25h[?25l追加してHuffman木を構成するアルゴリズム */[18;33H[?12l[?25h[?25l[19;45H[?12l[?25h[25;1H[K[19;44H[?25l[?12l[?25h[17;44H[16;24H[15;28H[13;44H[11;44H[?25l[8;32H[46m([11C)[m[35Coo[9;1H[93m [m[78Cll[10;1H[93m [8;44H[?12l[?25h[?25l[m[8;32H([11C)[35Coo[9;1H[93m [m[78Cll[10;1H[93m [5;44H[?12l[?25h[2;44H[1;44H[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];[1;44H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m198 [mvoid CreateBinaryTree() { /* void関数CreateBinaryTree() */[1;44H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m197 [m// Frequent words will have short uniqe binary codes /* 高頻度の単語に短い一[2;1H[93m    [m意的な2進数を割当る */[1;44H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffmaa[2;1H[93m    [mn木を作成 */[1;44H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m195 [m[24;1H[94m@                                                                               [1;5H[?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m194 [m}[?12l[?25h[2;5H[3;44H[5;44H[7;44H[8;44H[9;44H[10;44H[13;44H[?25l[36Coo[14;1H[93m [m[78C  [15;1H[93m [m[16;32H[46m([11C)[m[35Coo[17;1H[93m [m[78Cll[18;1H[93m [16;44H[?12l[?25h[?25l[m[16;32H([11C)[35Coo[17;1H[93m [m[78Cll[18;1H[93m [19;44H[?12l[?25h[21;44H[23;28H[24;24H[23;28H[21;44H[19;44H[?25l[m[16;32H[46m([11C)[m[35Coo[17;1H[93m [m[78Cll[18;1H[93m [16;44H[?12l[?25h[?25l[m[16;32H([11C)[35Coo[17;1H[93m [m[78Cll[18;1H[93m [13;44H[?12l[?25h[10;44H[13;44H[?25l[m[36Coo[14;1H[93m [m[78C  [15;1H[93m [m[16;32H[46m([11C)[m[35Coo[17;1H[93m [m[78Cll[18;1H[93m [16;44H[?12l[?25h[?25l[m[16;32H([11C)[35Coo[17;1H[93m [m[78Cll[18;1H[93m [19;44H[?12l[?25h[21;44H[19;44H[?25l[mt[46m[[ma[46m][m[32C[94m>>[m[20;1H[93m [19;45H[?12l[?25h[?25l[m[a][32C[94m>>[m[20;1H[93m [19;46H[?12l[?25h[?25l[m[46m[[ma[46m][m[32C[94m>>[m[20;1H[93m [19;47H[?12l[?25h[?25l[m[a][32C[94m>>[m[20;1H[93m [19;48H[?12l[?25h[m = v[21;52H[23;28H[24;24H[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m208 [m  // Following algorithm constructs the Huffman tree by adding one node at aa[24;1H[93m    [m time /* ノードをa回追加してHuffman木を構成するアルゴリズム */[23;52H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m209 [m  for (a = 0; a < vocab_size - 1; a++) {
[93m210 [m    // First, find two smallest nodes 'min1, min2'[23;44H[?12l[?25h[24;52H[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m211 [m    if (pos1 >= 0) {
[93m212 [m      if (count[pos1] < count[pos2]) {[23;24H[?12l[?25h[22;52H[21;44H[22;52Hn2[23;24H[24;42H[?25l[1;24r[24;1H
[1;25r[24;1H[93m213 [m[7C min1i = pos1;[?12l[?25h[23;42H[22;24H[23;42H[22;24H[21;54H[?25l[25;1H[1m-- INSERT --[21;55H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l まず */[?12l[?25h[?25l最小 */[?12l[?25h[?25lの */[?12l[?25h[2C[?25l2最小の */[21;64H[?12l[?25h[?25l2つの最小の */[21;68H[?12l[?25h[2C[2C[2C[?25l */[21;75H[K[21;72H[?12l[?25h[?25lの */[?12l[?25h[?25l */[21;75H[K[21;72H[?12l[?25h[?25lノード */[21;78H[?12l[?25h[?25l[22;24r[22;1H[L[1;25r[21;78H' **[22;1H[93m    [m/[21;79H[?12l[?25h[?25l'm  [22;1H[93m    [m*/[21;80H[?12l[?25h[?25lmii[22;1H[93m    [m */[?12l[?25h[?25l[93m [mn */[?12l[?25h[?25ln1 */[?12l[?25h[?25l1, */[?12l[?25h[?25l  */[?12l[?25h[?25l m */[?12l[?25h[?25lmi */[?12l[?25h[?25lin */[?12l[?25h[?25ln2 */[?12l[?25h[?25l2' */[?12l[?25h[?25l'を */[?12l[?25h[?25l探す */[?12l[?25h[?25l[23;25H[?12l[?25h[?25l[24;43H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m213 [m[7C min1i = pos1;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m214 [m[7C pos1--;[?12l[?25h[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m215 [m      } else {
[93m216 [m[7C min1i = pos2;
[93m217 [m[7C pos2++;[22;19H[?12l[?25h[23;26H[24;20H[?25l[1;24r[1;1H[3M[1;25r[19;18H[46m{[m


[93m218 [m      [46m}[m
[93m219 [m    } else {
[93m220 [m      min1i = pos2;[22;12H[?12l[?25h[?25l[19;18H{[22;11H}[23;17H[?12l[?25h[24;24H[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m221 [m      pos2++;
[93m222 [m    }
[93m223 [m    if (pos1 >= 0) {[22;18H[?12l[?25h[?25l[20;16H[46m{[23;9H}[?12l[?25h[?25l[m[20;16H{[23;9H}[22;18H[?12l[?25h[21;24H[?25l[20;16H[46m{[23;9H}[20;17H[?12l[?25h[?25l[16;18H{[19;11H}[m[20;16H{[23;9H}[19;12H[?12l[?25h[?25l[16;18H{[19;11H}[18;20H[?12l[?25h[17;26H[?25l[16;18H[46m{[19;11H}[16;19H[?12l[?25h[?25l[m{[19;11H}[15;20H[?12l[?25h[14;26H[?25l;k[?12l[?25h[?25lkk[?12l[?25h[?25l[14;27H[K[14;27H[?12l[?25h[?25l[14;26H[K[14;26H[?12l[?25h[?25l[13;20H[46m[[mpos1[46m][?12l[?25h[?25l[12;24H{[m[13;20H[pos1][20;9H[46m}[12;25H[?12l[?25h[?25l[m{[20;9H}[10;26H[?12l[?25h[9;26Hab_size - 1; a+[?25l[9;11H[46m([30C)[?12l[?25h[?25l)[?12l[?25h[?25l[m[9;11H([30C) [?12l[?25h[?25l{[?12l[?25h[10;45H[?25l[35Cii[11;1H[93m [m[12;24H[46m{[20;9H}[12;25H[?12l[?25h[?25l[m{[13;42H[46m{[16;11H}[m[20;9H}[13;43H[?12l[?25h[?25l[12;24H[46m{[m[13;42H{[16;11H}[20;9H[46m}[12;25H[?12l[?25h[?25l[m{[20;9H}[10;45H[?12l[?25h[?25l[9;45H[?12l[?25h[7;45H[6;25H[5;29H[?25l [?12l[?25h[?25l[?12l[?25h[6;25H[7;29H[9;29H[10;29H[?25l[51Cii[11;1H[93m [m[12;24H[46m{[20;9H}[12;25H[?12l[?25h[?25l[m{[20;9H}[13;29H[?12l[?25h[?25l[12;24H[46m{[20;9H}[12;25H[?12l[?25h[?25l[m{[20;9H}[12;26H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [?25l p */[?12l[?25h[?25lpo */[?12l[?25h[?25los */[?12l[?25h[?25ls1 */[?12l[?25h[?25l1( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l[?12l[?25h[?25l[46m([m最初は[46m)[m */[?12l[?25h[?25lv[46m)[m */[?12l[?25h[?25lvo[46m)[m */[?12l[?25h[?25loc[46m)[m */[?12l[?25h[?25lca[46m)[m */[?12l[?25h[?25lab[46m)[m */[?12l[?25h[?25lb_[46m)[m */[?12l[?25h[?25l_s[46m)[m */[?12l[?25h[?25lsi[46m)[m */[?12l[?25h[?25liz[46m)[m */[?12l[?25h[?25lze[46m)[m */[?12l[?25h[?25le-[46m)[m */[?12l[?25h[?25l-1[46m)[m */[?12l[?25h[?25l[1C[?12l[?25h[?25l[12;33H([18C)が */[?12l[?25h[?25l非負 */[?12l[?25h[?25lん */[?12l[?25h[?25l */[12;62H[K[12;59H[?12l[?25h[?25l */[12;60H[K[12;57H[?12l[?25h[?25l負 */[?12l[?25h[?25lの */[?12l[?25h[?25l時 */[?12l[?25h[?25l[13;42H[46m{[16;11H}[13;43H[?12l[?25h[m[25;1H[K[13;42H[?25l[?12l[?25h[?25l{[16;11H}[12;42H[?12l[?25h[10;42H[?25l[9;11H[46m([30C)[?12l[?25h[?25l[m[9;11H([30C)[10;42H[?12l[?25h[12;42H[10;42H[?25l[9;11H[46m([30C)[?12l[?25h[?25l[m[9;11H([30C)[7;42H[?12l[?25h[6;24H[5;28H[6;24H[7;27H[?25l[25;1H:[?12l[?25hw[?25l"word2vec.c" 703L, 30813C written[7;27H[?12l[?25h[?25l[25;1H[K[25;1H:[?12l[?25hq[?25l[?1l>[?12l[?25h[?1049l
bash-3.2$ vi word2vec.c
[?1049h[?1h=[1;25r[?12;25h[?12l[?25h[27m[m[H[2J[?25l[25;1H"word2vec.c" 703L, 30813C[>c[1;1H//  Copyright 2013 Google Inc. All Rights Reserved.
//
//  Licensed under the Apache License, Version 2.0 (the "License");
//  you may not use this file except in compliance with the License.
//  You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
//  Unless required by applicable law or agreed to in writing, software
//  distributed under the License is distributed on an "AS IS" BASIS,
//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//  See the License for the specific language governing permissions and
//  limitations under the License.

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <pthread.h>

#define MAX_STRING 100 /* 最大文字数は100字まで */
#define EXP_TABLE_SIZE 1000
#define MAX_EXP 6
#define MAX_SENTENCE_LENGTH 1000[1;1H[?12l[?25h[?25l[25;1H[K[25;1H:[?12l[?25hset number[?25l[1;1H[93m  1 [m//  Copyright 2013 Google Inc. All Rights Reserved.
[93m  2 [m//
[93m  3 [m//  Licensed under the Apache License, Version 2.0 (the "License");
[93m  4 [m//  you may not use this file except in compliance with the License.
[93m  5 [m//  You may obtain a copy of the License at
[93m  6 [m//
[93m  7 [m//      http://www.apache.org/licenses/LICENSE-2.0
[93m  8 [m//
[93m  9 [m//  Unless required by applicable law or agreed to in writing, software
[93m 10 [m//  distributed under the License is distributed on an "AS IS" BASIS,
[93m 11 [m//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.[12;1H[93m 12 [m//  See the License for the specific language governing permissions and
[93m 13 [m//  limitations under the License.
[93m 14 
 15 [m#include <stdio.h>
[93m 16 [m#include <stdlib.h>
[93m 17 [m#include <string.h>
[93m 18 [m#include <math.h>
[93m 19 [m#include <pthread.h>
[93m 20 
 21 [m#define MAX_STRING 100 /* 最大文字数は100字まで */
[93m 22 [m#define EXP_TABLE_SIZE 1000
[93m 23 [m#define MAX_EXP 6
[93m 24 [m#define MAX_SENTENCE_LENGTH 1000[1;5H[?12l[?25h[2;5H[3;5H[4;5H[5;5H[6;5H[7;5H[8;5H[9;5H[10;5H[11;5H[12;5H[13;5H[14;5H[15;5H[16;5H[17;5H[18;5H[19;5H[20;5H[21;5H[22;5H[23;5H[24;5H[?25l[1;24r[24;1H
[1;25r[24;1H[93m 25 [m#define MAX_CODE_LENGTH 40 /* 最大コード長は40字まで */[25;1H[K[24;5H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 26 [?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[23;1H[93m 27 [mconst int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in thh[24;1H[93m    [me vocabulary[23;5H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 28 [?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[24;1H[93m 29 [mtypedef float real;[19C // Precision of float numbers[24;5H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 30 [?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[24;1H[93m 31 [m/* 構造体型struct vocab_wordを宣言 */[24;5H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 32 [mstruct vocab_word {[24;5H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 33 [m  long long cn; /* long long型(64 bit符号付整数型) cn */[24;5H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 34 [m  int *point; /* int型ポインタpointを宣言 */[24;5H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m 35 [m  char *word, *code, codelen; /* char型(1 byte文字型)codelenとポインタword，[24;1H[93m    [mcodeを宣言 */[23;5H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[19;23H[46m{[m[24;1H[93m 36 [m[46m}[m;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[18;23H{[23;5H}
[93m 37 [?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[23;1H[93m 38 [mchar train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[24;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */[23;5H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[24;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */[23;5H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocabを宣言  [24;1H[93m    [m*/[23;5H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[24;1H[93m    [meads = 12, min_reduce = 1;[23;5H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */[24;5H[?12l[?25h[?25l
/[?12l[?25hcount[?25l[1;24r[1;1H[4M[1;25r[21;1H[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [22;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[24;1H[93m    [mlasses = 0;[25;1H[K[23;37H[?12l[?25h[?25l

/count[27m[m[H[2J[1;1H[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size[94m>>[m[2;1H[93m    [m以上の時 */
[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */
[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struu[5;1H[93m    [mct vocab_word)); /*  */
[93m133 [m  }
[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;
[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 
140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用い[19;1H[93m    [mて頻度順に並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替え[24;1H[93m    [mて文字列</s>を先頭に保つ */[13;39H[?12l[?25h[?25l[25;1H/count[18;53H[?12l[?25h[?25l[25;1H[1;24r[1;1H[8M[1;25r[17;1H[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);;[18;1H[93m    [m/* vocab[1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[24;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */[25;1H[K[23;41H[?12l[?25h[?25l

/count[24;17H[?12l[?25h[?25l
[1;24r[1;1H[2M[1;25r[23;1H[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未[24;1H[93m    [m満かつaが0でない時 */[25;1H[K[23;32H[?12l[?25h[?25l

/count[23;74H[?12l[?25h[?25l

[27m[m[H[2J[1;1H[93m185 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m186 [m  for (a = 0; a < vocab_size; a++) {
[93m187 [m    // Hash will be re-computed, as it is not actual
[93m188 [m    hash = GetWordHash(vocab[a].word);
[93m189 [m    while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m190 [m    vocab_hash[hash] = a;
[93m191 [m  }
[93m192 [m  fflush(stdout);
[93m193 [m  min_reduce++;
[93m194 [m}
[93m195 
196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffmaa[13;1H[93m    [mn木を作成 */
[93m197 [m// Frequent words will have short uniqe binary codes /* 高頻度の単語に短い一[15;1H[93m    [m意的な2進数を割当る */
[93m198 [mvoid CreateBinaryTree() { /* void関数CreateBinaryTree() */
[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];
[93m200 [m  char code[MAX_CODE_LENGTH]; /* char型code[最大コード長MAX_CODE_LENGTH] */
[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long lonn[20;1H[93m    [mg)); /* long long型ポインタcountに(vocab_size * 2 * 1) * (long long)分のメモ[21;1H[93m    [mリを確保 */
[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long loo[23;1H[93m    [mng)); /* long long型ポインタbinaryに(vocab_size * 2 * 1) * (long long)分のメ[24;1H[93m    [mモリを確保 */[12;50H[?12l[?25h[?25l[25;1H/count[19;18H[?12l[?25h[?25l[25;1H?[12;50H[?12l[?25h[?25l[25;1H/[19;18H[?12l[?25h[?25l[25;1H[20;32H[?12l[?25h[?25l[25;1H[1;24r[1;1H[5M[1;25r[20;1H[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[21;1H[93m    [mng long)); /* long long型ポインタparent_nodeに(vocab_size * 2 * 1) * (long ll[22;1H[93m    [mong)分のメモリを確保 */
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn; /* ポインタcount[94m>>[m[24;1H[93m    [mの0 <= a < vocab_size番目ににvocab[a].cnを代入 */[25;1H[K[23;40H[?12l[?25h[?25l

/[?12l[?25hvocab_size[?25l[24;16H[?12l[?25h[?25l
?[23;23H[?12l[?25h[?25l

[21;52H[?12l[?25h[?25l[25;1H[20;52H[?12l[?25h[?25l[25;1H[18;42H[?12l[?25h[?25l[25;1H[17;47H[?12l[?25h[?25l[25;1H[15;40H[?12l[?25h[?25l[25;1H[14;46H[?12l[?25h[?25l[25;1H[1;24r[1;1H[4L[1;25r[1;1H[93m186 [m  for (a = 0; a < vocab_size; a++) {
[93m187 [m    // Hash will be re-computed, as it is not actual
[93m188 [m    hash = GetWordHash(vocab[a].word);
[93m189 [m    while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;[24;1H[94m@                                                                               [m[25;1H[K[1;23H[?12l[?25h[?25l[25;1H?vocab_size[1;24r[1;1H[2L[1;25r[1;1H[93m184 [m  vocab_size = b;
[93m185 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[23;1H[94m@                                                                               [24;1H@                                                                               [m[25;1H[K[1;7H[?12l[?25h[?25l[25;1H?vocab_size[1;24r[1;1H[5L[1;25r[1;1H[93m179 [m  for (a = 0; a < vocab_size; a++) if (vocab[a].cn > min_reduce) {
[93m180 [m    vocab[b].cn = vocab[a].cn;
[93m181 [m    vocab[b].word = vocab[a].word;
[93m182 [m    b++;
[93m183 [m  } else free(vocab[a].word);[25;1H[K[1;23H[?12l[?25h[?25l[25;1H?vocab_size[1;24r[1;1H[10L[1;25r[1;1H[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));
[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 
175 [m// Reduces the vocabulary by removing infrequent tokens
[93m176 [mvoid ReduceVocab() {
[93m177 [m  int a, b = 0;
[93m178 [m  unsigned int hash;[25;1H[K[1;23H[?12l[?25h[?25l[25;1H?vocab_size[1;24r[1;1H[3L[1;25r[1;1H[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struu[2;1H[93m    [mct vocab_word));
[93m168 [m  // Allocate memory for the binary tree construction[25;1H[K[1;52H[?12l[?25h[?25l[25;1H?vocab_size[1;24r[1;1H[11L[1;25r[1;1H[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /*  [5;1H[93m    [mハッシュを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }[25;1H[K[1;28H[?12l[?25h[?25l[25;1H?vocab_size[1;11H[?12l[?25h[?25l[25;1H[1;24r[1;1H[7L[1;25r[1;1H[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[5;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未 [7;1H[93m    [m満かつaが0でない時 */[25;1H[K[1;14H[?12l[?25h[?25l[25;1H?vocab_size[1;24r[1;1H[3L[1;25r[1;1H[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);;[2;1H[93m    [m/* vocab[1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[25;1H[K[2;28H[?12l[?25h[?25l[25;1H?vocab_size[1;24H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */
[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */
[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size[94m>>[m[4;1H[93m    [m以上の時 */
[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */
[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struu[7;1H[93m    [mct vocab_word)); /*  */
[93m133 [m  }
[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;
[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 
140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用い[21;1H[93m    [mて頻度順に並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;[12;14H[?12l[?25h[?25l[25;1H?vocab_size[11;26H[?12l[?25h[?25l[25;1H[3;50H[?12l[?25h[?25l[25;1H[3;11H[?12l[?25h[?25l[25;1H[1;24H[?12l[?25h[?25l[25;1H[1;7H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */[25;1H[K[1;42H[?12l[?25h[?25l[25;1H?vocab_size[1;13H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコ[94m>>[m[2;1H[93m    [mピー */[25;1H[K[1;54H[?12l[?25h[?25l[25;1H?vocab_size[1;20H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個[2;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */[25;1H[K[2;53H[?12l[?25h[?25l[25;1H?vocab_size[1;13H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[2;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[4;1H[93m    [m);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boo[18;1H[93m    [mundaries /* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見[94m>>[m[19;1H[93m    [mなす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポイン[21;1H[93m    [mタfinが引数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にル[94m>>[m[24;1H[93m    [mープ終了 */[13;34H[?12l[?25h[?25l[25;1H?vocab_size[13;18H[?12l[?25h[?25l[25;1H[3;23H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m 36 [m};
[93m 37 
 38 [mchar train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[4;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */
[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[6;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */
[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocabを宣言  [8;1H[93m    [m*/
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[10;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [13;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[15;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {[13;27H[?12l[?25h[?25l[25;1H/vocab_size[1;24r[1;1H[8M[1;25r[17;1H[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[21;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[23;1H[93m    [m);
[93m 59 [m  i = 0;[25;1H[K[22;23H[?12l[?25h[?25l


/vocab_size[1;24r[1;1H[8M[1;25r[17;1H[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;[25;1H[K[24;18H[?12l[?25h[?25l
/vocab_size[24;34H[?12l[?25h[?25l
[27m[m[H[2J[1;1H[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[7;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[9;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[11;1H[93m    [mきい場合はlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個[13;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコ[94m>>[m[15;1H[93m    [mピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */
[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */
[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */
[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size[94m>>[m[20;1H[93m    [m以上の時 */
[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */
[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struu[23;1H[93m    [mct vocab_word)); /*  */
[93m133 [m  }[12;13H[?12l[?25h[?25l[25;1H/vocab_size[13;53H[?12l[?25h[?25l[25;1H[14;20H[?12l[?25h[?25l[25;1H[14;54H[?12l[?25h[?25l[25;1H[16;13H[?12l[?25h[?25l[25;1H[16;42H[?12l[?25h[?25l[25;1H[17;7H[?12l[?25h[?25l[25;1H[17;24H[?12l[?25h[?25l[25;1H[19;11H[?12l[?25h[?25l[25;1H[19;50H[?12l[?25h[?25l[25;1H[1;24r[1;1H[3M[1;25r[22;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;[25;1H[K[24;26H[?12l[?25h[?25l
/vocab_size[1;24r[24;1H
[1;25r[24;1H[93m137 [m  return vocab_size - 1;[25;1H[K[24;14H[?12l[?25h[?25l
/vocab_size[27m[m[H[2J[1;1H[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用い[6;1H[93m    [mて頻度順に並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替え[11;1H[93m    [mて文字列</s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);;[13;1H[93m    [m/* vocab[1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[19;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未[21;1H[93m    [m満かつaが0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {[12;24H[?12l[?25h[?25l[25;1H/vocab_size[13;28H[?12l[?25h[?25l[25;1H[15;14H[?12l[?25h[?25l[25;1H[22;11H[?12l[?25h[?25l


[22;28H[?12l[?25h[?25l


[1;24r[1;1H[11M[1;25r[14;1H[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /*  [15;1H[93m    [mハッシュを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }
[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struu[23;1H[93m    [mct vocab_word));
[93m168 [m  // Allocate memory for the binary tree construction[25;1H[K[22;52H[?12l[?25h[?25l


/vocab_size[1;24r[1;1H[2M[1;25r[23;1H[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));[25;1H[K[23;23H[?12l[?25h[?25l

/vocab_size[1;24r[1;1H[9M[1;25r[16;1H[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 
175 [m// Reduces the vocabulary by removing infrequent tokens
[93m176 [mvoid ReduceVocab() {
[93m177 [m  int a, b = 0;
[93m178 [m  unsigned int hash;
[93m179 [m  for (a = 0; a < vocab_size; a++) if (vocab[a].cn > min_reduce) {[25;1H[K[24;23H[?12l[?25h[?25l
/vocab_size[1;24r[1;1H[5M[1;25r[20;1H[93m180 [m    vocab[b].cn = vocab[a].cn;
[93m181 [m    vocab[b].word = vocab[a].word;
[93m182 [m    b++;
[93m183 [m  } else free(vocab[a].word);
[93m184 [m  vocab_size = b;[25;1H[K[24;7H[?12l[?25h[?25l
/vocab_size[1;24r[1;1H[2M[1;25r[23;1H[93m185 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m186 [m  for (a = 0; a < vocab_size; a++) {[25;1H[K[24;23H[?12l[?25h[?25l
/vocab_size[27m[m[H[2J[1;1H[93m193 [m  min_reduce++;
[93m194 [m}
[93m195 
196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffmaa[5;1H[93m    [mn木を作成 */
[93m197 [m// Frequent words will have short uniqe binary codes /* 高頻度の単語に短い一 [7;1H[93m    [m意的な2進数を割当る */
[93m198 [mvoid CreateBinaryTree() { /* void関数CreateBinaryTree() */
[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];
[93m200 [m  char code[MAX_CODE_LENGTH]; /* char型code[最大コード長MAX_CODE_LENGTH] */
[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long lonn[12;1H[93m    [mg)); /* long long型ポインタcountに(vocab_size * 2 * 1) * (long long)分のメモ[13;1H[93m    [mリを確保 */
[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long loo[15;1H[93m    [mng)); /* long long型ポインタbinaryに(vocab_size * 2 * 1) * (long long)分のメ[16;1H[93m    [mモリを確保 */
[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[18;1H[93m    [mng long)); /* long long型ポインタparent_nodeに(vocab_size * 2 * 1) * (long ll[19;1H[93m    [mong)分のメモリを確保 */
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn; /* ポインタcount[94m>>[m[21;1H[93m    [mの0 <= a < vocab_size番目ににvocab[a].cnを代入 */
[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15; /* ポインタ [23;1H[93m    [mcountのvocab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */
[93m206 [m  pos1 = vocab_size - 1;[11;46H[?12l[?25h[?25l[34Cnn[12;1H[93m [m[14;46H[46m([m[33Coo[15;1H[93m [m[6C[46m)[14;46H[?12l[?25h[?25l[m([33Coo[15;1H[93m [m[6C)[17;46H[?12l[?25h[20;46H[22;46H[24;28H[?25l[1;24r[24;1H
[1;25r[24;1H[93m207 [m  pos2 = vocab_size;[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m208 [m  // Following algorithm constructs the Huffman tree by adding one node at aa[24;1H[93m    [m time /* ノードをa回追加してHuffman木を構成するアルゴリズム */[23;46H[?12l[?25h[22;24H[21;28H[19;46H[21;28H[22;24H[23;46H[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m209 [m  for (a = 0; a < vocab_size - 1; a++) {
[93m210 [m    // First, find two smallest nodes 'min1, min2' /* まず2つの最小ノード'mi[24;1H[94m@                                                                               [23;44H[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[22;1H[93m210 [m    // First, find two smallest nodes 'min1, min2' /* まず2つの最小ノード'mii[23;1H[93m    [mn1, min2'を探す */
[93m211 [m    if (pos1 >= 0) { /* pos1(最初はvocab_size-1)が非負の時 */[22;46H[?12l[?25h[24;46H[?25l[1;24r[24;1H
[1;25r[24;1H[93m212 [m      if (count[pos1] < count[pos2]) {[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m213 [m[7C min1i = pos1;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m214 [m[7C pos1--;[?12l[?25h[23;25H[22;42H[23;25H[24;19H[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m215 [m      } else {
[93m216 [m[7C min1i = pos2;
[93m217 [m[7C pos2++;[22;18H[?12l[?25h[23;25H[22;18H[21;19H[20;25H[?25l[19;42H[46m{[22;11H}[19;42H[?12l[?25h[?25l[m[25;1H[1m-- INSERT --[19;43H[?12l[?25h[?25l[m{[22;11H}[19;44H[?12l[?25h[?25l ?[?12l[?25h[?25l[19;44H[K[19;44H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h */[?25l c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lut */[?12l[?25h[?25lu */[19;53H[K[19;50H[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25lt[ */[?12l[?25h[?25l[p */[?12l[?25h[?25lpo */[?12l[?25h[?25los */[?12l[?25h[?25ls1 */[?12l[?25h[?25l[46m[[mpos1[46m][m */[?12l[?25h[?25l[pos1]< */[?12l[?25h[?25l<c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25lt[ */[?12l[?25h[?25l[p */[?12l[?25h[?25lpo */[?12l[?25h[?25los */[?12l[?25h[?25ls2 */[?12l[?25h[?25l[46m[[mpos2[46m][m */[?12l[?25h[?25l[pos2]( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l[?12l[?25h[?25l[46m([m最初は[46m)[m */[19;77H[?12l[?25h[?25l[20;24r[20;1H[L[1;25r[19;77Hp[46m)[m **[20;1H[93m    [m/[19;78H[?12l[?25h[?25lpo[46m)[m  [20;1H[93m    [m*/[19;79H[?12l[?25h[?25los[46m))[m[20;1H[93m    [m */[19;80H[?12l[?25h[?25ls11[20;1H[93m    [m[46m)[m */[?12l[?25h[?25l[93m [m=[46m)[m */[?12l[?25h[?25l=v[46m)[m */[?12l[?25h[?25lvo[46m)[m */[?12l[?25h[?25loc[46m)[m */[?12l[?25h[?25lca[46m)[m */[?12l[?25h[?25lab[46m)[m */[?12l[?25h[?25lb_[46m)[m */[?12l[?25h[?25l_s[46m)[m */[?12l[?25h[?25lsi[46m)[m */[?12l[?25h[?25liz[46m)[m */[?12l[?25h[?25lze[46m)[m */[?12l[?25h[?25le-[46m)[m */[?12l[?25h[?25l-1[46m)[m */[?12l[?25h[?25l1,[46m)[m */[?12l[?25h[?25l,v[46m)[m */[?12l[?25h[?25l,[46m)[m */[20;23H[K[20;19H[?12l[?25h[?25l,p[46m)[m */[?12l[?25h[?25lpo[46m)[m */[?12l[?25h[?25los[46m)[m */[?12l[?25h[?25ls2[46m)[m */[?12l[?25h[?25l2=[46m)[m */[?12l[?25h[?25l[19;70H([9C11[20;1H[93m [m[22C)[?12l[?25h[?25l, pos2=) */[20;20H[?12l[?25hpos2[?25l2 =) */[?12l[?25h[?25l[19;70H[46m([m[9C11[20;1H[93m [m[24C[46m)[?12l[?25h[?25l[m= [46m)[m */[?12l[?25h[?25l v[46m)[m */[?12l[?25h[?25lvo[46m)[m */[?12l[?25h[?25loc[46m)[m */[?12l[?25h[?25lca[46m)[m */[?12l[?25h[?25lab[46m)[m */[?12l[?25h[?25lb_[46m)[m */[?12l[?25h[?25l_s[46m)[m */[?12l[?25h[?25lsi[46m)[m */[?12l[?25h[?25liz[46m)[m */[?12l[?25h[?25lze[46m)[m */[?12l[?25h[?25l[19;70H([9C11[20;1H[93m [m[35C)[?12l[?25h[?25le -1, pos2 = vocab_size) */[20;17H[?12l[?25h-[?25l- 1, pos2 = vocab_size) */[20;19H[?12l[?25h[?25l= vocab_size - 1, pos2 = vocab_size) */[20;7H[?12l[?25h[19;80H[20;5H[?25l[19;79Hs==[20;1H[93m    [m vocab_size - 1, pos2 = vocab_size) */[20;43H[K[19;80H[?12l[?25h[20;5H[19;80H[20;5H[?25l[19;79Hs  [20;1H[93m    [mvocab_size - 1, pos2 = vocab_size) */[20;42H[K[19;80H[?12l[?25h[?25ls11[20;1H[93m    [m vocab_size - 1, pos2 = vocab_size) */[20;5H[?12l[?25h[?25l  vocab_size - 1, pos2 = vocab_size) */[20;6H[?12l[?25h[?25l = vocab_size - 1, pos2 = vocab_size) */[20;7H[?12l[?25h[19;80H[20;5H[?25l[19;79Hs  [20;1H[93m    [m= vocab_size - 1, pos2 = vocab_size) */[20;44H[K[19;80H[?12l[?25h[?25ls11[20;1H[93m    [m = vocab_size - 1, pos2 = vocab_size) */[20;5H[?12l[?25h[21;26H[22;20H[21;26H[20;5H[18;66H[20;5H[19;80H[?25l[46m([m[9C11[20;1H[93m [m[39C[46m)[19;71H[?12l[?25h[?25l[m[9C11[20;1H[93m [19;70H[?12l[?25h[?25l[m[46m[[mpos2[46m][m([9C11[20;1H[93m [m[39C)[19;69H[?12l[?25h[?25l[pos2][46m([m[9C11[20;1H[93m [m[39C[46m)[19;70H[?12l[?25h[?25l[m[10C11[20;1H[93m [19;71H[?12l[?25h[?25l[m([9C11[20;1H[93m [m[39C)[19;73H[?12l[?25h[2C[2Cpos[20;5H = vocab_size - 1, pos2 = vocab_siz[?25l[19;70H[46m([m[9C11[20;1H[93m [m[39C[46m)[?12l[?25h[?25l)[?12l[?25h[?25l[m[19;70H([9C11[20;1H[93m [m[39C)の */[?12l[?25h[?25l時 */[?12l[?25h[?25l[19;70H[46m([m[9C11[20;1H[93m [m[39C[46m)[?12l[?25h[?25l[?12l[?25h[?25l[m[19;70H([9C11[20;1H[93m [m[39C)[?12l[?25h[19;80H[?25l[46m([m[9C11[20;1H[93m [m[39C[46m)[19;71H[?12l[?25h[?25l[m[9C11[20;1H[93m [19;70H[?12l[?25h[?25l[m[46m[[mpos2[46m][m([9C11[20;1H[93m [m[39C)[19;69H[?12l[?25h[?25l[pos2][10C11[20;1H[93m [19;68H[?12l[?25h[?25l[m[46m[[mpos2[46m][m[10C11[20;1H[93m [19;65H[?12l[?25h[?25l[m[15C11[20;1H[93m [19;64H[?12l[?25h[?25l[m[pos2][10C11[20;1H[93m [19;63H[?12l[?25h[?25l[m< count[pos2](最初はposs[20;1H[93m    [m1 = vocab_size - 1, pos2 = vocab_size)の時 */[19;60H[?12l[?25h[?25l[19;52H[46m[[mpos1[46m][m[22Css[20;1H[93m [19;58H[?12l[?25h[?25l[m[pos1] < count[pos2](最初はpoo[20;1H[93m    [ms1 = vocab_size - 1, pos2 = vocab_size)の時 */[19;59H[?12l[?25h[21;26H[22;20H[?25l[23;19H[?12l[?25h[24;26H[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m217 [m[7C pos2++;
[93m218 [m      }
[93m219 [m    } else {[22;20H[?12l[?25h[21;26H[?25l[20;18H[46m{[23;11H}[20;19H[?12l[?25h[?25l[m{[23;11H}[19;20H[?12l[?25h[18;26H[?25l [?12l[?25h[?25l ?[?12l[?25h[?25l?:[?12l[?25h[?25l[18;28H[K[18;28H[?12l[?25h[?25l[18;27H[K[18;27H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l m[?12l[?25h[?25lmi[?12l[?25h[?25lin[?12l[?25h[?25ln1[?12l[?25h[?25l1i[?12l[?25h[19;20H[?25l[20;18H[46m{[23;11H}[20;19H[?12l[?25h[?25l[m{[23;11H}[21;26H[?12l[?25h[22;20H[?25l[20;18H[46m{[23;11H}[?12l[?25h[?25l[m[20;18H{[23;11H}[24;17H[?12l[?25h[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m220 [m      min1i = pos2;
[93m221 [m      pos2++;
[93m222 [m    }[22;24H[?12l[?25h[23;18H[?25l[21;16H[46m{[24;9H}[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[19;16H{[22;9H}
[93m223 [m    if (pos1 >= 0) {
[93m224 [m      if (count[pos1] < count[pos2]) {[23;25H[?12l[?25h[?25l[24;34H[46m[[mpos2[46m][?12l[?25h[?25l[m[pos2][23;25H[?12l[?25h[?25l[19;16H[46m{[22;9H}[?12l[?25h[?25l[m[19;16H{[22;9H}[21;18H[?12l[?25h[20;24H[?25l[19;16H[46m{[22;9H}[19;17H[?12l[?25h[?25l[15;18H{[18;11H}[m[19;16H{[22;9H}[18;12H[?12l[?25h[?25l[15;18H{[18;11H}[17;20H[?12l[?25h[16;26H[?25l[15;18H[46m{[18;11H}[15;19H[?12l[?25h[?25l[m{[18;11H}[14;20H[?12l[?25h[13;35H[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[25;1H[K[13;37H[?25l[?12l[?25h[?25l[25;1H/[?12l[?25hmin1i[?25l[16;13H[?12l[?25h[?25l[25;1H?[13;30H[?12l[?25h[?25l[25;1H[13;13H[?12l[?25h[?25l[25;1H[1;24r[1;1H[13L[1;25r[1;1H[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];
[93m200 [m  char code[MAX_CODE_LENGTH]; /* char型code[最大コード長MAX_CODE_LENGTH] */
[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long lonn[4;1H[93m    [mg)); /* long long型ポインタcountに(vocab_size * 2 * 1) * (long long)分のメモ[5;1H[93m    [mリを確保 */
[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long loo[7;1H[93m    [mng)); /* long long型ポインタbinaryに(vocab_size * 2 * 1) * (long long)分のメ[8;1H[93m    [mモリを確保 */
[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[10;1H[93m    [mng long)); /* long long型ポインタparent_nodeに(vocab_size * 2 * 1) * (long ll[11;1H[93m    [mong)分のメモリを確保 */
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn; /* ポインタcount[94m>>[m[13;1H[93m    [mの0 <= a < vocab_size番目ににvocab[a].cnを代入 */[24;1H[94m@                                                                               [m[25;1H[K[1;26H[?12l[?25hmin1i, min2i, pos1, pos2, poin[?25lt[46m[[15C][1;57H[?12l[?25h[?25l[m[[15C][1;58H[?12l[?25hMAX_CODE_LENGT[?25l[1;57H[46m[[15C][?12l[?25h[?25l[m[1;57H[[15C][?12l[?25h[?25l[25;1H/min1i[1;24r[1;1H[2M[1;25r[22;1H[93m212 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpoo[23;1H[93m    [ms1 = vocab_size - 1, pos2 = vocab_size)の時 */
[93m213 [m[7C min1i = pos1; /* min1i */[25;1H[K[24;13H[?12l[?25hmin1i = pos1; /* min1i[?25l
[1m-- INSERT --[24;31H[?12l[?25h[?25l[m lmin1i */[24;31H[?12l[?25h[?25llomin1i */[24;32H[?12l[?25h[?25lonmin1i */[24;33H[?12l[?25h[?25lngmin1i */[24;34H[?12l[?25h[?25lg min1i */[24;35H[?12l[?25h[?25l lmin1i */[24;36H[?12l[?25h[?25llomin1i */[24;37H[?12l[?25h[?25lonmin1i */[24;38H[?12l[?25h[?25lngmin1i */[24;39H[?12l[?25h[?25lg型min1i */[24;41H[?12l[?25hmin1i[?25liに */[?12l[?25h[?25lp */[?12l[?25h[?25lpo */[?12l[?25h[?25los */[?12l[?25h[?25ls1 */[?12l[?25h[?25l1を */[?12l[?25h[?25l代入 */[?12l[?25h[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m214 [m[7C pos1--;
[93m215 [m      } else {
[93m216 [m[7C min1i = pos2;[22;20H[?12l[?25h[?25l[23;19H[?12l[?25h[24;26H[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m217 [m[7C pos2++;
[93m218 [m      }
[93m219 [m    } else {[22;20H[?12l[?25h[21;26H[?25l[20;18H[46m{[23;11H}[20;19H[?12l[?25h[?25l[m{[23;11H}[20;20H[?12l[?25h[?25l .[?12l[?25h[?25l[20;20H[K[20;20H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25lt[ */[?12l[?25h[?25l[p */[?12l[?25h[?25lpo */[?12l[?25h[?25los */[?12l[?25h[?25ls1 */[?12l[?25h[?25l[46m[[mpos1[46m][m */[?12l[?25h[?25l[pos1]  */[?12l[?25h[?25l > */[?12l[?25h[?25l>= */[?12l[?25h[?25l  */[?12l[?25h[?25l c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25lt[ */[?12l[?25h[?25l[p */[?12l[?25h[?25lpo */[?12l[?25h[?25los */[?12l[?25h[?25ls2 */[?12l[?25h[?25l[46m[[mpos2[46m][m */[?12l[?25h[?25l[pos2]の */[?12l[?25h[?25l時 */[?12l[?25h[19;20H[20;53H[21;26H[22;20H[?25l[20;18H[46m{[23;11H}[?12l[?25h[?25l[m[20;18H{[23;11H}[24;17H[?12l[?25h[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m220 [m      min1i = pos2;
[93m221 [m      pos2++;
[93m222 [m    }[22;24H[?12l[?25h[?25l[21;16H[46m{[24;9H}[21;17H[?12l[?25h[?25l[17;18H{[20;11H}[m[21;16H{[24;9H}[20;12H[?12l[?25h[?25l[17;18H{[20;11H}[19;20H[?12l[?25h[18;26H[17;53H[16;20H[15;52H[?25l[13;52H[46m[[mpos1[46m][m[22Coo[14;1H[93m [13;53H[?12l[?25h[?25l[m[12;33H[46m([18C)[m[13;52H[pos1][22Coo[14;1H[93m [12;53H[?12l[?25h[?25l[m[12;33H([18C)[13;52H[46m[[mpos1[46m][m[22Coo[14;1H[93m [13;53H[?12l[?25h[?25l[m[pos1][22Coo[14;1H[93m [15;52H[?12l[?25h[16;20H[17;53H[18;26H[19;20H[?25l[m[17;18H[46m{[20;11H}[?12l[?25h[?25l[m[17;18H{[20;11H}[21;16H[46m{[24;9H}[21;17H[?12l[?25h[?25l[m{[24;9H}[21;18H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*?[?12l[?25h[?25l[21;23H[K[21;23H[?12l[?25h[?25l*/[?12l[?25h [?25l p */[?12l[?25h[?25lpo */[?12l[?25h[?25los */[?12l[?25h[?25ls1 */[?12l[?25h[?25l1が */[?12l[?25h[?25l負 */[?12l[?25h[?25lの */[?12l[?25h[?25l時 */[?12l[?25h[22;24H[23;18H[?25l[21;16H[46m{[24;9H}[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[19;16H{[22;9H}
[93m223 [m    if (pos1 >= 0) {
[93m224 [m      if (count[pos1] < count[pos2]) {[23;25H[?12l[?25h[24;33H[?25l[23;25H[?12l[?25h[24;33H[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m225 [m[7C min2i = pos1;
[93m226 [m[7C pos1--;[23;26H[?12l[?25h[24;20H[23;26H[22;33H[23;26H[24;20H[?25l[1;24r[24;1H
[1;25r[24;1H[93m227 [m      } else {[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m228 [m[7C min2i = pos2;[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m229 [m[7C pos2++;
[93m230 [m      }[23;20H[?12l[?25h[?25l[21;18H[46m{[24;11H}[?12l[?25h[?25l[m[21;18H{[24;11H}[23;20H[?12l[?25h[22;26H[?25l[21;18H[46m{[24;11H}[21;19H[?12l[?25h[?25l[m{[24;11H}[20;20H[?12l[?25h[19;26H[18;33H[19;26H[20;20H[?25l[21;18H[46m{[24;11H}[21;19H[?12l[?25h[?25l[m{[24;11H}[22;26H[?12l[?25h[23;20H[?25l[21;18H[46m{[24;11H}[?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[20;18H{[23;11H}
[93m231 [m    } else {[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m232 [m      min2i = pos2;
[93m233 [m      pos2++;[23;24H[?12l[?25h[24;18H[?25l[1;24r[24;1H
[1;25r[21;16H[46m{[m


[93m234 [m    [46m}[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[19;16H{[22;9H}
[93m235 [m    count[vocab_size + a] = count[min1i] + count[min2i];
[93m236 [m    parent_node[min1i] = vocab_size + a;[23;33H[?12l[?25h[24;33H[23;33H[?25l[19;16H[46m{[22;9H}[?12l[?25h[?25l[m[19;16H{[22;9H}[21;18H[?12l[?25h[20;24H[?25l[19;16H[46m{[22;9H}[19;17H[?12l[?25h[?25l[15;18H{[18;11H}[m[19;16H{[22;9H}[18;12H[?12l[?25h[?25l[15;18H{[18;11H}[17;20H[?12l[?25h[16;26H[?25l[15;18H[46m{[18;11H}[15;19H[?12l[?25h[?25l[m{[18;11H}[14;20H[?12l[?25h[13;26H[12;33H[?25l[11;24H[46m{[19;9H}[11;25H[?12l[?25h[?25l[7;16H{[10;9H}[m[11;24H{[19;9H}[10;10H[?12l[?25h[?25l[7;16H{[10;9H}[9;18H[?12l[?25h[8;24H[7;33H[8;24H[9;18H[?25l[7;16H[46m{[10;9H}[?12l[?25h[?25l[m[7;16H{[10;9H}[11;24H[46m{[19;9H}[11;25H[?12l[?25h[?25l[m{[19;9H}[12;33H[?12l[?25h[13;26H[14;20H[?25l[15;18H[46m{[18;11H}[15;19H[?12l[?25h[?25l[m{[18;11H}[16;26H[?12l[?25h[17;20H[?25l[15;18H[46m{[18;11H}[?12l[?25h[?25l[m[15;18H{[18;11H}[19;16H[46m{[22;9H}[19;17H[?12l[?25h[?25l[m{[22;9H}[20;24H[?12l[?25h[21;18H[?25l[19;16H[46m{[22;9H}[?12l[?25h[?25l[m[19;16H{[22;9H}[23;33H[?12l[?25h[24;33H[?25l[1;24r[24;1H
[1;25r[24;1H[93m237 [m    parent_node[min2i] = vocab_size + a;[24;33H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m238 [m    binary[min2i] = 1;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m239 [m  }[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m240 [m  // Now assign binary code to each vocabulary word[24;33H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m241 [m  for (a = 0; a < vocab_size; a++) {[24;33H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m242 [m    b = a;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m243 [m    i = 0;[?12l[?25h[23;15H[22;33H[21;33H[?25l[20;8H[?12l[?25h[19;27H[18;33H[17;33H[16;33H[?25l[12;16H[46m{[15;9H}[?12l[?25h[?25l[m[12;16H{[15;9H}[14;18H[?12l[?25h[13;24H[?25l[12;16H[46m{[15;9H}[12;17H[?12l[?25h[?25l[8;18H{[11;11H}[m[12;16H{[15;9H}[11;12H[?12l[?25h[?25l[8;18H{[11;11H}[10;20H[?12l[?25h[9;26H[?25l[8;18H[46m{[11;11H}[8;19H[?12l[?25h[?25l[m{[11;11H}[7;20H[?12l[?25h[6;26H[5;33H[?25l[4;24H[46m{[12;9H}[4;25H[?12l[?25h[?25l[m{[12;9H}[3;10H[?12l[?25h[2;18H[1;24H[?25l[1;24r[1;1H[L[1;25r[1;1H[93m219 [m    } else { /* pos1が負の時 */[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m218 [m      }[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m217 [m[7C pos2++;[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m216 [m[7C min1i = pos2;[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m215 [m      } else { /* count[46m[[mpos1[46m][m >= count[pos2]の時 */[1;33H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m214 [m[7C pos1--;[2;28H[pos1][1;20H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m213 [m[7C min1i = pos1; /* long long型min1iにpos1を代入 */[1;33H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m212 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpoo[2;1H[93m    [ms1 = vocab_size - 1, pos2 = vocab_size)の時 */[1;33H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m211 [m    if (pos1 >= 0) { /* pos1[46m([m最初はvocab_size-1[46m)[mが非負の時 */[1;33H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m210 [m    // First, find two smallest nodes 'min1, min2' /* まず2つの最小ノード'mii[2;1H[93m    [mn1, min2'を探す */[3;33H([18C)[1;33H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m209 [m  for (a = 0; a < vocab_size - 1; a++) {[1;33H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m208 [m  // Following algorithm constructs the Huffman tree by adding one node at aa[2;1H[93m    [m time /* ノードをa回追加してHuffman木を構成するアルゴリズム */[1;33H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m207 [m  pos2 = vocab_size;[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m206 [m  pos1 = vocab_size - 1;[?12l[?25h[2;25H[3;33H[5;33H[6;33H[?25l[47Cii[7;1H[93m [m[8;33H[46m([18C)[8;33H[?12l[?25h[?25l[m([18C)[9;33H[?12l[?25h[11;33H[12;20H[?25l[13;28H[46m[[mpos1[46m][?12l[?25h[?25l[m[pos1][14;26H[?12l[?25h[15;20H[?25l[13;18H[46m{[16;11H}[?12l[?25h[?25l[m[13;18H{[16;11H}[17;33H[?12l[?25h[18;24H[19;18H[18;24H[19;18H[?25l[17;16H[46m{[20;9H}[?12l[?25h[?25l[m[17;16H{[20;9H}[21;25H[?12l[?25h[22;33H[23;26H[22;33H[?25lt[46m[[mpos2[46m][?12l[?25h[?25l[[?12l[?25h[?25l[m[pos2][?12l[?25hos[?25l[46m[[mpos2[46m][?12l[?25h[?25l[22;14H([m[19C[pos2][46m)[?12l[?25h[?25l)[?12l[?25h[?25l[m[22;14H([25C) [?12l[?25h[?25l{[?12l[?25h[?25l [?12l[?25h[?25l /* count[pos1] < count[pos2](最初はpoo[23;1H[93m    [mo[23;13H[K[24;2H[93m25[m[4C s1 = vocab_size - 1, pos2 = vocab_size)の時 */[?12l[?25h[22;50H[24;50H[?25l[22;72H[46m([m[7Coo[23;1H[93m [m[24;47H[46m)[?12l[?25h[?25l[?12l[?25h[?25l[m[22;72H([7Coo[23;1H[93m [m[24;47H)[?12l[?25h[?25l s1 = vocab_size - 1, pos2 = vocab_size)の時 */[24;54H[K[24;8H[?12l[?25h[?25l s1 = vocab_size - 1, pos2 = vocab_size)の時 */[24;53H[K[24;7H[?12l[?25h[?25l s1 = vocab_size - 1, pos2 = vocab_size)の時 */[24;52H[K[24;6H[?12l[?25h[?25l[93m [ms1 = vocab_size - 1, pos2 = vocab_size)の時 */[24;51H[K[24;5H[?12l[?25h[?25l[23;5Hos1 = vocab_size - 1, pos2 = vocab_size)の時 */[24;4H[93m [m        min2i = pos1;[24;26H[K[23;6H[?12l[?25hs1 = vocab_size - 1,[24;26H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [?25l l */[?12l[?25h[?25llo */[?12l[?25h[?25lon */[?12l[?25h[?25lng */[?12l[?25h[?25l  */[?12l[?25h[?25l g */[?12l[?25h[?25l  */[24;38H[K[24;35H[?12l[?25h[?25l l */[?12l[?25h[?25llo */[?12l[?25h[?25lon */[?12l[?25h[?25lng */[?12l[?25h[?25lg型 */[?12l[?25h[?25lm */[?12l[?25h[?25lmi */[?12l[?25h[?25lin */[?12l[?25h[?25ln2 */[?12l[?25h[?25l2i */[?12l[?25h[?25liに */[?12l[?25h[?25lp */[?12l[?25h[?25lpo */[?12l[?25h[?25los */[?12l[?25h[?25ls1 */[?12l[?25h[?25l1を */[?12l[?25h[?25l代入 */[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m226 [m[7C pos1--;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m227 [m      } else {[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m228 [m[7C min2i = pos2;
[93m229 [m[7C pos2++;[23;26H[?12l[?25h[?25l[22;19H[?12l[?25h[21;20H[?25l[22;19H[?12l[?25h[?25l [?12l[?25h[?25l /* count[pos1] >= count[pos2]の時 */[?12l[?25h[23;26H[24;20H[?25l[1;24r[24;1H
[1;25r[21;18H[46m{[m


[93m230 [m      [46m}[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[19;18H{[22;11H}
[93m231 [m    } else {
[93m232 [m      min2i = pos2;[23;17H[?12l[?25h[24;24H[?25l[23;17H[?12l[?25h[?25l [?12l[?25h[?25l /* pos1が負の時 */[?12l[?25h[24;24H[?25l[1;24r[24;1H
[1;25r[24;1H[93m233 [m      pos2++;[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[20;16H[46m{[m


[93m234 [m    [46m}[m
[93m235 [m    count[vocab_size + a] = count[min1i] + count[min2i];[23;10H[?12l[?25h[?25l[20;16H{[23;9H}[24;36H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m236 [m    parent_node[min1i] = vocab_size + a;[24;36H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m237 [m    parent_node[min2i] = vocab_size + a;[24;36H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m238 [m    binary[min2i] = 1;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m239 [m  }[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m240 [m  // Now assign binary code to each vocabulary word[24;36H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m241 [m  for (a = 0; a < vocab_size; a++) {[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m242 [m    b = a;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m243 [m    i = 0;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m244 [m    while (1) {[?12l[?25h[23;15H[22;15H[21;36H[20;36H[?25l[19;8H[?12l[?25h[18;27H[17;36H[16;36H[17;36H[18;27H[?25l[19;8H[?12l[?25h[20;36H[?25l[19;8H[?12l[?25h[18;27H[17;36H[16;36H[15;36H[?25l[11;16H[46m{[14;9H}[?12l[?25h[?25l[m[11;16H{[14;9H}[15;36H[?12l[?25h[?25l[11;16H[46m{[14;9H}[?12l[?25h[?25l[m[11;16H{[14;9H}[15;36H[?12l[?25h[?25l[11;16H[46m{[14;9H}[?12l[?25h[m[25;1H[K[14;9H[?25l[?12l[?25h[?25l[25;1H[1m-- INSERT --[14;10H[?12l[?25h[?25l[m[11;16H{[14;9H}[15;10H[?12l[?25h[?25l[11;16H[46m{[14;9H}[?12l[?25h[?25l[m[11;16H{[14;9H}[13;10H[?12l[?25h[12;10H[?25l[2;24H[46m{[11;9H}[?12l[?25h[?25l[m[2;24H{[11;9H}[12;10H[?12l[?25h [13;11H[?25l[11;16H[46m{[14;9H}[?12l[?25h[?25l[m[11;16H{[14;9H}[15;11H[?12l[?25hun[?25lt[46m[[14C][15;14H[?12l[?25h[?25l[[?12l[?25h[?25l[m[[14C][15;16H[?12l[?25hocab_size + [?25l[15;14H[46m[[14C][?12l[?25h[?25l][?12l[?25h[?25l[m[15;14H[[14C] [?12l[?25h= coun[?25lt[46m[[mmin1i[46m][15;38H[?12l[?25h[?25l[[?12l[?25h[?25l[m[min1i][?12l[?25hin1[?25l[46m[[mmin1i[46m][?12l[?25h[?25l][?12l[?25h[?25l[m[15;38H[min1i] [?12l[?25h+ coun[?25lt[46m[[mmin2i[46m][15;53H[?12l[?25h[?25l[[?12l[?25h[?25l[m[min2i][?12l[?25hin2[?25l[46m[[mmin2i[46m][?12l[?25h[?25l][?12l[?25h[?25l[m[15;53H[min2i];[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25lt[ */[?12l[?25h[?25l[v */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_s */[15;78H[?12l[?25h[?25l[16;24r[16;1H[L[1;25r[15;77Hsi **[16;1H[93m    [m/[15;79H[?12l[?25h[?25liz  [16;1H[93m    [m*/[15;80H[?12l[?25h[?25lzee[16;1H[93m    [m */[?12l[?25h[?25l[15;79Hz  [16;1H[93m    [m*/[16;7H[K[15;80H[?12l[?25h[?25lzee[16;1H[93m    [m */[?12l[?25h[?25l  */[?12l[?25h[?25l + */[?12l[?25h[?25l+a */[?12l[?25h[?25l[15;70H[46m[[m[9Cee[16;1H[93m [m[5Ca[46m][m */[?12l[?25h[?25l[?12l[?25h[?25l[15;70H[[9Cee[16;1H[93m [m[6C][?12l[?25h[?25l+ a] */[?12l[?25h[?25l[15;70H[46m[[m[9Cee[16;1H[93m [m[7C[46m][?12l[?25h[?25l][?12l[?25h[?25l[m[15;70H[[9Cee[16;1H[93m [m[7C]に */[?12l[?25h[?25lc */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25lt[ */[?12l[?25h[?25l[m */[?12l[?25h[?25lmi */[?12l[?25h[?25lin */[?12l[?25h[?25ln1 */[?12l[?25h[?25l1i */[?12l[?25h[?25l[46m[[mmin1i[46m][m */[?12l[?25h[?25l[16;17H[min1i]  */[?12l[?25h[?25l + */[?12l[?25h[?25l+m */[?12l[?25h[?25l+ */[16;29H[K[16;26H[?12l[?25h[?25l  */[?12l[?25h[?25l c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25lt[ */[?12l[?25h[?25l[m */[?12l[?25h[?25lmi */[?12l[?25h[?25lin */[?12l[?25h[?25ln2 */[?12l[?25h[?25l2i */[?12l[?25h[?25l[46m[[mmin2i[46m][m */[?12l[?25h[?25l[16;32H[min2i]を */[?12l[?25h[?25l代入 */[?12l[?25h[17;45H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l  */[?12l[?25h[?25l m */[?12l[?25h[?25lmi */[?12l[?25h[?25lin */[?12l[?25h[?25ln1 */[?12l[?25h[?25l1i */[?12l[?25h[?25liの */[?12l[?25h[?25l親 */[?12l[?25h[?25lノード */[?12l[?25h[?25lに */[?12l[?25h[?25l  */[?12l[?25h[?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_s */[?12l[?25h[?25lsi */[?12l[?25h[?25liz */[?12l[?25h[?25lze */[?12l[?25h[?25l  */[17;78H[?12l[?25h[?25l[18;24r[18;1H[L[1;25r[17;77H + **[18;1H[93m    [m/[17;79H[?12l[?25h[?25l   [18;1H[93m    [m*/[17;80H[?12l[?25h[?25l aa[18;1H[93m    [m */[?12l[?25h[?25l[93m [mを */[?12l[?25h[?25l代入 */[?12l[?25h[19;45H[20;27H[19;45H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l m */[?12l[?25h[?25lmi */[?12l[?25h[?25lin */[?12l[?25h[?25ln2 */[?12l[?25h[?25l2i */[?12l[?25h[?25liの */[?12l[?25h[?25l親ノード */[?12l[?25h[?25lに */[?12l[?25h[?25l  */[?12l[?25h[?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_s */[?12l[?25h[?25lsi */[?12l[?25h[?25liz */[?12l[?25h[?25lze */[?12l[?25h[?25l  */[19;78H[?12l[?25h[?25l[20;24r[20;1H[L[1;25r[19;77H + **[20;1H[93m    [m/[19;79H[?12l[?25h[?25l   [20;1H[93m    [m*/[19;80H[?12l[?25h[?25l aa[20;1H[93m    [m */[?12l[?25h[?25l[93m [mを */[?12l[?25h[?25l代入 */[?12l[?25h[19;80H[?25lvocab_size + a[94m>>[m[20;1H[93m [19;66H[?12l[?25h[17;66H[m [?25lvocab_size + a[94m>>[m[18;1H[93m [17;66H[?12l[?25h[mvocab_size + [18;5H[17;79H[18;5H[?25l[17;79Ha  [18;1H[93m    [?12l[?25h[20;5H[21;27H[20;5H[19;79H
    [?25l[m[19;79Ha  [20;1H[93m    [?12l[?25h[21;27H[?25l[22;8H[?12l[?25h[21;27H[?25l[22;8H[?12l[?25h[23;56H[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 各 */[?12l[?25h[?25l 語彙の各 */[?12l[?25h[2C[?25l単語 */[?12l[?25h[?25lに */[?12l[?25h[?25l二進数  [24;1H[93m    [m*/[24;7H[K[23;80H[?12l[?25h[?25l */[24;1H[93m241 [m  for (a = 0; a < vocab_size; a++) {[23;78H[?12l[?25h[?25l */[23;79H[K[23;76H[?12l[?25h[?25l */[23;77H[K[23;74H[?12l[?25h[?25l二進法  [24;1H[93m    [m*/[24;7H[K[23;80H[?12l[?25h[?25l[94m>>[m[24;1H[93m    [mコード */[?12l[?25h[?25lを */[?12l[?25h[?25l割当 */[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m241 [m  for (a = 0; a < vocab_size; a++) {[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m242 [m    b = a;[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m243 [m    i = 0;
[93m244 [m    while (1) {[23;15H[?12l[?25h[?25l[24;20H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m245 [m      code[i] = binary[b];[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m246 [m      point[i] = b;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m247 [m      i++;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m248 [m      b = parent_node[b];[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m249 [m      if (b == vocab_size * 2 - 2) break;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[18;19H[46m{[m[24;1H[93m250 [m    [46m}[?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[17;19H{[23;9H}
[93m251 [m    vocab[a].codelen = i;[?12l[?25h[?25l[17;19H[46m{[23;9H}[?12l[?25h[?25l[m[17;19H{[23;9H}[22;46H[?12l[?25h[21;30H[20;15H[19;24H[18;31H[?25l[17;19H[46m{[23;9H}[17;20H[?12l[?25h[?25l[m{[23;9H}[16;15H[?12l[?25h[?25l[17;19H[46m{[23;9H}[17;20H[?12l[?25h[?25l[m{[23;9H}[18;31H[?12l[?25h[?25l[17;19H[46m{[23;9H}[17;20H[?12l[?25h[?25l[m{[23;9H}[16;15H[?12l[?25h[15;15H[?25l[14;41H[?12l[?25h[15;15H[16;15H[?25l[17;19H[46m{[23;9H}[17;20H[?12l[?25h[m[25;1H[K[17;19H[?25l[?12l[?25h[?25l{[23;9H}[16;14H[?12l[?25h[?25l[17;19H[46m{[23;9H}[17;19H[?12l[?25h[?25l[m{[23;9H}[18;19H[?12l[?25h[19;19H[20;14H[21;19H[22;19H[?25l[17;19H[46m{[23;9H}[?12l[?25h[?25l[m[17;19H{[23;9H}[24;19H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m252 [m    vocab[a].point[0] = vocab_size - 2;[24;19H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m253 [m    for (b = 0; b < i; b++) {[24;19H[?12l[?25h[?25l
1 change; before #45  13:54:53[10;24r[24;1H
[1;25r[10;1H[93m240 [m  // Now assign binary code to each vocabulary word /* 語彙の各 */[24;1H[93m254 [m      vocab[a].code[i - b - 1] = code[b];[25;1H[K[10;68H[?12l[?25h[?25l[25;1H1 change; after #45  13:54:53[11;24r[11;1H[L[1;25r[10;68H単語に二進法[94m>>[m[11;1H[93m    [mコードを割当 */[25;1H[K[10;68H[?12l[?25h[?25l[25;1H/[?12l[?25hwhile (1[?25l[15;9H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m264 [m  char word[MAX_STRING];
[93m265 [m  FILE *fin;
[93m266 [m  long long a, i;
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m268 [m  fin = fopen(train_file, "rb");
[93m269 [m  if (fin == NULL) {
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>");
[93m275 [m  while (1) {
[93m276 [m    ReadWord(word, fin);
[93m277 [m    if (feof(fin)) break;
[93m278 [m    train_words++;
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) {
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;[12;7H[?12l[?25h[?25l[25;1H?while (1[27m[m[H[2J[1;1H[93m236 [m    parent_node[min1i] = vocab_size + a; /* min1iの親ノードにvocab_size + a  [2;1H[93m    [mを代入 */
[93m237 [m    parent_node[min2i] = vocab_size + a; /* min2iの親ノードにvocab_size + a  [4;1H[93m    [mを代入 */
[93m238 [m    binary[min2i] = 1;
[93m239 [m  }
[93m240 [m  // Now assign binary code to each vocabulary word /* 語彙の各単語に二進法[94m>>[m[8;1H[93m    [mコードを割当 */
[93m241 [m  for (a = 0; a < vocab_size; a++) {
[93m242 [m    b = a;
[93m243 [m    i = 0;
[93m244 [m    while (1) {
[93m245 [m      code[i] = binary[b];
[93m246 [m      point[i] = b;
[93m247 [m      i++;
[93m248 [m      b = parent_node[b];
[93m249 [m      if (b == vocab_size * 2 - 2) break;
[93m250 [m    }
[93m251 [m    vocab[a].codelen = i;
[93m252 [m    vocab[a].point[0] = vocab_size - 2;
[93m253 [m    for (b = 0; b < i; b++) {
[93m254 [m      vocab[a].code[i - b - 1] = code[b];
[93m255 [m      vocab[a].point[i - b] = point[b] - vocab_size;
[93m256 [m    }[12;9H[?12l[?25h[?25l[25;1H?while (1[27m[m[H[2J[1;1H[93m 98 [m  hash = hash % vocab_hash_size; /* hashにhashをvocab_hash_sizeの剰余を代入  [2;1H[93m    [m*/
[93m 99 [m  return hash; /* hashを返す */
[93m100 [m}
[93m101 
102 [m// Returns position of a word in the vocabulary; if the word is not found, rr[7;1H[93m    [meturns -1 /* 語彙中の単語の位置を返す(単語が語彙中に無い場合は-1を返す) */
[93m103 [mint SearchVocab(char *word) { /* char型ポインタwordを引数に持つint型関数Searr[9;1H[93m    [mchVocab() */
[93m104 [m  unsigned int hash = GetWordHash(word); /* 符号無int型hashにwordのhash値を[94m>>[m[11;1H[93m    [m代入 */
[93m105 [m  while (1) { /* 無限ループ */
[93m106 [m    if (vocab_hash[hash] == -1) return -1; /* vocab_hash[hash]が-1の時-1を返[14;1H[93m    [mす */
[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]][16;1H[93m    [m; /* 文字列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返[94m>>[m[17;1H[93m    [mす */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sii[19;1H[93m    [mzeを返す */
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語[94m>[24;1H@                                                                               [12;7H[?12l[?25h[?25l[m[25;1H/while (1[27m[m[H[2J[1;1H[93m236 [m    parent_node[min1i] = vocab_size + a; /* min1iの親ノードにvocab_size + a  [2;1H[93m    [mを代入 */
[93m237 [m    parent_node[min2i] = vocab_size + a; /* min2iの親ノードにvocab_size + a  [4;1H[93m    [mを代入 */
[93m238 [m    binary[min2i] = 1;
[93m239 [m  }
[93m240 [m  // Now assign binary code to each vocabulary word /* 語彙の各単語に二進法[94m>>[m[8;1H[93m    [mコードを割当 */
[93m241 [m  for (a = 0; a < vocab_size; a++) {
[93m242 [m    b = a;
[93m243 [m    i = 0;
[93m244 [m    while (1) {
[93m245 [m      code[i] = binary[b];
[93m246 [m      point[i] = b;
[93m247 [m      i++;
[93m248 [m      b = parent_node[b];
[93m249 [m      if (b == vocab_size * 2 - 2) break;
[93m250 [m    }
[93m251 [m    vocab[a].codelen = i;
[93m252 [m    vocab[a].point[0] = vocab_size - 2;
[93m253 [m    for (b = 0; b < i; b++) {
[93m254 [m      vocab[a].code[i - b - 1] = code[b];
[93m255 [m      vocab[a].point[i - b] = point[b] - vocab_size;
[93m256 [m    }[12;9H[?12l[?25hwhile[?25l [46m([m1[46m)[?12l[?25h[?25l[m(1)[?12l[?25h[?25l[46m([m1[46m)[?12l[?25h[?25l[m(1)[?12l[?25h[?25l [46m{[18;9H}[12;19H[?12l[?25h[?25l[m[25;1H[1m-- INSERT --[12;20H[?12l[?25h[?25l[m{[18;9H}[12;21H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l 無限ループ[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[13;31H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l c */[?12l[?25h[?25lco */[?12l[?25h[?25lod */[?12l[?25h[?25lde */[?12l[?25h[?25le[ */[?12l[?25h[?25l[i */[?12l[?25h[?25l[46m[[mi[46m][m */[?12l[?25h[?25l[i]に */[?12l[?25h[?25lb */[?12l[?25h[?25lbi */[?12l[?25h[?25lin */[?12l[?25h[?25lna */[?12l[?25h[?25lar */[?12l[?25h[?25lry */[?12l[?25h[?25ly[ */[?12l[?25h[?25l[b */[?12l[?25h[?25l[46m[[mb[46m][m */[?12l[?25h[?25l[b]を */[?12l[?25h[?25l代入 */[?12l[?25h[12;37H[11;15H[10;15H[?25l[9;41H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l a */[?12l[?25h[?25l  */[9;48H[K[9;45H[?12l[?25h[?25l 0 */[?12l[?25h[?25l0< */[?12l[?25h[?25l<- */[?12l[?25h[?25l< */[9;50H[K[9;47H[?12l[?25h[?25l<= */[?12l[?25h[?25l=a */[?12l[?25h[?25l0 <=a */[?12l[?25h<=[?25l= a */[?12l[?25ha[?25l  */[?12l[?25h[?25l < */[?12l[?25h[?25l  */[?12l[?25h[?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_s */[?12l[?25h[?25lsi */[?12l[?25h[?25liz */[?12l[?25h[?25lze */[?12l[?25h[?25leの */[?12l[?25h[?25l時 */[?12l[?25h[10;15H[11;15H[12;37H[13;62H[?25l[46m[[mb[46m][?12l[?25h[?25l[?12l[?25h[?25l][?12l[?25h[?25l[m[b](を代入 */[13;54H[?12l[?25h[?25l[46m()[mを代入 */[13;55H[?12l[?25h[?25l[?12l[?25h[?25l[46m([m最初は[46m)[mを代入 */[13;60H[?12l[?25h[?25la[46m)[mを代入 */[13;61H[?12l[?25h[?25l[13;53H([7C)[?12l[?25h[?25lba)を代入 */[13;61H[?12l[?25h[?25lb=a)を代入 */[13;62H[?12l[?25h[14;24H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l p*/[?12l[?25h[?25lpo*/[?12l[?25h[?25lon*/[?12l[?25h[?25lnt*/[?12l[?25h[?25lt[*/[?12l[?25h[?25l[i*/[?12l[?25h[?25l[46m[[mi[46m][m*/[?12l[?25h[?25l[i]に*/[?12l[?25h[?25lb*/[?12l[?25h[?25lbを*/[?12l[?25h[?25l代入*/[?12l[?25h[15;15H[16;30H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l  */[?12l[?25h[?25l b */[?12l[?25h[?25lbに */[?12l[?25h[?25lp */[?12l[?25h[?25lpa */[?12l[?25h[?25lar */[?12l[?25h[?25lre */[?12l[?25h[?25len */[?12l[?25h[?25lnt */[?12l[?25h[?25lt_ */[?12l[?25h[?25l_n */[?12l[?25h[?25lno */[?12l[?25h[?25lod */[?12l[?25h[?25lde */[?12l[?25h[?25leを */[?12l[?25h[?25l代入 */[?12l[?25h[25;1H[K[16;52H[?25l[?12l[?25h[?25l[25;1H:[?12l[?25hw[?25l"word2vec.c" 703L, 31586C written[16;52H[?12l[?25h[17;45H[?25l[25;1H[1m-- INSERT --[m[25;14H[K[17;46H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [?25l b */[?12l[?25h[?25lb= */[?12l[?25h[?25l== */[?12l[?25h[?25l  */[?12l[?25h[?25l= =  */[?12l[?25h[?25l==  */[17;57H[K[17;52H[?12l[?25h[?25lb ==  */[?12l[?25h== [?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_s */[?12l[?25h[?25lsi */[?12l[?25h[?25liz */[?12l[?25h[?25lze */[?12l[?25h[?25l  */[?12l[?25h[?25l * */[?12l[?25h[?25l  */[?12l[?25h[?25l 2 */[?12l[?25h[?25l  */[?12l[?25h[?25l - */[?12l[?25h[?25l-2 */[?12l[?25h[?25l- 2 */[?12l[?25h2[?25l2の */[?12l[?25h[?25l時 */[?12l[?25h[?25l[18;24r[18;1H[L[1;25r[17;77H無限 [18;1H[93m    [mループ */[?12l[?25h[?25lから */[?12l[?25h[?25l脱出 */[?12l[?25h[?25l[12;19H[46m{[19;9H}[?12l[?25h[m[25;1H[K[19;9H[?25l[?12l[?25h[?25l[12;19H{[19;9H}[20;9H[?12l[?25h[21;9H[22;9H[23;9H[24;9H[?25l[1;24r[1;1H[2M[1;25r[20;33H[46m{[m


[93m256 [m    [46m}[m
[93m257 [m  }[23;9H[?12l[?25h[?25l[7;40H[46m{[m[20;33H{[23;9H}[24;7H[46m}[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[5;40H{[22;7H}
[93m258 [m  free(count);
[93m259 [m  free(binary);[23;9H[?12l[?25h[24;9H[23;9H[?25l[5;40H[46m{[22;7H}[?12l[?25h[?25l[m[5;40H{[18;33H[46m{[21;9H}[m[22;7H}[21;9H[?12l[?25h[?25l[18;33H{[21;9H}[20;9H[?12l[?25h[19;9H[18;9H[17;9H[?25l[25;1H/[?12l[?25hcodelen[?25l[27m[m[H[2J[1;1H[93m427 [m[7C c = sentence_position - window + a;
[93m428 [m[7C if (c < 0) continue;
[93m429 [m[7C if (c >= sentence_length) continue;
[93m430 [m[7C last_word = sen[c];
[93m431 [m[7C if (last_word == -1) continue;
[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * laa[7;1H[93m    [myer1_size];
[93m433 [m[7C cw++;
[93m434 [m      }
[93m435 [m      if (cw) {
[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;
[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {
[93m438 [m[9C f = 0;
[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;
[93m440 [m[9C // Propagate hidden -> output
[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1[c + l2];
[93m442 [m[9C if (f <= -MAX_EXP) continue;
[93m443 [m[9C else if (f >= MAX_EXP) continue;
[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [20;1H[93m    [m/ 2))];
[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate
[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;
[93m447 [m[9C // Propagate errors output -> hidden
[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[12;49H[?12l[?25h[?25l[25;1H?codelen[27m[m[H[2J[1;1H[93m241 [m  for (a = 0; a < vocab_size; a++) { /* 0 <= a < vocab_sizeの時 */
[93m242 [m    b = a;
[93m243 [m    i = 0;
[93m244 [m    while (1) { /* 無限ループ */
[93m245 [m      code[i] = binary[b]; /* code[i]にbinary[b](最初はb=a)を代入 */
[93m246 [m      point[i] = b; /* pont[i]にbを代入*/
[93m247 [m      i++;
[93m248 [m      b = parent_node[b]; /* bにparent_nodeを代入 */
[93m249 [m      if (b == vocab_size * 2 - 2) break; /* b == vocab_size * 2 - 2の時無限[10;1H[93m    [mループから脱出 */
[93m250 [m    }
[93m251 [m    vocab[a].codelen = i;
[93m252 [m    vocab[a].point[0] = vocab_size - 2;
[93m253 [m    for (b = 0; b < i; b++) {
[93m254 [m      vocab[a].code[i - b - 1] = code[b];
[93m255 [m      vocab[a].point[i - b] = point[b] - vocab_size;
[93m256 [m    }
[93m257 [m  }
[93m258 [m  free(count);
[93m259 [m  free(binary);
[93m260 [m  free(parent_node);
[93m261 [m}
[93m262 
263 [mvoid LearnVocabFromTrainFile() {[12;18H[?12l[?25h[?25l[25;1H?codelen[27m[m[H[2J[1;1H[93m 25 [m#define MAX_CODE_LENGTH 40 /* 最大コード長は40字まで */
[93m 26 
 27 [mconst int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in thh[4;1H[93m    [me vocabulary
[93m 28 
 29 [mtypedef float real;[19C // Precision of float numbers
[93m 30 
 31 [m/* 構造体型struct vocab_wordを宣言 */
[93m 32 [mstruct vocab_word {
[93m 33 [m  long long cn; /* long long型(64 bit符号付整数型) cn */
[93m 34 [m  int *point; /* int型ポインタpointを宣言 */
[93m 35 [m  char *word, *code, codelen; /* char型(1 byte文字型)codelenとポインタword，[13;1H[93m    [mcodeを宣言 */
[93m 36 [m};
[93m 37 
 38 [mchar train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[17;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */
[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[19;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */
[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocabを宣言  [21;1H[93m    [m*/
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[23;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */[12;58H[?12l[?25hcodel[14;6H[12;63H[?25l[12;44H[46m([12C)[?12l[?25h[?25l[m[12;44H([12C)[?12l[?25h[12;7H[?25l[25;1H/[?12l[?25hvocab[?25l[18;15H[?12l[?25h[20;5H[18;5H[16;5H[15;5H[?25l[9;23H[46m{[14;5H}[?12l[?25h[?25l[m[9;23H{[14;5H}[12;5H[?12l[?25h[11;5H[10;5H  long long cn; /* long long[?25l[2C[46m([18C)[10;35H[?12l[?25h[?25l[m([18C)[10;36H[?12l[?25h64 bit[2C[2C[2C[2C[2C[?25l[10;35H[46m([18C)[?12l[?25h[?25l[m[10;35H([18C)[?12l[?25h cn[11;48H[12;58H[14;6H[15;5H[14;6H[?25l[25;1H[1m-- INSERT --[14;7H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 変数 */[?12l[?25h[2C[2C[?25l無し */[?12l[?25h[?25l この段階で変数無し */[14;21H[?12l[?25h[15;5H[?25l[16;20H[46m[[10C][m[48CNN[17;1H[93m [16;21H[?12l[?25h[?25l[m[[10C][48CNN[17;1H[93m [18;21H[?12l[?25h[20;21H[22;21H[24;21H[?25l[1;24r[m[1;1H[2M[1;25r[23;1H[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [24;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */[23;21H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[24;1H[93m    [mlasses = 0;[23;21H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;[24;21H[?12l[?25h[25;1H[K[24;20H[?25l[?12l[?25h[?25l
/vocab[27m[m[H[2J[1;1H[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[11;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[13;1H[93m    [m);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}[12;23H[?12l[?25h[?25l[25;1H/vocab[12;63H[?12l[?25h[?25l[25;1H[15;16H[?12l[?25h[14;12H[?25l[25;1H?[12;63H[?12l[?25h[?25l[25;1H[12;23H[?12l[?25h[?25l[25;1H[1;24r[1;1H[7L[1;25r[1;1H[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [2;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[4;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;[25;1H[K[2;27H[?12l[?25h[?25l[25;1H?vocab[2;11H[?12l[?25h[?25l[25;1H[1;38H[?12l[?25h[?25l[25;1H[1;15H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */[25;1H[K[1;38H[?12l[?25h[?25l[25;1H?vocab[1;10H[?12l[?25h[?25l[25;1H[1;24r[1;1H[4L[1;25r[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocabを宣言  [2;1H[93m    [m*/
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[4;1H[93m    [meads = 12, min_reduce = 1;[24;1H[94m@                                                                               [m[25;1H[K[1;69H[?12l[?25h[2C[2C[2C[2C[2Cvocab[?25l[1;24r[1;1H[4L[1;25r[1;1H[93m 38 [mchar train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[2;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */
[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[4;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */[1;5H[?12l[?25h[?25l[25;1H1 change; before #72  41 seconds ago[1;2H[93m36 [m}; /* 変数無し */[1;22H[K[2;1H[93m 37[m[2;5H[K[3;2H[93m38[m[5C train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[4;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */
[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[6;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */[7;2H[93m40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocabを宣言  [8;1H[93m    [m*/[8;7H[K[9;2H[93m41[m[4C binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[10;1H[93m    [meads = 12, min_reduce = 1;[10;32H[K[11;1H[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */[12;2H[93m43[m[10C vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [13;1H[93m [m[3Clong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */[14;2H[93m44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[15;1H[93m    [mlasses = 0;[15;17H[K[16;2H[93m45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;[17;2H[93m46 [mreal *syn0, *syn1, *syn1neg, *expTable;[18;2H[93m47 [mclock_t start;[18;19H[K[19;1H[93m 48[m[19;5H[K[20;1H[93m 49[m[4C hs = 0, negative = 5;[21;2H[93m50 [mconst int table_size = 1e8;[21;32H[K[22;2H[93m51 [mint *table;[22;16H[K[23;2H[93m52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */[24;2H[93m53 [mvoid InitUnigramTable() {[24;30H[K[1;11H[?12l[?25h[?25l[25;20H1  48[1;15H */ [1;20H[K[1;15H[?12l[?25h[?25l[25;11Hafter #71  51 seconds ago[25;36H[K[1;15H無し */[1;15H[?12l[?25h[?25l[25;19H2  49[1;10H この段階で変数無し */[1;11H[?12l[?25h[?25l[25;1HAlready at newest change[25;25H[K[1;11H[?12l[?25h[?25l[25;1H[K[25;1H/[?12l[?25h[?25lvocab[?12l[?25h[?25l/codelen[?12l[?25h[?25l/while (1[?12l[?25h[?25l[25;9H[K[25;9H[?12l[?25h[?25l[25;8H[K[25;8H[?12l[?25h[?25l[?12l[?25h[?25l[25;6H[K[25;6H[?12l[?25h[?25l[25;5H[K[25;5H[?12l[?25h[?25l[25;4H[K[25;4H[?12l[?25h[?25l[25;3H[K[25;3H[?12l[?25h[?25l[25;2H[K[25;2H[?12l[?25hvocab[?25l[5;15H[?12l[?25h[?25l[25;1H[5;44H[?12l[?25h[?25l[25;1H[6;6H[?12l[?25h[?25l[25;1H[6;23H[?12l[?25h[?25l[25;1H[7;12H[?12l[?25h[?25l[25;1H[7;24H[?12l[?25hvocab; [?25l[25;1H[1m-- INSERT --[7;32H[?12l[?25h[m* [2C[2C[2C[2Cstruct vocab_word[2C[2C[2C[2C[2Cvocab[?25lb(を宣言 [8;1H[93m    [m */[7;75H[?12l[?25h[?25l[46m()[mを宣[94m>>[m[8;1H[93m    [m言 */[7;76H[?12l[?25h[?25l[4C[94m>>[m[8;1H[93m [7;75H[?12l[?25h[?25l[m[46m([mこれは [8;1H[93m    [m[46m)[mを宣言 */[8;5H[?12l[?25h[?25l[93m [m変数[46m)[mを宣言 */[8;9H[?12l[?25h[?25l！[46m)[mを宣言 */[8;11H[?12l[?25h[?25l[7;74H([5C  [8;1H[93m [m[9C)[6;11H[?12l[?25h[4;10H[2;5H[1;32H[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m 35 [m  char *word, *code, codelen; /* char型(1 byte文字型)codelenとポインタword，[2;1H[93m    [mcodeを宣言 */[2;11H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m 34 [m  int *point; /* int型ポインタpointを宣言 */[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m 33 [m  long long cn; /* long long型(64 bit符号付整数型) cn */[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m 32 [mstruct vocab_word [46m{[6;5H}[1;24H[?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m 31 [m/* 構造体型struct vocab_wordを宣言 */[2;23H{[7;5H}[1;42H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m 30 [?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m 29 [mtypedef float real;[19C // Precision of float numbers[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m 28 [?12l[?25h[?25l[1;24r[m[1;1H[2L[1;25r[1;1H[93m 27 [mconst int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in thh[2;1H[93m    [me vocabulary[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m 26 [m[24;1H[94m@                                                                               [1;5H[?12l[?25h[3;11H[4;5H[5;73H[6;5H[7;42H[?25l[m[8;23H[46m{[13;5H}[8;24H[?12l[?25h[?25l[m{[13;5H}[9;61H[?12l[?25h[10;49H[12;11H[13;32H[14;5H[16;10H[18;11H[?25l[19;74H[46m([m[5C  [20;1H[93m [m[9C[46m)[?12l[?25h[?25l[m[19;74H([5C  [20;1H[93m [m[9C)[22;11H[?12l[?25h[?25l[19;74H[46m([m[5C  [20;1H[93m [m[9C[46m)[?12l[?25h[?25l[m[19;74H([5C  [20;1H[93m [m[9C)[18;11H[?12l[?25h[?25l[19;74H[46m([m[5C  [20;1H[93m [m[9C[46m)[?12l[?25h[?25l)[?12l[?25h[?25l[m[19;74H([5C  [20;1H[93m [m[9C)[2C[?12l[?25h[2C[2C[?25l[19;74H[46m([m[5C  [20;1H[93m [m[9C[46m)[?12l[?25h[?25l[?12l[?25h[?25l[ma[46m)[mを宣言 */[20;12H[?12l[?25h[?25l[46m)[mを宣言 */[20;21H[K[20;11H[?12l[?25h[?25l[46m)[mを宣言 */[20;19H[K[20;9H[?12l[?25h[?25lだから[46m)[mを宣言 */[20;15H[?12l[?25h[?25lv[46m)[mを宣言 */[20;16H[?12l[?25h[?25lvo[46m)[mを宣言 */[20;17H[?12l[?25h[?25loc[46m)[mを宣言 */[20;18H[?12l[?25h[?25lca[46m)[mを宣言 */[20;19H[?12l[?25h[?25lab[46m)[mを宣言 */[20;20H[?12l[?25h[?25lb_[46m)[mを宣言 */[20;21H[?12l[?25h[?25l_w[46m)[mを宣言 */[20;22H[?12l[?25h[?25lwo[46m)[mを宣言 */[20;23H[?12l[?25h[?25lor[46m)[mを宣言 */[20;24H[?12l[?25h[?25lrd[46m)[mを宣言 */[20;25H[?12l[?25h[?25ldの[46m)[mを宣言 */[20;27H[?12l[?25h[?25l各メンバ[46m)[mを宣言 */[20;35H[?12l[?25h[?25l[46m)[mを宣言 */[20;43H[K[20;33H[?12l[?25h[?25l[46m)[mを宣言 */[20;41H[K[20;31H[?12l[?25h[?25l[46m)[mを宣言 */[20;39H[K[20;29H[?12l[?25h[?25l[46m)[mを宣言 */[20;37H[K[20;27H[?12l[?25h[?25ld[46m)[mを宣言 */[20;35H[K[20;25H[?12l[?25h[?25lr[46m)[mを宣言 */[20;34H[K[20;24H[?12l[?25h[?25lo[46m)[mを宣言 */[20;33H[K[20;23H[?12l[?25h[?25lw[46m)[mを宣言 */[20;32H[K[20;22H[?12l[?25h[?25l_[46m)[mを宣言 */[20;31H[K[20;21H[?12l[?25h[?25lb[46m)[mを宣言 */[20;30H[K[20;20H[?12l[?25h[?25lb.[46m)[mを宣言 */[20;21H[?12l[?25h[?25l.c[46m)[mを宣言 */[20;22H[?12l[?25h[?25lcn[46m)[mを宣言 */[20;23H[?12l[?25h[?25ln,[46m)[mを宣言 */[20;24H[?12l[?25h[?25l, [46m)[mを宣言 */[20;25H[?12l[?25h[?25l v[46m)[mを宣言 */[20;26H[?12l[?25h[?25lvo[46m)[mを宣言 */[20;27H[?12l[?25h[?25loc[46m)[mを宣言 */[20;28H[?12l[?25h[?25lca[46m)[mを宣言 */[20;29H[?12l[?25h[?25lab[46m)[mを宣言 */[20;30H[?12l[?25h[?25lb.[46m)[mを宣言 */[20;31H[?12l[?25h[?25l.p[46m)[mを宣言 */[20;32H[?12l[?25h[?25lpo[46m)[mを宣言 */[20;33H[?12l[?25h[?25loi[46m)[mを宣言 */[20;34H[?12l[?25h[?25lin[46m)[mを宣言 */[20;35H[?12l[?25h[?25lnt[46m)[mを宣言 */[20;36H[?12l[?25h[?25lt,[46m)[mを宣言 */[20;37H[?12l[?25h[?25l, [46m)[mを宣言 */[20;38H[?12l[?25h[?25l v[46m)[mを宣言 */[20;39H[?12l[?25h[?25lvo[46m)[mを宣言 */[20;40H[?12l[?25h[?25loc[46m)[mを宣言 */[20;41H[?12l[?25h[?25lca[46m)[mを宣言 */[20;42H[?12l[?25h[?25lab[46m)[mを宣言 */[20;43H[?12l[?25h[?25lb.[46m)[mを宣言 */[20;44H[?12l[?25h[?25l.w[46m)[mを宣言 */[20;45H[?12l[?25h[?25lwo[46m)[mを宣言 */[20;46H[?12l[?25h[?25lor[46m)[mを宣言 */[20;47H[?12l[?25h[?25lrd[46m)[mを宣言 */[20;48H[?12l[?25h[?25ld,[46m)[mを宣言 */[20;49H[?12l[?25h[?25l, [46m)[mを宣言 */[20;50H[?12l[?25h[?25l v[46m)[mを宣言 */[20;51H[?12l[?25h[?25lvo[46m)[mを宣言 */[20;52H[?12l[?25h[?25loc[46m)[mを宣言 */[20;53H[?12l[?25h[?25lca[46m)[mを宣言 */[20;54H[?12l[?25h[?25lab[46m)[mを宣言 */[20;55H[?12l[?25h[?25lb.[46m)[mを宣言 */[20;56H[?12l[?25h[?25l.c[46m)[mを宣言 */[20;57H[?12l[?25h[?25lco[46m)[mを宣言 */[20;58H[?12l[?25h[?25lod[46m)[mを宣言 */[20;59H[?12l[?25h[?25lde[46m)[mを宣言 */[20;60H[?12l[?25h[?25le,[46m)[mを宣言 */[20;61H[?12l[?25h[?25l, [46m)[mを宣言 */[20;62H[?12l[?25h[?25l v[46m)[mを宣言 */[20;63H[?12l[?25h[?25lvo[46m)[mを宣言 */[20;64H[?12l[?25h[?25loc[46m)[mを宣言 */[20;65H[?12l[?25h[?25lca[46m)[mを宣言 */[20;66H[?12l[?25h[?25lab[46m)[mを宣言 */[20;67H[?12l[?25h[?25lb.[46m)[mを宣言 */[20;68H[?12l[?25h[?25l.c[46m)[mを宣言 */[20;69H[?12l[?25h[?25lco[46m)[mを宣言 */[20;70H[?12l[?25h[?25lod[46m)[mを宣言 */[20;71H[?12l[?25h[?25l[21;24r[21;1H[L[1;25r[20;70Hde[46m)[mを宣言 **[21;1H[93m    [m/[20;72H[?12l[?25h[?25lel[46m)[mを宣言  [21;1H[93m    [m*/[20;73H[?12l[?25h[?25lle[46m)[mを宣言[21;4H[93m [m */[20;74H[?12l[?25h[?25len[46m)[mを宣[94m>>[m[21;1H[93m    [m言 */[20;75H[?12l[?25h[?25lnを[46m)[mを[94m>>[m[21;1H[93m    [m宣言 */[20;77H[?12l[?25h[?25l持つ[21;4H[93m [m[46m)[mを宣言 */[21;5H[?12l[?25h[?25l[19;74H([5C  [20;1H[93m [m[21;5H)[23;31H[?12l[?25h[24;72H[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [23;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, c[24;1H[94m@                                                                               [23;59H[?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[23;1H[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[24;1H[93m    [mlasses = 0;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;[?12l[?25h[23;55H[22;16H[20;59H[18;72H[17;31H[25;1H[K[17;30H[?25l[?12l[?25h[16;5H[?25l[25;1H/[?12l[?25hvocab.cn[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[14;15H[?12l[?25h[?25l[m[25;1H/vocab.cn[25;10H[K[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[14;15H[?12l[?25h[?25l[m[25;1H/vocab.cn[25;10H[K[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[14;15H[?12l[?25h[?25l[m[25;1H/vocab.cn[25;10H[K[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[14;15H[?12l[?25h[?25l[m[25;1H/vocab.cn[25;10H[K[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[14;15H[?12l[?25h[?25l[m[25;1H/vocab.cn[25;10H[K[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[14;15H[?12l[?25h[?25l[m[25;1H/vocab.cn[25;10H[K[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[14;15H[?12l[?25h[?25l[m[25;1H[K[25;1H/[?12l[?25h.cn[?25l[14;20H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[11;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[13;1H[93m    [m);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}[12;71H[?12l[?25h[?25l[25;1H?.cn[1;24r[1;1H[13L[1;25r[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは[2;1H[93m    [m変数だからvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ [3;1H[93m    [m)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[5;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [8;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[10;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;[25;1H[K[2;20H[?12l[?25h[?25l[25;1H?.cn[1;24r[1;1H[10L[1;25r[1;1H[93m 33 [m  long long cn; /* long long型(64 bit符号付整数型) cn */
[93m 34 [m  int *point; /* int型ポインタpointを宣言 */
[93m 35 [m  char *word, *code, codelen; /* char型(1 byte文字型)codelenとポインタword，[4;1H[93m    [mcodeを宣言 */
[93m 36 [m}; /* この段階で変数無し */
[93m 37 
 38 [mchar train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[8;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */
[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[10;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */[25;1H[K[1;55H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m 32 [mstruct vocab_word [46m{[6;5H}[1;23H[?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m 31 [m/* 構造体型struct vocab_wordを宣言 */[2;23H{[7;5H}[1;41H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m 30 [?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m 29 [mtypedef float real;[19C // Precision of float numbers[1;55H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m 28 [m[24;1H[94m@                                                                               [1;5H[?12l[?25h[?25l[1;24r[m[1;1H[2L[1;25r[1;1H[93m 27 [mconst int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in thh[2;1H[93m    [me vocabulary[24;1H[94m@                                                                               [1;55H[?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m 26 [?12l[?25h[?25l[25;1H[m/[?12l[?25hvocab_size[?25l[1;24r[1;1H[3M[1;25r[22;1H[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [23;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, c[24;1H[94m@                                                                               [m[25;1H[K[22;38H[?12l[?25h[?25l


/vocab_size[23;27H[?12l[?25h[?25l

[27m[m[H[2J[1;1H[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[11;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[13;1H[93m    [m);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}[12;23H[?12l[?25h[?25l[25;1H/vocab_size[22;18H[?12l[?25h[?25l


[22;34H[?12l[?25h[?25l


[27m[m[H[2J[1;1H[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[7;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[9;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[11;1H[93m    [mきい場合はlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個 [13;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコ[94m>>[m[15;1H[93m    [mピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */
[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */
[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */
[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size[94m>>[m[20;1H[93m    [m以上の時 */
[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */
[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struu[23;1H[93m    [mct vocab_word)); /*  */
[93m133 [m  }[12;13H[?12l[?25h[?25l[25;1H/vocab_size[13;53H[?12l[?25h[?25l[25;1H[14;20H[?12l[?25h[?25l[25;1H[14;54H[?12l[?25h[?25l[25;1H[16;13H[?12l[?25h[?25l[25;1H[16;42H[?12l[?25h[?25l[25;1H[17;7H[?12l[?25h[?25l[25;1H[17;24H[?12l[?25h[?25l[25;1H[K[25;1H/[?12l[?25hcn[?25l[1;24r[1;1H[9M[1;25r[16;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;
[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 
140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;[25;1H[K[24;42H[?12l[?25h[?25l
/cn[24;73H[?12l[?25h[?25l
[27m[m[H[2J[1;1H[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替え[3;1H[93m    [mて文字列</s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);;[5;1H[93m    [m/* vocab[1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[11;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未 [13;1H[93m    [m満かつaが0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /*  [18;1H[93m    [mハッシュを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }[12;23H[?12l[?25h[?25l[25;1H[1m-- INSERT --[m[25;1H[K[14;24r[14;1H[L[1;25r[12;21H]だからvocab.cn, vocab.point, vocab.word, vocab.code, vocab..[13;1H[93m    [mcodelenを持つcn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満か[94m>>[m[14;1H[93m    [mつaが0でない時 */[13;16H[?12l[?25h[?25l[25;1H1 change; before #76  2 seconds ago[12;24r[24;1H
[1;25r[12;1H[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未[13;4H[93m [m満かつaが0でない時 */[24;1H[93m166 [m  }[25;1H[K[12;23H[?12l[?25h[?25l[25;1H/[?12l[?25h.cn[?25l[12;65H[?12l[?25h[?25l[25;1H[22;34H[?12l[?25h[?25l


[27m[m[H[2J[1;1H[93m168 [m  // Allocate memory for the binary tree construction
[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));
[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 
175 [m// Reduces the vocabulary by removing infrequent tokens
[93m176 [mvoid ReduceVocab() {
[93m177 [m  int a, b = 0;
[93m178 [m  unsigned int hash;
[93m179 [m  for (a = 0; a < vocab_size; a++) if (vocab[a].cn > min_reduce) {
[93m180 [m    vocab[b].cn = vocab[a].cn;
[93m181 [m    vocab[b].word = vocab[a].word;
[93m182 [m    b++;
[93m183 [m  } else free(vocab[a].word);
[93m184 [m  vocab_size = b;
[93m185 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m186 [m  for (a = 0; a < vocab_size; a++) {
[93m187 [m    // Hash will be re-computed, as it is not actual
[93m188 [m    hash = GetWordHash(vocab[a].word);
[93m189 [m    while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m190 [m    vocab_hash[hash] = a;
[93m191 [m  }[12;52H[?12l[?25h[?25l[25;1H/.cn[13;17H[?12l[?25h[?25l[25;1H[13;31H[?12l[?25h[?25l[25;1H?[13;17H[?12l[?25h[?25l[25;1H[12;52H[?12l[?25h[?25l[25;1H[1;24r[1;1H[5L[1;25r[1;1H[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }
[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struu[5;1H[93m    [mct vocab_word));[25;1H[K[1;34H[?12l[?25h[?25l[25;1H?.cn[1;24r[1;1H[10L[1;25r[1;1H[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未 [2;1H[93m    [m満かつaが0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /*  [7;1H[93m    [mハッシュを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;[25;1H[K[1;65H[?12l[?25h[?25l[25;1H?.cn[1;22H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[2;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */[25;1H[K[1;22H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m154 [m  for (a = 0; a < size; a++) {[1;22H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m153 [m  train_words = 0;[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m152 [m  size = vocab_size;[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[1;22H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);;[2;1H[93m    [m/* vocab[1]のアドレス，vocab_size -1， */[1;22H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替え [2;1H[93m    [mて文字列</s>を先頭に保つ */[24;1H[94m@                                                                               [1;22H[?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m148 [m  unsigned int hash;[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m147 [m  int a, size;[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m146 [mvoid SortVocab() { /* void関数SortVocab() */[1;22H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用い[2;1H[93m    [mて頻度順に並替え */[1;22H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m144 [?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m143 [m}[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;[24;1H[94m@                                                                               [1;22H[?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m141 [mint VocabCompare(const void *a, const void *b) {[1;22H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */[1;22H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m139 [?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m138 [m}[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m137 [m  return vocab_size - 1;[24;1H[94m@                                                                               [1;22H[?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m136 [m  vocab_hash[46m[[mhash[46m][m = vocab_size - 1;[1;22H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;[2;17H[hash][24;1H[94m@                                                                               [1;22H[?12l[?25h[?25l[1;24r[m[1;1H[L[1;25r[1;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */[1;22H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m133 [m  }[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struu[2;1H[93m    [mct vocab_word)); /*  */[1;22H[?12l[?25h[?25l[1;24r[1;1H[L[1;25r[1;1H[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */[1;22H[?12l[?25h[?25l[1;24r[1;1H[2L[1;25r[1;1H[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size[94m>>[m[2;1H[93m    [m以上の時 */[1;22H[?12l[?25h[?25l[25;1H:[?12l[?25h210[?25l[27m[m[H[2J[1;1H[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[2;1H[93m    [mng long)); /* long long型ポインタparent_nodeに(vocab_size * 2 * 1) * (long ll[3;1H[93m    [mong)分のメモリを確保 */
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn; /* ポインタcount[94m>>[m[5;1H[93m    [mの0 <= a < vocab_size番目ににvocab[a].cnを代入 */
[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15; /* ポインタ[7;1H[93m    [mcountのvocab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */
[93m206 [m  pos1 = vocab_size - 1;
[93m207 [m  pos2 = vocab_size;
[93m208 [m  // Following algorithm constructs the Huffman tree by adding one node at aa[11;1H[93m    [m time /* ノードをa回追加してHuffman木を構成するアルゴリズム */
[93m209 [m  for (a = 0; a < vocab_size - 1; a++) {
[93m210 [m    // First, find two smallest nodes 'min1, min2' /* まず2つの最小ノード'mii[14;1H[93m    [mn1, min2'を探す */
[93m211 [m    if (pos1 >= 0) { /* pos1(最初はvocab_size-1)が非負の時 */
[93m212 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpoo[17;1H[93m    [ms1 = vocab_size - 1, pos2 = vocab_size)の時 */
[93m213 [m[7C min1i = pos1; /* long long型min1iにpos1を代入 */
[93m214 [m[7C pos1--;
[93m215 [m      } else { /* count[pos1] >= count[pos2]の時 */
[93m216 [m[7C min1i = pos2;
[93m217 [m[7C pos2++;
[93m218 [m      }
[93m219 [m    } else { /* pos1が負の時 */[13;9H[?12l[?25h[15;9H[16;9H[18;9H[19;9H[20;9H[21;9H[22;9H[23;9H[?25l[15;24H[46m{[24;9H}[?12l[?25h[?25l[1;24r[m[1;1H[3M[1;25r[12;24H{[21;9H}
[93m220 [m      min1i = pos2;
[93m221 [m      pos2++;
[93m222 [m    }[22;9H[?12l[?25h[23;9H[?25l[21;16H[46m{[24;9H}[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[19;16H{[22;9H}
[93m223 [m    if (pos1 >= 0) {
[93m224 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpo[24;1H[94m@                                                                               [23;9H[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[22;1H[93m224 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpoo[23;1H[93m    [mos1 = vocab_size - 1, pos2 = vocab_size)の時 */
[93m225 [m[7C min2i = pos1; /* long long型min2iにpos1を代入 */[22;9H[?12l[?25h[24;9H[?25l[1;24r[24;1H
[1;25r[24;1H[93m226 [m[7C pos1--;[24;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m227 [m      } else { /* count[pos1] >= count[pos2]の時 */[24;9H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m228 [m[7C min2i = pos2;
[93m229 [m[7C pos2++;[23;9H[?12l[?25h[24;9H[?25l[1;24r[24;1H
[1;25r[24;1H[93m230 [m      }[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[14;24H[46m{[m[23;1H[93m231 [m    [46m}[m else { /* pos1が負の時 */
[93m232 [m      min2i = pos2;[23;9H[?12l[?25h[?25l[14;24H{[23;9H}[24;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m233 [m      pos2++;[24;9H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[20;16H[46m{[m


[93m234 [m    [46m}[m
[93m235 [m    count[vocab_size + a] = count[min1i] + count[min2i]; /* count[vocab_size[24;1H[94m@                                                                               [23;9H[?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[19;16H{[22;9H}
[93m235 [m    count[vocab_size + a] = count[min1i] + count[min2i]; /* count[vocab_sizee[24;1H[93m    [m + a]にcount[min1i] + count[min2i]を代入 */[23;9H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m236 [m    parent_node[min1i] = vocab_size + a; /* min1iの親ノードにvocab_size + a  [24;1H[93m    [mを代入 */[23;9H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m237 [m    parent_node[min2i] = vocab_size + a; /* min2iの親ノードにvocab_size + a  [24;1H[93m    [mを代入 */[23;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m238 [m    binary[min2i] = 1;[24;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m239 [m  }[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m240 [m  // Now assign binary code to each vocabulary word /* 語彙の各単語に二進法[94m>>[m[24;1H[93m    [mコードを割当 */[23;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m241 [m  for (a = 0; a < vocab_size; a++) { /* 0 <= a < vocab_sizeの時 */[24;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m242 [m    b = a;[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m243 [m    i = 0;
[93m244 [m    while (1) { /* 無限ループ */[23;9H[?12l[?25h[24;9H[?25l[1;24r[24;1H
[1;25r[24;1H[93m245 [m      code[i] = binary[b]; /* code[i]にbinary[b](最初はb=a)を代入 */[24;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m246 [m      point[i] = b; /* pont[i]にbを代入*/[24;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m247 [m      i++;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m248 [m      b = parent_node[b]; /* bにparent_nodeを代入 */[24;9H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m249 [m      if (b == vocab_size * 2 - 2) break; /* b == vocab_size * 2 - 2の時無限 [24;1H[93m    [mループから脱出 */[23;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[17;19H[46m{[m[24;1H[93m250 [m    [46m}[?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[16;19H{[23;9H}
[93m251 [m    vocab[a].codelen = i;[24;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m252 [m    vocab[a].point[0] = vocab_size - 2;[24;9H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m253 [m    for (b = 0; b < i; b++) {[24;9H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m254 [m      vocab[a].code[i - b - 1] = code[b];
[93m255 [m      vocab[a].point[i - b] = point[b] - vocab_size;[23;9H[?12l[?25h[24;9H[?25l[1;24r[1;1H[2M[1;25r[20;33H[46m{[m


[93m256 [m    [46m}[m
[93m257 [m  }[23;9H[?12l[?25h[?25l[7;40H[46m{[m[20;33H{[23;9H}[24;7H[46m}[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[5;40H{[22;7H}
[93m258 [m  free(count);
[93m259 [m  free(binary);[23;9H[?12l[?25h[?25l[5;40H[46m{[22;7H}[?12l[?25h[?25l[m[5;40H{[18;33H[46m{[21;9H}[m[22;7H}[21;9H[?12l[?25h[?25l[18;33H{[21;9H}[20;9H[?12l[?25h[19;9H[18;9H[17;9H[16;9Hvoca[?25lb[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h.c[17;19H[18;19H[19;19H[20;19H[?25l[18;33H[46m{[21;9H}[?12l[?25h[?25l[5;40H{[m[18;33H{[21;9H}[22;7H[46m}[?12l[?25h[?25l[m[5;40H{[22;7H}[23;18H[?12l[?25h[24;19H[?25l[1;24r[24;1H
[1;25r[24;1H[93m260 [m  free(parent_node);[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m261 [m}[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m262 
263 [mvoid LearnVocabFromTrainFile() {[23;5H[?12l[?25h[24;19H[23;5H[22;5H[21;19H[20;19H[19;18H[20;19H[21;19H[22;5H[23;5H[24;19H[?25l[1;24r[24;1H
[1;25r[24;1H[93m264 [m  char word[MAX_STRING];[24;19H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m265 [m  FILE *fin;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m266 [m  long long a, i;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[24;19H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m268 [m  fin = fopen(train_file, "rb");[24;19H[?12l[?25h[?25l
/[?12l[?25h解放[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[13;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[15;1H[93m    [m);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[38;5;224msearch hit BOTTOM, continuing at TOP[13;50H[?12l[?25h[?25l[m[25;1H[K[25;1H/[?12l[?25hfree[?25l[27m[m[H[2J[1;1H[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);;[2;1H[93m    [m/* vocab[1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[8;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未 [10;1H[93m    [m満かつaが0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /*  [15;1H[93m    [mハッシュを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }
[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struu[23;1H[93m    [mct vocab_word));
[93m168 [m  // Allocate memory for the binary tree construction[12;11H[?12l[?25h[?25l[25;1H/free[27m[m[H[2J[1;1H[93m172 [m  }
[93m173 [m}
[93m174 
175 [m// Reduces the vocabulary by removing infrequent tokens
[93m176 [mvoid ReduceVocab() {
[93m177 [m  int a, b = 0;
[93m178 [m  unsigned int hash;
[93m179 [m  for (a = 0; a < vocab_size; a++) if (vocab[a].cn > min_reduce) {
[93m180 [m    vocab[b].cn = vocab[a].cn;
[93m181 [m    vocab[b].word = vocab[a].word;
[93m182 [m    b++;
[93m183 [m  } else free(vocab[a].word);
[93m184 [m  vocab_size = b;
[93m185 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m186 [m  for (a = 0; a < vocab_size; a++) {
[93m187 [m    // Hash will be re-computed, as it is not actual
[93m188 [m    hash = GetWordHash(vocab[a].word);
[93m189 [m    while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m190 [m    vocab_hash[hash] = a;
[93m191 [m  }
[93m192 [m  fflush(stdout);
[93m193 [m  min_reduce++;
[93m194 [m}
[93m195 [12;14H[?12l[?25h[?25l[m[25;1H/free[27m[m[H[2J[1;1H[93m248 [m      b = parent_node[b]; /* bにparent_nodeを代入 */
[93m249 [m      if (b == vocab_size * 2 - 2) break; /* b == vocab_size * 2 - 2の時無限 [3;1H[93m    [mループから脱出 */
[93m250 [m    }
[93m251 [m    vocab[a].codelen = i;
[93m252 [m    vocab[a].point[0] = vocab_size - 2;
[93m253 [m    for (b = 0; b < i; b++) {
[93m254 [m      vocab[a].code[i - b - 1] = code[b];
[93m255 [m      vocab[a].point[i - b] = point[b] - vocab_size;
[93m256 [m    }
[93m257 [m  }
[93m258 [m  free(count);
[93m259 [m  free(binary);
[93m260 [m  free(parent_node);
[93m261 [m}
[93m262 
263 [mvoid LearnVocabFromTrainFile() {
[93m264 [m  char word[MAX_STRING];
[93m265 [m  FILE *fin;
[93m266 [m  long long a, i;
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m268 [m  fin = fopen(train_file, "rb");
[93m269 [m  if (fin == NULL) {
[93m270 [m    printf("ERROR: training data file not found!\n");[12;7H[?12l[?25hfre[?25le[46m([mcount[46m)[12;11H[?12l[?25h[?25l[m(count)[?12l[?25hcoun[?25l[46m([mcount[46m)[?12l[?25h[?25l[m(count)[?12l[?25h[?25l[25;1H[1m-- INSERT --[12;19H[?12l[?25h[?25l[m [?12l[?25h[?25l ?[?12l[?25h[?25l[12;20H[K[12;20H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lut */[?12l[?25h[?25lu */[12;29H[K[12;26H[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25lt分 */[?12l[?25h[?25lの */[?12l[?25h[?25lメモリ */[?12l[?25h[?25lを */[?12l[?25h[?25l解放 */[?12l[?25h[?25l[11;8H[?12l[?25h[12;44H[13;20H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l i */[?12l[?25h[?25l  */[13;27H[K[13;24H[?12l[?25h[?25l b */[?12l[?25h[?25lbi */[?12l[?25h[?25lin */[?12l[?25h[?25lna */[?12l[?25h[?25lar */[?12l[?25h[?25lry */[?12l[?25h[?25ly分の */[?12l[?25h[?25lメモリ */[?12l[?25h[?25lを */[?12l[?25h[?25l解放 */[?12l[?25h[14;25H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/+[?12l[?25h[?25l[14;27H[K[14;27H[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l p */[?12l[?25h[?25lpa */[?12l[?25h[?25lar */[?12l[?25h[?25lre */[?12l[?25h[?25len */[?12l[?25h[?25lnt */[?12l[?25h[?25lt_ */[?12l[?25h[?25l_n */[?12l[?25h[?25lno */[?12l[?25h[?25lod */[?12l[?25h[?25lde */[?12l[?25h[?25le分 */[?12l[?25h[?25lの */[?12l[?25h[?25lメモリ */[?12l[?25h[?25lを */[?12l[?25h[?25l解放 */[?12l[?25h[?25l[15;6H[?12l[?25h[16;5H[?25l[17;37H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loi */[?12l[?25h[?25lid */[?12l[?25h[?25ld型 */[?12l[?25h[?25l関数 */[?12l[?25h[?25lL */[?12l[?25h[?25lLe */[?12l[?25h[?25lea */[?12l[?25h[?25lan */[?12l[?25h[?25lnv */[?12l[?25h[?25ln */[17;58H[K[17;55H[?12l[?25h[?25la */[17;57H[K[17;54H[?12l[?25h[?25lar */[?12l[?25h[?25lrn */[?12l[?25h[?25lnV */[?12l[?25h[?25lVo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lbF */[?12l[?25h[?25lFr */[?12l[?25h[?25lro */[?12l[?25h[?25lom */[?12l[?25h[?25lmT */[?12l[?25h[?25lTr */[?12l[?25h[?25lri */[?12l[?25h[?25lin */[?12l[?25h[?25li */[17;71H[K[17;68H[?12l[?25h[?25lr */[17;70H[K[17;67H[?12l[?25h[?25lra */[?12l[?25h[?25lai */[?12l[?25h[?25lin */[?12l[?25h[?25lnF */[?12l[?25h[?25lFi */[?12l[?25h[?25lil */[?12l[?25h[?25lle */[?12l[?25h[?25le( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l()[18;29H[?12l[?25h[?25l[17;74H[46m()[?12l[?25h[?25l[m()の */[17;78H[?12l[?25h[?25l[18;24r[18;1H[L[1;25r[17;78H宣[94m>>[m[18;1H[93m    [m言 */[?12l[?25h[?25l[17;80H  [18;1H[93m    [m*/[18;8H[K[17;80H[?12l[?25h[?25l[17;24r[24;1H
[1;25r[17;1H[93m263 [mvoid LearnVocabFromTrainFile() { /* void型関数LearnVocabFromTrainFile()の */[24;1H[93m270 [m    printf("ERROR: training data file not found!\n");[17;78H[?12l[?25h[?25l[46m()[m */[17;79H[K[17;76H[?12l[?25h[?25l()[18;29H[?12l[?25h[19;17H[?25l;/[?12l[?25h[?25l[19;17H[K[19;17H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[25;1H[K[19;23H[?25l[?12l[?25h[?25l[25;1H/[?12l[?25hFI[?25l[25;3H[K[25;3H[?12l[?25h[?25l[25;2H[K[25;2H[?12l[?25hファイル[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boo[12;1H[93m    [mundaries /* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見[94m>>[m[13;1H[93m    [mなす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポイン [15;1H[93m    [mタfinが引数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にル[94m>>[m[18;1H[93m    [mープ終了 */
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行が[94m>>[m[22;1H[93m    [mある場合 */
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却し[24;1H[94m@                                                                               [m[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[12;17H[?12l[?25h[14;5H[?25l[m[25;1H/ファイル[25;10H[K[25;1H[14;67H[?12l[?25h[?25l[25;1H[17;31H[?12l[?25h[?25l[25;1H[K[25;1H:[?12l[?25h20[?25l[25;3H[K[25;3H[?12l[?25h10[?25l[27m[m[H[2J[1;1H[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(loo[2;1H[93m    [mng long)); /* long long型ポインタparent_nodeに(vocab_size * 2 * 1) * (long ll[3;1H[93m    [mong)分のメモリを確保 */
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn; /* ポインタcount[94m>>[m[5;1H[93m    [mの0 <= a < vocab_size番目ににvocab[a].cnを代入 */
[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15; /* ポインタ [7;1H[93m    [mcountのvocab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */
[93m206 [m  pos1 = vocab_size - 1;
[93m207 [m  pos2 = vocab_size;
[93m208 [m  // Following algorithm constructs the Huffman tree by adding one node at aa[11;1H[93m    [m time /* ノードをa回追加してHuffman木を構成するアルゴリズム */
[93m209 [m  for (a = 0; a < vocab_size - 1; a++) {
[93m210 [m    // First, find two smallest nodes 'min1, min2' /* まず2つの最小ノード'mii[14;1H[93m    [mn1, min2'を探す */
[93m211 [m    if (pos1 >= 0) { /* pos1(最初はvocab_size-1)が非負の時 */
[93m212 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpoo[17;1H[93m    [ms1 = vocab_size - 1, pos2 = vocab_size)の時 */
[93m213 [m[7C min1i = pos1; /* long long型min1iにpos1を代入 */
[93m214 [m[7C pos1--;
[93m215 [m      } else { /* count[pos1] >= count[pos2]の時 */
[93m216 [m[7C min1i = pos2;
[93m217 [m[7C pos2++;
[93m218 [m      }
[93m219 [m    } else { /* pos1が負の時 */[13;9H[?12l[?25h[?25l[25;1H/ファイル[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boo[12;1H[93m    [mundaries /* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見[94m>>[m[13;1H[93m    [mなす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポイン [15;1H[93m    [mタfinが引数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にル[94m>>[m[18;1H[93m    [mープ終了 */
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行が[94m>>[m[22;1H[93m    [mある場合 */
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却し[24;1H[94m@                                                                               [m[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[12;17H[?12l[?25h[?25l[m[25;1H/ファイル[25;10H[K[25;1H[14;67H[?12l[?25h[?25l[25;1H[K[25;1H:[?12l[?25h220[?25l[27m[m[H[2J[1;1H[93m210 [m    // First, find two smallest nodes 'min1, min2' /* まず2つの最小ノード'mii[2;1H[93m    [mn1, min2'を探す */
[93m211 [m    if (pos1 >= 0) { /* pos1(最初はvocab_size-1)が非負の時 */
[93m212 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpoo[5;1H[93m    [ms1 = vocab_size - 1, pos2 = vocab_size)の時 */
[93m213 [m[7C min1i = pos1; /* long long型min1iにpos1を代入 */
[93m214 [m[7C pos1--;
[93m215 [m      } else { /* count[pos1] >= count[pos2]の時 */
[93m216 [m[7C min1i = pos2;
[93m217 [m[7C pos2++;
[93m218 [m      }
[93m219 [m    } else { /* pos1が負の時 */
[93m220 [m      min1i = pos2;
[93m221 [m      pos2++;
[93m222 [m    }
[93m223 [m    if (pos1 >= 0) {
[93m224 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpoo[18;1H[93m    [mos1 = vocab_size - 1, pos2 = vocab_size)の時 */
[93m225 [m[7C min2i = pos1; /* long long型min2iにpos1を代入 */
[93m226 [m[7C pos1--;
[93m227 [m      } else { /* count[pos1] >= count[pos2]の時 */
[93m228 [m[7C min2i = pos2;
[93m229 [m[7C pos2++;
[93m230 [m      }[13;11H[?12l[?25h[?25l[25;1H/ファイル[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boo[12;1H[93m    [mundaries /* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見[94m>>[m[13;1H[93m    [mなす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポイン [15;1H[93m    [mタfinが引数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にル[94m>>[m[18;1H[93m    [mープ終了 */
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行が[94m>>[m[22;1H[93m    [mある場合 */
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却し[24;1H[94m@                                                                               [m[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[12;17H[?12l[?25h[?25l[m[25;1H/ファイル[25;10H[K[25;1H[14;67H[?12l[?25h[?25l[25;1H[K[25;1H:[?12l[?25h220[?25l[25;4H[K[25;4H[?12l[?25h[?25l[25;3H[K[25;3H[?12l[?25h30[?25l[27m[m[H[2J[1;1H[93m220 [m      min1i = pos2;
[93m221 [m      pos2++;
[93m222 [m    }
[93m223 [m    if (pos1 >= 0) {
[93m224 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpoo[6;1H[93m    [mos1 = vocab_size - 1, pos2 = vocab_size)の時 */
[93m225 [m[7C min2i = pos1; /* long long型min2iにpos1を代入 */
[93m226 [m[7C pos1--;
[93m227 [m      } else { /* count[pos1] >= count[pos2]の時 */
[93m228 [m[7C min2i = pos2;
[93m229 [m[7C pos2++;
[93m230 [m      }
[93m231 [m    } else { /* pos1が負の時 */
[93m232 [m      min2i = pos2;
[93m233 [m      pos2++;
[93m234 [m    }
[93m235 [m    count[vocab_size + a] = count[min1i] + count[min2i]; /* count[vocab_sizee[18;1H[93m    [m + a]にcount[min1i] + count[min2i]を代入 */
[93m236 [m    parent_node[min1i] = vocab_size + a; /* min1iの親ノードにvocab_size + a  [20;1H[93m    [mを代入 */
[93m237 [m    parent_node[min2i] = vocab_size + a; /* min2iの親ノードにvocab_size + a  [22;1H[93m    [mを代入 */
[93m238 [m    binary[min2i] = 1;
[93m239 [m  }[12;11H[?12l[?25h[13;11H[14;11H[15;11H[?25l[13;16H[46m{[16;9H}[?12l[?25h[?25l[m[13;16H{[16;9H}[17;11H[?12l[?25h[19;11H[21;11H[23;11H[24;7H[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m240 [m  // Now assign binary code to each vocabulary word /* 語彙の各単語に二進法[94m>>[m[24;1H[93m    [mコードを割当 */[23;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m241 [m  for [46m([ma = 0; a < vocab_size; a++[46m)[m { /* 0 <= a < vocab_sizeの時 */[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[23;11H([26C)
[93m242 [m    b = a;[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m243 [m    i = 0;
[93m244 [m    while (1) { /* 無限ループ */[23;11H[?12l[?25h[24;11H[?25l[1;24r[24;1H
[1;25r[24;1H[93m245 [m      code[i] = binary[b]; /* code[i]にbinary[b](最初はb=a)を代入 */[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m246 [m      point[i] = b; /* pont[i]にbを代入*/[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m247 [m      i++;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m248 [m      b = parent_node[b]; /* bにparent_nodeを代入 */[24;11H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m249 [m      if (b == vocab_size * 2 - 2) break; /* b == vocab_size * 2 - 2の時無限[24;1H[93m    [mループから脱出 */[23;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[17;19H[46m{[m[24;1H[93m250 [m    [46m}[?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[16;19H{[23;9H}
[93m251 [m    vocab[a].codelen = i;[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m252 [m    vocab[a].point[0] = vocab_size - 2;[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m253 [m    for (b = 0; b < i; b++) {[24;11H[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m254 [m      vocab[a].code[i - b - 1] = code[b];
[93m255 [m      vocab[a].point[i - b] = point[b] - vocab_size;[23;11H[?12l[?25h[24;11H[?25l[1;24r[1;1H[2M[1;25r[20;33H[46m{[m


[93m256 [m    [46m}[m
[93m257 [m  }[23;9H[?12l[?25h[?25l[7;40H[46m{[m[20;33H{[23;9H}[24;7H[46m}[?12l[?25h[?25l[1;24r[m[1;1H[2M[1;25r[5;40H{[22;7H}
[93m258 [m  free[46m([mcount[46m)[m; /* count分のメモリを解放 */
[93m259 [m  free(binary); /* binary分のメモリを解放 */[23;11H[?12l[?25h[?25l(count)[24;11H[46m([mbinary[46m)[24;11H[?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[23;11H(binary)
[93m260 [m  free[46m([mparent_node[46m)[m; /* parent_node分のメモリを解放 */[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[23;11H([11C)
[93m261 [m}[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[23;1H[93m262 
263 [mvoid LearnVocabFromTrainFile() { /* void型関数LearnVocabFromTrainFile() */[23;5H[?12l[?25h[24;11H[?25l[1;24r[24;1H
[1;25r[24;1H[93m264 [m  char word[MAX_STRING];[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m265 [m  FILE *fin; /*  */[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m266 [m  long long a, i;[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m267 [m  for [46m([ma = 0; a < vocab_hash_size; a++[46m)[m vocab_hash[a] = -1;[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[23;11H([31C)
[93m268 [m  fin = fopen(train_file, "rb");[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m269 [m  if (fin == NULL) {[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m270 [m    printf("ERROR: training data file not found!\n");[24;11H[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m271 [m    exit(1);[?12l[?25h[?25l[1;24r[1;1H[2M[1;25r[20;24H[46m{[m


[93m272 [m  [46m}[m
[93m273 [m  vocab_size = 0;[23;7H[?12l[?25h[?25l[20;24H{[23;7H}[22;11H[?12l[?25h[21;11H[20;11H[19;11H[?25l[18;11H[46m([31C)[18;11H[?12l[?25h[?25l[m([31C)[17;11H[?12l[?25h[16;11H *fin; /* [16;8HILE *fin; /* [?25l[25;1H[1m-- INSERT --[16;22H[?12l[?25h[?25l[m F */[?12l[?25h[?25lFI */[?12l[?25h[?25lIL */[?12l[?25h[?25lLE */[?12l[?25h[?25lE型 */[?12l[?25h[?25lポインタ */[?12l[?25h[?25lf */[?12l[?25h[?25lfi */[?12l[?25h[?25lin */[?12l[?25h[17;22H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l//[?12l[?25h[?25l/*/[?12l[?25h[?25l* /[?12l[?25h[?25l  /[?12l[?25h[?25l */[?12l[?25h[?25l l */[?12l[?25h[?25llo */[?12l[?25h[?25lon */[?12l[?25h[?25lng */[?12l[?25h[?25l  */[?12l[?25h[?25l l */[?12l[?25h[?25llo */[?12l[?25h[?25lon */[?12l[?25h[?25lng */[?12l[?25h[?25lg型 */[?12l[?25h[?25l変数 */[?12l[?25h[?25la */[?12l[?25h[?25la, */[?12l[?25h[?25l  */[?12l[?25h[?25l i */[?12l[?25h[16;41H[15;29H[16;41H[17;45H[16;41H[15;29H[16;41H[17;45H[18;45Hvocab_has[?25lh[46m[[ma[46m][?12l[?25h[?25l[[?12l[?25h[?25l[ma[?12l[?25h[?25l[1C[?12l[?25h[?25l[a] [?12l[?25h= -1;[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 0 */[?12l[?25h[?25l  */[?12l[?25h[?25l < */[?12l[?25h[?25l<= */[?12l[?25h[?25l  */[?12l[?25h[?25l 1 */[?12l[?25h[?25l  */[?12l[?25h[?25l */[18;77H[K[18;74H[?12l[?25h[?25l  */[18;76H[K[18;73H[?12l[?25h[?25l a */[?12l[?25h[?25l  */[?12l[?25h[?25l < */[?12l[?25h[?25l  */[?12l[?25h[?25l v */[18;78H[?12l[?25h[?25l[19;24r[19;1H[L[1;25r[18;77Hvo **[19;1H[93m    [m/[18;79H[?12l[?25h[?25loc  [19;1H[93m    [m*/[18;80H[?12l[?25h[?25lcaa[19;1H[93m    [m */[?12l[?25h[?25l[93m [mb */[?12l[?25h[?25l[93m [m */[19;8H[K[19;5H[?12l[?25h[?25l[18;79Hc  [19;1H[93m    [m*/[19;7H[K[18;80H[?12l[?25h[?25lcaa[19;1H[93m    [m */[?12l[?25h[?25l[93m [mb */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_h */[?12l[?25h[?25lha */[?12l[?25h[?25las */[?12l[?25h[?25lsh */[?12l[?25h[?25lh_ */[?12l[?25h[?25l_s */[?12l[?25h[?25lsi */[?12l[?25h[?25liz */[?12l[?25h[?25lze */[?12l[?25h[?25leの */[?12l[?25h[?25l時 */[?12l[?25h[?25lv */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_h */[?12l[?25h[?25lha */[?12l[?25h[?25las */[?12l[?25h[?25lsh */[?12l[?25h[?25lh[ */[?12l[?25h[?25l[a */[?12l[?25h[?25l[46m[[ma[46m][m */[?12l[?25h[?25l[a]  */[?12l[?25h[?25l = */[?12l[?25h[?25l  */[?12l[?25h[?25l */[19;38H[K[19;35H[?12l[?25h[?25l  */[19;37H[K[19;34H[?12l[?25h[?25l[46m[[ma[46m][m */[19;36H[K[19;33H[?12l[?25h[?25l[a]に */[?12l[?25h[?25l0 */[?12l[?25h[?25l01 */[?12l[?25h[?25l0 */[19;39H[K[19;36H[?12l[?25h[?25l */[19;38H[K[19;35H[?12l[?25h[?25l- */[?12l[?25h[?25l-1 */[?12l[?25h[?25l1を */[?12l[?25h[?25l代入 */[?12l[?25h[20;37H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l[21;24H[46m{[24;7H}[21;25H[?12l[?25h[?25l[m{a[24;7H}[21;26H[?12l[?25h[?25l[46m{[m[21;25H[K[24;7H[46m}[21;25H[?12l[?25h[?25l[m{[24;7H}[21;26H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l f */[?12l[?25h[?25l  */[21;32H[K[21;29H[?12l[?25h[?25l ポインタ */[?12l[?25h[2C[2C[2C[2C[?25lf */[?12l[?25h[?25lfi */[?12l[?25h[?25lin */[?12l[?25h[?25lnが */[?12l[?25h[?25lN */[?12l[?25h[?25lNU */[?12l[?25h[?25lUL */[?12l[?25h[?25lLL */[?12l[?25h[?25lLの */[?12l[?25h[?25l時 */[?12l[?25h[20;43H[?25l  */[?12l[?25h[?25l t */[?12l[?25h[?25ltr */[?12l[?25h[?25lra */[?12l[?25h[?25lai */[?12l[?25h[?25lin */[?12l[?25h[?25ln_ */[?12l[?25h[?25l_f */[?12l[?25h[?25lfi */[?12l[?25h[?25lil */[?12l[?25h[?25lle */[?12l[?25h[?25leを */[?12l[?25h[?25l読込 */[?12l[?25h[?25lモード */[?12l[?25h[?25lで */[?12l[?25h[?25l開く */[?12l[?25h[21;53H[22;58H[23;17H[?25l[21;24H[46m{[24;7H}[?12l[?25h[?25l[1;24r[m[24;1H
[1;25r[20;24H{[23;7H}
[93m273 [m  vocab_size = 0;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m274 [m  AddWordToVocab((char *)"</s>");[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m275 [m  while (1) {[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m276 [m    ReadWord(word, fin);[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m277 [m    if (feof(fin)) break;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m278 [m    train_words++;[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) {[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m280 [m      printf("%lldK%c", train_words / 1000, 13);[?12l[?25h[?25l[1;24r[24;1H
[1;25r[24;1H[93m281 [m      fflush(stdout);[?12l[?25h[23;53H[?25l[22;63H[?12l[?25h[21;23H[20;30H[19;29H[?25l[18;18H[?12l[?25h[17;38H[16;22H[?25l[12;24H[46m{[15;7H}[?12l[?25h[?25l[m[12;24H{[15;7H}[16;22H[?12l[?25h[17;38H[?25l;/[?12l[?25h[?25l[17;38H[K[17;38H[?12l[?25h[25;1H[K[17;37H[?25l[?12l[?25h[?25l[25;1H/[?12l[?25hADD[?25l[25;4H[K[25;4H[?12l[?25h[?25l[25;3H[K[25;3H[?12l[?25hddWordToVocab[?25l[1;24r[1;1H[4M[1;25r[21;1H[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);[25;1H[K[24;15H[?12l[?25h[?25l
?AddWordToVocab[13;7H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[2;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル[5;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[12;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[14;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[16;1H[93m    [mきい場合はlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個[18;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコ[94m>>[m[20;1H[93m    [mピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */
[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */
[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */
[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size[94m>[24;1H@                                                                               [11;80H[?12l[?25h[?25l[m[25;1H/AddWordToVocab[27m[m[H[2J[1;1H[93m264 [m  char word[MAX_STRING];
[93m265 [m  FILE *fin; /* FILE型ポインタfin */
[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocaa[5;1H[93m    [mb_hash_sizeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>");
[93m275 [m  while (1) {
[93m276 [m    ReadWord(word, fin);
[93m277 [m    if (feof(fin)) break;
[93m278 [m    train_words++;
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) {
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;[12;7H[?12l[?25hAddWordToVoca[?25lb[46m([14C)[12;21H[?12l[?25h[?25l[m([46m([mchar *[46m)[m"</s>")[12;22H[?12l[?25h[?25l(char *)[12;23H[?12l[?25hchar [?25l[46m([mchar *[46m)[?12l[?25h[?25l[m[12;22H(char *)[?12l[?25h"</[?25l[25;1H?AddWordToVocab[12;7H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[2;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル[5;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[12;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[14;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[16;1H[93m    [mきい場合はlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個[18;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコ[94m>>[m[20;1H[93m    [mピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */
[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */
[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */
[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size[94m>[24;1H@                                                                               [11;80H[?12l[?25h[?25l[m[25;1H/AddWordToVocab[27m[m[H[2J[1;1H[93m264 [m  char word[MAX_STRING];
[93m265 [m  FILE *fin; /* FILE型ポインタfin */
[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocaa[5;1H[93m    [mb_hash_sizeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>");
[93m275 [m  while (1) {
[93m276 [m    ReadWord(word, fin);
[93m277 [m    if (feof(fin)) break;
[93m278 [m    train_words++;
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) {
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;[12;7H[?12l[?25hAddWordToVoca[?25lb[46m([14C)[12;21H[?12l[?25h[?25l[m([46m([mchar *[46m)[m"</s>")[12;22H[?12l[?25h[?25l(char *)[12;23H[?12l[?25hchar [?25l[46m([mchar *[46m)[?12l[?25h[?25l[m[12;22H(char *)[?12l[?25h"</s>[?25l[12;21H[46m([14C)[?12l[?25h[?25l[m[12;21H([14C)[?12l[?25h[?25l[25;1H[1m-- INSERT --[12;38H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l A */[?12l[?25h[?25lAd */[?12l[?25h[?25ldd */[?12l[?25h[?25ldW */[?12l[?25h[?25lWo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25ldT */[?12l[?25h[?25lTo */[?12l[?25h[?25loV */[?12l[?25h[?25lVo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25l 単語AddWordToVocab */[12;46H[?12l[?25h[?25lをAddWordToVocab */[12;48H[?12l[?25h[?25l語彙にAddWordToVocab */[12;54H[?12l[?25h[?25l加えるAddWordToVocab */[12;60H[?12l[?25h[?25l関数AddWordToVocab */[12;64H[?12l[?25h[?25l[13;18H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [?25l 無限ループ */[?12l[?25h[25;1H[K[13;30H[?25l[?12l[?25h[?25l[25;1H/[?12l[?25hReadWord[?25l[14;9H[?12l[?25h[?25l[25;1H?[27m[m[H[2J[1;1H[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sii[2;1H[93m    [mzeを返す */
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語[94m>>[m[8;1H[93m    [m彙中での単語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[10;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル[13;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[20;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[22;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[24;1H[93m    [mきい場合はlenghに最大文字数を代入 */[12;43H[?12l[?25h[?25l[25;1H?ReadWord[12;7H[?12l[?25h[?25l[25;1H[9;79H[?12l[?25h[?25l[25;1H[9;9H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boo[10;1H[93m    [mundaries /* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見[94m>>[m[11;1H[93m    [mなす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポイン[13;1H[93m    [mタfinが引数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にル[94m>>[m[16;1H[93m    [mープ終了 */
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行が[94m>>[m[20;1H[93m    [mある場合 */
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却し[23;1H[93m    [mchを返す */
[93m 80 [m[7C break;[13;28H[?12l[?25h[?25l[25;1H?ReadWord[12;10H[?12l[?25h[?25l[25;1H[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SECC[3;1H[93m    [m * 1000));
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train__[7;1H[93m    [mwords + 1));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;
[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) {
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break;
[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break;
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping thh[18;1H[93m    [me ranking same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (([21;1H[93m    [msample * train_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[38;5;224msearch hit TOP, continuing at BOTTOM[12;20H[?12l[?25h[?25l[m[25;1H/ReadWord[25;10H[K[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boo[10;1H[93m    [mundaries /* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見[94m>>[m[11;1H[93m    [mなす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポイン[13;1H[93m    [mタfinが引数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にル[94m>>[m[16;1H[93m    [mープ終了 */
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行が[94m>>[m[20;1H[93m    [mある場合 */
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却し[23;1H[93m    [mchを返す */
[93m 80 [m[7C break;
[38;5;224msearch hit BOTTOM, continuing at TOP[12;10H[?12l[?25h[?25l[m[25;1H?ReadWord[25;10H[K[25;1H[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SECC[3;1H[93m    [m * 1000));
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train__[7;1H[93m    [mwords + 1));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;
[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) {
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break;
[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break;
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping thh[18;1H[93m    [me ranking same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (([21;1H[93m    [msample * train_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[38;5;224msearch hit TOP, continuing at BOTTOM[12;20H[?12l[?25h[?25l[m[25;1H?ReadWord[25;10H[K[25;1H[27m[m[H[2J[1;1H[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb");
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) {
[93m318 [m    ReadWord(word, fin);
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {[12;9H[?12l[?25h[?25l[25;1H/ReadWord[27m[m[H[2J[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SECC[3;1H[93m    [m * 1000));
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train__[7;1H[93m    [mwords + 1));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;
[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) {
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break;
[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break;
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping thh[18;1H[93m    [me ranking same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (([21;1H[93m    [msample * train_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }[12;20H[?12l[?25h[?25l[25;1H/ReadWord[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boo[10;1H[93m    [mundaries /* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見[94m>>[m[11;1H[93m    [mなす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポイン[13;1H[93m    [mタfinが引数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にル[94m>>[m[16;1H[93m    [mープ終了 */
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行が[94m>>[m[20;1H[93m    [mある場合 */
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却し[23;1H[93m    [mchを返す */
[93m 80 [m[7C break;
[38;5;224msearch hit BOTTOM, continuing at TOP[12;10H[?12l[?25h[?25l[m[25;1H/ReadWord[25;10H[K[25;1H[13;28H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]][2;1H[93m    [m; /* 文字列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返[94m>>[m[3;1H[93m    [mす */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sii[5;1H[93m    [mzeを返す */
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語[94m>>[m[11;1H[93m    [m彙中での単語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[13;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル [16;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[23;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(w[24;1H[94m@                                                                               [12;9H[?12l[?25h[?25l[m[25;1H/ReadWord[12;79H[?12l[?25h[?25l[25;1H[15;7H[?12l[?25h[?25l[25;1H[15;43H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocaa[3;1H[93m    [mb_hash_sizeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */[11;1H[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin);
[93m277 [m    if (feof(fin)) break;
[93m278 [m    train_words++;
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) {
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();[12;9H[?12l[?25h[?25l[25;1H/ReadWord[27m[m[H[2J[1;1H[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb");
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) {
[93m318 [m    ReadWord(word, fin);
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {[12;9H[?12l[?25h[?25l[25;1H/ReadWord[27m[m[H[2J[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SECC[3;1H[93m    [m * 1000));
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train__[7;1H[93m    [mwords + 1));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;
[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) {
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break;
[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break;
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping thh[18;1H[93m    [me ranking same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (([21;1H[93m    [msample * train_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }[12;20H[?12l[?25h[?25l[25;1H?ReadWord[27m[m[H[2J[1;1H[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb");
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) {
[93m318 [m    ReadWord(word, fin);
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {[12;9H[?12l[?25h[?25l[25;1H?ReadWord[27m[m[H[2J[1;1H[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocaa[3;1H[93m    [mb_hash_sizeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */[11;1H[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin);
[93m277 [m    if (feof(fin)) break;
[93m278 [m    train_words++;
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) {
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();[12;9H[?12l[?25hReadWor[?25ld[46m([9C)[12;17H[?12l[?25h[?25l[m([9C)[12;18H[?12l[?25hword, fi[?25l[12;17H[46m([9C)[?12l[?25h[?25l[m[12;17H([9C)[?12l[?25h[?25l[25;1H[1m-- INSERT --[12;29H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 7 */[?12l[?25h[?25l72 */[?12l[?25h[?25l2行目 */[?12l[?25h[?25lで */[?12l[?25h[?25l定義した */[?12l[?25h[?25lR */[?12l[?25h[?25lRe */[?12l[?25h[?25lea */[?12l[?25h[?25lad */[?12l[?25h[?25ldW */[?12l[?25h[?25lWo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25ld関数 */[?12l[?25h[?25lで */[?12l[?25hord[2C[2C[2C[?25lt */[?12l[?25h[?25ltr */[?12l[?25h[?25lra */[?12l[?25h[?25lai */[?12l[?25h[?25lin */[?12l[?25h[?25ln_ */[?12l[?25h[?25l_f */[?12l[?25h[?25lfi */[?12l[?25h[?25lil */[?12l[?25h[?25lle */[?12l[?25h[?25leの */[?12l[?25h[?25l[13;24r[13;1H[L[1;25r[12;75H単語を[13;1H[93m    [m */[?12l[?25h[?25l[93m [m読み込む */[?12l[?25h[14;30H[25;1H[K[14;29H[?25l[?12l[?25h[14;9H[?25l[25;1H/[?12l[?25hfeof(fin[?25l[14;13H[?12l[?25h[?25l[25;1H?[27m[m[H[2J[1;1H[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語[94m>>[m[6;1H[93m    [m彙中での単語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[8;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル [11;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[18;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[20;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[22;1H[93m    [mきい場合はlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個[24;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */[12;11H[?12l[?25h[?25l[25;1H/feof(fin[27m[m[H[2J[1;1H[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocaa[2;1H[93m    [mb_hash_sizeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */[10;1H[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を[12;1H[93m    [m読み込む */
[93m277 [m    if (feof(fin)) break;
[93m278 [m    train_words++;
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) {
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();[13;13H[?12l[?25hfeo[?25lf[46m([mfin[46m)[?12l[?25h[?25l[m(fin)[?12l[?25hfi[?25l[46m([mfin[46m)[?12l[?25h[?25l[13;12H([mfeof(fin)[46m)[?12l[?25h[?25l[m[13;12H([9C)[?12l[?25h break[?25l[25;1H[1m-- INSERT --[13;30H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l ファイル */[?12l[?25h[?25lポインタ */[?12l[?25h[?25lが */[?12l[?25h[?25l終端 */[?12l[?25h[?25lに */[?12l[?25h[?25l達した時 */[?12l[?25h[?25l[14;24r[14;1H[L[1;25r[13;66H無限ループから  [14;1H[93m    [m*/[13;80H[?12l[?25h[?25l[94m>>[m[14;1H[93m    [m脱出 */[?12l[?25h[15;23H[25;1H[K[15;22H[?25l[?12l[?25h[?25l[25;1H/[?12l[?25htrain_words[?25l[16;34H[?12l[?25h[?25l[25;1H?[15;9H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[2;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未 [4;1H[93m    [m満かつaが0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /*  [9;1H[93m    [mハッシュを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }
[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struu[17;1H[93m    [mct vocab_word));
[93m168 [m  // Allocate memory for the binary tree construction
[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));
[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 [13;11H[?12l[?25h[?25l[m[25;1H/train_words[27m[m[H[2J[1;1H[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */[7;1H[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を[9;1H[93m    [m読み込む */
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから[94m>>[m[11;1H[93m    [m脱出 */
[93m278 [m    train_words++;
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) {
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();[12;9H[?12l[?25h[?25l[25;1H?train_words[27m[m[H[2J[1;1H[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[2;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未 [4;1H[93m    [m満かつaが0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /*  [9;1H[93m    [mハッシュを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }
[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struu[17;1H[93m    [mct vocab_word));
[93m168 [m  // Allocate memory for the binary tree construction
[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));
[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 [13;11H[?12l[?25h[?25l[m[25;1H?train_words[1;24r[1;1H[2L[1;25r[1;1H[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {[25;1H[K[1;7H[?12l[?25h[?25l[25;1H?train_words[27m[m[H[2J[1;1H[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[3;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[5;1H[93m    [m);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boo[19;1H[93m    [mundaries /* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見[94m>>[m[20;1H[93m    [mなす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポイン[22;1H[93m    [mタfinが引数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にル[94m>[24;1H@                                                                               [12;43H[?12l[?25h[?25l[m[25;1H?train_words[7;38H[?12l[?25h[?25l[25;1H[4;40H[?12l[?25h[?25l[25;1H[1;24r[1;1H[L[1;25r[1;1H[93m 55 [m  double train_words_pow = 0;[25;1H[K[1;14H[?12l[?25h[?25l[25;1H?train_words[27m[m[H[2J[1;1H[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[2;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */
[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは[4;1H[93m    [m変数だからvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ [5;1H[93m    [m)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[7;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [10;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[12;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;[11;15H[?12l[?25h[?25l[25;1H/train_words[23;14H[?12l[?25h[?25l

[1;24r[1;1H[5M[1;25r[20;1H[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[21;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[23;1H[93m    [m);
[93m 59 [m  i = 0;[25;1H[K[22;40H[?12l[?25h[?25l


/train_words[1;24r[1;1H[2M[1;25r[23;1H[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {[25;1H[K[23;38H[?12l[?25h[?25l

/train_words[1;24r[1;1H[5M[1;25r[20;1H[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }[25;1H[K[23;43H[?12l[?25h[?25l

?train_words[18;38H[?12l[?25h[?25l[25;1H[15;40H[?12l[?25h[?25l[25;1H[11;14H[?12l[?25h[?25l[25;1H[1;24r[1;1H[2L[1;25r[1;1H[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[2;1H[93m    [mlasses = 0;[25;1H[K[1;15H[?12l[?25h[?25l[25;1H?train_words[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (([2;1H[93m    [msample * train_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;
[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;
[93m412 [m      last_word_count = 0;
[93m413 [m      sentence_length = 0;
[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SETT[20;1H[93m    [m);
[93m415 [m      continue;
[93m416 [m    }
[93m417 [m    word = sen[sentence_position];
[93m418 [m    if (word == -1) continue;
[38;5;224msearch hit TOP, continuing at BOTTOM[12;39H[?12l[?25h[?25l[m[25;1H?train_words[25;13H[K[25;1H[2;14H[?12l[?25h[?25l[25;1H[1;59H[?12l[?25h[?25l[25;1H/[2;14H[?12l[?25h[?25l[25;1H[12;39H[?12l[?25h[?25l[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[2;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */
[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは [4;1H[93m    [m変数だからvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ[5;1H[93m    [m)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[7;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [10;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[12;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[38;5;224msearch hit BOTTOM, continuing at TOP[11;15H[?12l[?25h[?25l[m[25;1H?train_words[25;13H[K[25;1H[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (([2;1H[93m    [msample * train_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;
[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;
[93m412 [m      last_word_count = 0;
[93m413 [m      sentence_length = 0;
[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SETT[20;1H[93m    [m);
[93m415 [m      continue;
[93m416 [m    }
[93m417 [m    word = sen[sentence_position];
[93m418 [m    if (word == -1) continue;
[38;5;224msearch hit TOP, continuing at BOTTOM[12;39H[?12l[?25h[?25l[m[25;1H?train_words[25;13H[K[25;1H[2;14H[?12l[?25h[?25l[25;1H[1;59H[?12l[?25h[?25l[25;1H/[2;14H[?12l[?25h[?25l[25;1H[12;39H[?12l[?25h[?25l[25;1H[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[2;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */
[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは [4;1H[93m    [m変数だからvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ[5;1H[93m    [m)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[7;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [10;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[12;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[38;5;224msearch hit BOTTOM, continuing at TOP[11;15H[?12l[?25h[?25l[m[25;1H/train_words[25;13H[K[25;1H[23;14H[?12l[?25h[?25l

[1;24r[1;1H[5M[1;25r[20;1H[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(inn[21;1H[93m    [mt)分のメモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, powerr[23;1H[93m    [m);
[93m 59 [m  i = 0;[25;1H[K[22;40H[?12l[?25h[?25l


/train_words[1;24r[1;1H[2M[1;25r[23;1H[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {[25;1H[K[23;38H[?12l[?25h[?25l

/train_words[1;24r[1;1H[5M[1;25r[20;1H[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }[25;1H[K[23;43H[?12l[?25h[?25l

/train_words[27m[m[H[2J[1;1H[93m145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用い [2;1H[93m    [mて頻度順に並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替え[7;1H[93m    [mて文字列</s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);;[9;1H[93m    [m/* vocab[1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vv[15;1H[93m    [mocab /* min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未 [17;1H[93m    [m満かつaが0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /*  [22;1H[93m    [mハッシュを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;[12;7H[?12l[?25h[?25l[25;1H/train_words[1;24r[1;1H[2M[1;25r[23;1H[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;[25;1H[K[24;11H[?12l[?25h[?25l
/train_words[27m[m[H[2J[1;1H[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */[7;1H[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を [9;1H[93m    [m読み込む */
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから[94m>>[m[11;1H[93m    [m脱出 */
[93m278 [m    train_words++;
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) {
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();[12;9H[?12l[?25htrain_words++[?25l[25;1H[1m-- INSERT --[12;23H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l t */[?12l[?25h[?25ltr */[?12l[?25h[?25lra */[?12l[?25h[?25lai */[?12l[?25h[?25lin */[?12l[?25h[?25ln_ */[?12l[?25h[?25l_w */[?12l[?25h[?25lwo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25lds */[?12l[?25h[?25lsに */[?12l[?25h[?25l1 */[?12l[?25h[?25l1を */[?12l[?25h[?25l足す */[?12l[?25h[13;47H[14;47H[13;47H 100000 == [?25l[13;33H[46m([25C)[?12l[?25h[?25l[13;12H([m[20C([25C)[46m)[?12l[?25h[?25l)[?12l[?25h[?25l[m[13;12H([47C) [46m{[16;9H}[13;62H[?12l[?25h[?25l{[?12l[?25h[?25l[?12l[?25h[?25l[13;12H([47C)[m {[16;9H}[13;61H[?12l[?25h[?25l[13;12H([47C) [46m{[16;9H}[13;62H[?12l[?25h[?25l{[?12l[?25h[?25l[m{[16;9H}[13;64H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [?25l d */[?12l[?25h[?25lde */[?12l[?25h[?25leb */[?12l[?25h[?25lbu */[?12l[?25h[?25lug */[?12l[?25h[?25lg_ */[?12l[?25h[?25l_m */[?12l[?25h[?25lmo */[?12l[?25h[?25lod */[?12l[?25h[?25lde */[?12l[?25h[?25l  */[13;78H[?12l[?25h[?25l[14;24r[14;1H[L[1;25r[13;77H > **[14;1H[93m    [m/[13;79H[?12l[?25h[?25l   [14;1H[93m    [m*/[13;80H[?12l[?25h[?25l 11[14;1H[93m    [m */[?12l[?25h[?25l[93m [mかつ */[?12l[?25h[?25lt */[?12l[?25h[?25ltr */[?12l[?25h[?25lra */[?12l[?25h[?25lai */[?12l[?25h[?25lin */[?12l[?25h[?25ln_ */[?12l[?25h[?25l_w */[?12l[?25h[?25lwo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25lds */[?12l[?25h[?25lsが */[?12l[?25h[?25l1 */[?12l[?25h[?25l10 */[?12l[?25h[?25l00 */[?12l[?25h[?25l00 */[?12l[?25h[?25l00 */[?12l[?25h[?25l00 */[?12l[?25h[?25ls100000 */[14;29H[K[14;20H[?12l[?25h[?25lsが100000 */[14;22H[?12l[?25h100000[?25l0で */[?12l[?25h[?25l割り切れる */[?12l[?25h[?25l時 */[?12l[?25h[?25l切れる時 */[14;43H[K[14;32H[?12l[?25h[15;53H[16;26H[15;53H[16;26H[?25l[13;62H[46m{[m[17C11[14;1H[93m [m[17;9H[46m}[?12l[?25h[?25l[m[13;62H{[17C11[14;1H[93m [m[17;9H}[18;31H[?12l[?25h[25;1H[K[18;30H[?25l[?12l[?25h[?25l[25;1H/[?12l[?25hs[?25l[25;2H[K[25;2H[?12l[?25hSearchVocab[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 36 [m}; /* この段階で変数無し */
[93m 37 
 38 [mchar train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[4;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */
[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[6;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */
[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは[8;1H[93m    [m変数だからvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ [9;1H[93m    [m)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[11;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [14;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[16;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[38;5;224msearch hit BOTTOM, continuing at TOP[12;49H[?12l[?25h[?25l[m[25;1H/SearchVocab[25;13H[K[25;1H[27m[m[H[2J[1;1H[93m 96 [m  unsigned long long a, hash = 0; /* 符号無long long型a, hash */
[93m 97 [m  for (a = 0; a < strlen(word); a++) hash = hash * 257 + word[a]; /* aが文字 [3;1H[93m    [m列wordの文字長未満の時hashにhash * 257 + word[a]を代入 */
[93m 98 [m  hash = hash % vocab_hash_size; /* hashにhashをvocab_hash_sizeの剰余を代入  [5;1H[93m    [m*/
[93m 99 [m  return hash; /* hashを返す */
[93m100 [m}
[93m101 
102 [m// Returns position of a word in the vocabulary; if the word is not found, rr[10;1H[93m    [meturns -1 /* 語彙中の単語の位置を返す(単語が語彙中に無い場合は-1を返す) */
[93m103 [mint SearchVocab(char *word) { /* char型ポインタwordを引数に持つint型関数Searr[12;1H[93m    [mchVocab() */
[93m104 [m  unsigned int hash = GetWordHash(word); /* 符号無int型hashにwordのhash値を[94m>>[m[14;1H[93m    [m代入 */
[93m105 [m  while (1) { /* 無限ループ */
[93m106 [m    if (vocab_hash[hash] == -1) return -1; /* vocab_hash[hash]が-1の時-1を返[17;1H[93m    [mす */
[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]][19;1H[93m    [m; /* 文字列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返[94m>>[m[20;1H[93m    [mす */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sii[22;1H[93m    [mzeを返す */
[93m109 [m  }
[93m110 [m  return -1;[11;9H[?12l[?25h[?25l[25;1H/SearchVocab[11;77H[?12l[?25h[?25l[25;1H[1;24r[1;1H[12M[1;25r[13;1H[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語[94m>>[m[16;1H[93m    [m彙中での単語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[18;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル [21;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}[25;1H[K[23;14H[?12l[?25h[?25l

/SearchVocab[27m[m[H[2J[1;1H[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を [3;1H[93m    [m読み込む */
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから[94m>>[m[5;1H[93m    [m脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 11[8;1H[93m    [mかつtrain_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);[12;13H[?12l[?25h[?25l[25;1H?SearchVocab[27m[m[H[2J[1;1H[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語[94m>>[m[5;1H[93m    [m彙中での単語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[7;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル[10;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[17;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[19;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[21;1H[93m    [mきい場合はlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個 [23;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコ[94m>[24;1H@                                                                               [12;14H[?12l[?25h[?25l[m[25;1H?SearchVocab[1;24r[1;1H[13L[1;25r[1;1H[93m103 [mint SearchVocab(char *word) { /* char型ポインタwordを引数に持つint型関数Searr[2;1H[93m    [mchVocab() */
[93m104 [m  unsigned int hash = GetWordHash(word); /* 符号無int型hashにwordのhash値を[94m>>[m[4;1H[93m    [m代入 */
[93m105 [m  while (1) { /* 無限ループ */
[93m106 [m    if (vocab_hash[hash] == -1) return -1; /* vocab_hash[hash]が-1の時-1を返[7;1H[93m    [mす */
[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]][9;1H[93m    [m; /* 文字列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返[94m>>[m[10;1H[93m    [mす */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sii[12;1H[93m    [mzeを返す */
[93m109 [m  }[25;1H[K[1;77H[?12l[?25h[?25l[25;1H?SearchVocab[1;9H[?12l[?25h[?25l[25;1H[27m[m[H[2J[1;1H[93m 36 [m}; /* この段階で変数無し */
[93m 37 
 38 [mchar train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[4;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */
[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[6;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */
[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは [8;1H[93m    [m変数だからvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ [9;1H[93m    [m)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[11;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [14;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[16;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */[12;49H[?12l[?25h[?25l[25;1H/SearchVocab[27m[m[H[2J[1;1H[93m 96 [m  unsigned long long a, hash = 0; /* 符号無long long型a, hash */
[93m 97 [m  for (a = 0; a < strlen(word); a++) hash = hash * 257 + word[a]; /* aが文字 [3;1H[93m    [m列wordの文字長未満の時hashにhash * 257 + word[a]を代入 */
[93m 98 [m  hash = hash % vocab_hash_size; /* hashにhashをvocab_hash_sizeの剰余を代入  [5;1H[93m    [m*/
[93m 99 [m  return hash; /* hashを返す */
[93m100 [m}
[93m101 
102 [m// Returns position of a word in the vocabulary; if the word is not found, rr[10;1H[93m    [meturns -1 /* 語彙中の単語の位置を返す(単語が語彙中に無い場合は-1を返す) */
[93m103 [mint SearchVocab(char *word) { /* char型ポインタwordを引数に持つint型関数Searr[12;1H[93m    [mchVocab() */
[93m104 [m  unsigned int hash = GetWordHash(word); /* 符号無int型hashにwordのhash値を[94m>>[m[14;1H[93m    [m代入 */
[93m105 [m  while (1) { /* 無限ループ */
[93m106 [m    if (vocab_hash[hash] == -1) return -1; /* vocab_hash[hash]が-1の時-1を返 [17;1H[93m    [mす */
[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]][19;1H[93m    [m; /* 文字列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返[94m>>[m[20;1H[93m    [mす */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sii[22;1H[93m    [mzeを返す */
[93m109 [m  }
[93m110 [m  return -1;[11;9H[?12l[?25h[?25l[25;1H?SearchVocab[27m[m[H[2J[1;1H[93m 36 [m}; /* この段階で変数無し */
[93m 37 
 38 [mchar train_file[MAX_STRING], output_file[MAX_STRING]; /* 最大文字数MAX_STRINN[4;1H[93m    [mGを引数に持つchar型(1 byte文字型)train_fileとoutput_fileを宣言 */
[93m 39 [mchar save_vocab_file[MAX_STRING], read_vocab_file[MAX_STRING]; /* char型savee[6;1H[93m    [m_vocab_fileとread_vocab_fileを宣言 */
[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは [8;1H[93m    [m変数だからvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ [9;1H[93m    [m)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_thrr[11;1H[93m    [meads = 12, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long  [14;1H[93m    [mlong型vocab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, cc[16;1H[93m    [mlasses = 0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */[12;49H[?12l[?25h[?25l[25;1H?SearchVocab[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を [3;1H[93m    [m読み込む */
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから[94m>>[m[5;1H[93m    [m脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 11[8;1H[93m    [mかつtrain_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);
[38;5;224msearch hit TOP, continuing at BOTTOM[12;13H[?12l[?25h[?25l[m[25;1H?SearchVocab[25;13H[K[25;1H[27m[m[H[2J[1;1H[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語[94m>>[m[5;1H[93m    [m彙中での単語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数Ree[7;1H[93m    [madWordIndex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイル [10;1H[93m    [mポインタfinを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AA[17;1H[93m    [mddWordToVocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(ww[19;1H[93m    [mordの文字長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大[94m>>[m[21;1H[93m    [mきい場合はlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個[23;1H[93m    [mのcharサイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコ[94m>[24;1H@                                                                               [12;14H[?12l[?25h[?25l[m[25;1H/SearchVocab[27m[m[H[2J[1;1H[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を [3;1H[93m    [m読み込む */
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから[94m>>[m[5;1H[93m    [m脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 11[8;1H[93m    [mかつtrain_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word);
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);[12;13H[?12l[?25hSearchVoca[?25lb[46m([mword[46m)[?12l[?25h[?25l[m(word)[?12l[?25hwor[?25l[46m([mword[46m)[?12l[?25h[?25l[m(word)[?12l[?25h[?25l[25;1H[1m-- INSERT --[12;31H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 1 */[?12l[?25h[?25l10 */[?12l[?25h[?25l03 */[?12l[?25h[?25l3行目 */[?12l[?25h[?25lで */[?12l[?25h[?25l定義 */[?12l[?25h[?25lした */[?12l[?25h[?25l語彙中 */[?12l[?25h[?25lの */[?12l[?25h[?25l単語 */[?12l[?25h[?25lを */[?12l[?25h[?25l返す */[?12l[?25h[?25lS */[?12l[?25h[?25lSe */[?12l[?25h[?25lea */[?12l[?25h[?25lar */[?12l[?25h[?25lrc */[?12l[?25h[?25lch */[?12l[?25h[?25lhV */[?12l[?25h[?25lVo */[12;78H[?12l[?25h[?25l[13;24r[13;1H[L[1;25r[12;77Hoc **[13;1H[93m    [m/[12;79H[?12l[?25h[?25lca  [13;1H[93m    [m*/[12;80H[?12l[?25h[?25labb[13;1H[93m    [m */[?12l[?25h[12;80H[?25l関数SearchVV[13;1H[93m    [mocab */[12;74H[?12l[?25h[?25l:Searchh[13;1H[93m    [mVocab */[12;75H[?12l[?25h[?25lSearchVV[13;1H[93m    [mocab */[13;12H[K[12;74H[?12l[?25h[25;1H[K[12;72H[?25l[?12l[?25h[?25l[25;1H:[?12l[?25h103[?25l[27m[m[H[2J[1;1H[93m 96 [m  unsigned long long a, hash = 0; /* 符号無long long型a, hash */
[93m 97 [m  for (a = 0; a < strlen(word); a++) hash = hash * 257 + word[a]; /* aが文字 [3;1H[93m    [m列wordの文字長未満の時hashにhash * 257 + word[a]を代入 */
[93m 98 [m  hash = hash % vocab_hash_size; /* hashにhashをvocab_hash_sizeの剰余を代入  [5;1H[93m    [m*/
[93m 99 [m  return hash; /* hashを返す */
[93m100 [m}
[93m101 
102 [m// Returns position of a word in the vocabulary; if the word is not found, rr[10;1H[93m    [meturns -1 /* 語彙中の単語の位置を返す(単語が語彙中に無い場合は-1を返す) */
[93m103 [mint SearchVocab(char *word) { /* char型ポインタwordを引数に持つint型関数Searr[12;1H[93m    [mchVocab() */
[93m104 [m  unsigned int hash = GetWordHash(word); /* 符号無int型hashにwordのhash値を[94m>>[m[14;1H[93m    [m代入 */
[93m105 [m  while (1) { /* 無限ループ */
[93m106 [m    if (vocab_hash[hash] == -1) return -1; /* vocab_hash[hash]が-1の時-1を返 [17;1H[93m    [mす */
[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]][19;1H[93m    [m; /* 文字列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返[94m>>[m[20;1H[93m    [mす */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sii[22;1H[93m    [mzeを返す */
[93m109 [m  }
[93m110 [m  return -1;[11;5H[?12l[?25h[?25l[25;1H:[?12l[?25h283[?25l[27m[m[H[2J[1;1H[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を [3;1H[93m    [m読み込む */
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから[94m>>[m[5;1H[93m    [m脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 11[8;1H[93m    [mかつtrain_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語を返す関数SearchVV[13;1H[93m    [mocab */
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }[12;9H[?12l[?25hi = SearchVoca[?25lb[46m([mword[46m)[m[50CVV[13;1H[93m [12;24H[?12l[?25h[?25l[m(word)[50CVV[13;1H[93m [12;25H[?12l[?25h[mwor[?25l[46m([mword[46m)[m[50CVV[13;1H[93m [12;29H[?12l[?25h[?25l[m(word)[50CVV[13;1H[93m [12;30H[?12l[?25h[m; /* 103[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[14;9H[12;9Hi = SearchVoca[?25lb[46m([mword[46m)[m[50CVV[13;1H[93m [12;24H[?12l[?25h[?25l[m(word)[50CVV[13;1H[93m [12;25H[?12l[?25h[mwor[?25l[46m([mword[46m)[m[50CVV[13;1H[93m [12;29H[?12l[?25h[?25l[m(word)[50CVV[13;1H[93m [12;30H[?12l[?25h[m; /* 103[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[?25l[25;1H[1m-- INSERT --[12;66H[?12l[?25h[?25l[mのを返す関数Searcc[13;1H[93m    [mhVocab */[12;66H[?12l[?25h[?25l1を返す関数Searr[13;1H[93m    [mchVocab */[12;67H[?12l[?25h[?25lを返す関数Searcc[13;1H[93m    [mhVocab */[13;14H[K[12;66H[?12l[?25h[?25l位置を返す関数SS[13;1H[93m    [mearchVocab */[12;70H[?12l[?25h[?25l[10CSS[13;1H[93m [m[14;22H[46m{[17;9H}[14;23H[?12l[?25h[?25l[m{[17;9H}[15;36H[?12l[?25h[16;27H[25;1H[K[16;26H[?25l[?12l[?25h[?25l[25;1H:[?12l[?25hw[?25l"word2vec.c" 703L, 32558C written[16;26H[?12l[?25h[?25l[25;1H[K[25;1H:[?12l[?25hq[?25l[25;1H[K[25;1H[?1l>[?12l[?25h[?1049lbash-3.2$ exit
exit

Script done on Wed Oct 21 16:15:35 2015
[H[2J[?25l[29;1HE325: ATTENTION
Found a swap file by the name ".word2vec.c.swp"
[10Cowned by: TATSUYA   dated: Wed Oct 21 16:07:40 2015
[9Cfile name: ~TATSUYA/c_projects/word2vec/word2vec.c
[10Cmodified: YES
[9Cuser name: TATSUYA   host name: TATSUYAs-MacBook-Air.local
[8Cprocess ID: 5087 (still running)
While opening file "word2vec.c"
[13Cdated: Wed Oct 21 14:30:50 2015

(1) Another program may be editing the same file.
    If this is the case, be careful not to end up with two
    different instances of the same file when making changes.
    Quit, or continue with caution.

(2) An edit session for this file crashed.
    If this is the case, use ":recover" or "vim -r word2vec.c"
    to recover the changes (see ":help recovery").
    If you did this already, delete the swap file ".word2vec.c.swp"
    to avoid this message.

Swap file ".word2vec.c.swp" already exists!
[O]pen Read-Only, (E)dit anyway, (R)ecover, (Q)uit, (A)bort:[?12l[?25h[29;1H[K[?25l[29;1H"word2vec.c" [readonly] 703L, 31586C[>c[1;1H//  Copyright 2013 Google Inc. All Rights Reserved.
//
//  Licensed under the Apache License, Version 2.0 (the "License");
//  you may not use this file except in compliance with the License.
//  You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//[8;3H[K[9;1H//  Unless required by applicable law or agreed to in writing, software
//  distributed under the License is distributed on an "AS IS" BASIS,
//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//  See the License for the specific language governing permissions and
//  limitations under the License.[13;35H[K[14;1H[K[15;1H#include <stdio.h>[15;19H[K[16;1H#include <stdlib.h>
#include <string.h>[17;21H[K[18;1H#include <math.h>[18;18H[K[19;1H#include <pthread.h>[19;21H[K[20;5H[K[21;1H#define MAX_STRING 100 /* 最大文字数は100字まで */
#define EXP_TABLE_SIZE 1000[22;28H[K[23;1H#define MAX_EXP 6[23;18H[K[24;1H#define MAX_SENTENCE_LENGTH 1000[24;33H[K[25;1H#define MAX_CODE_LENGTH 40 /* 最大コード長は40字まで */[25;56H[K[26;5H[K[27;1Hconst int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in the vocabulary[28;1H[K[1;1H[?12l[?25h[?25l[29;1H[K[29;1H:[?12l[?25hq[?25l[29;1H[K[29;1H[?1l>[?12l[?25h[?1049lbash-3.2$ exit
exit

Script done on Wed Oct 21 16:13:21 2015
Script started on Wed Oct 21 16:17:31 2015
bash: /path/to/your/virtualenvwrapper.sh: No such file or directory
[?1034hbash-3.2$ vi word1[K2vec.c
[?1049h[?1h=[1;29r[?12;25h[?12l[?25h[27m[m[H[2J[?25l[29;1H"word2vec.c" 703L, 32558C[>c[1;1H//  Copyright 2013 Google Inc. All Rights Reserved.
//
//  Licensed under the Apache License, Version 2.0 (the "License");
//  you may not use this file except in compliance with the License.
//  You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
//  Unless required by applicable law or agreed to in writing, software
//  distributed under the License is distributed on an "AS IS" BASIS,
//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//  See the License for the specific language governing permissions and
//  limitations under the License.

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <pthread.h>

#define MAX_STRING 100 /* 最大文字数は100字まで */
#define EXP_TABLE_SIZE 1000
#define MAX_EXP 6
#define MAX_SENTENCE_LENGTH 1000
#define MAX_CODE_LENGTH 40 /* 最大コード長は40字まで */

const int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in the vocabulary[1;1H[?12l[?25h[?25l[29;1H[K[29;1H:[?12l[?25hset number[?25l[1;1H[93m  1 [m//  Copyright 2013 Google Inc. All Rights Reserved.
[93m  2 [m//
[93m  3 [m//  Licensed under the Apache License, Version 2.0 (the "License");
[93m  4 [m//  you may not use this file except in compliance with the License.
[93m  5 [m//  You may obtain a copy of the License at
[93m  6 [m//
[93m  7 [m//      http://www.apache.org/licenses/LICENSE-2.0
[93m  8 [m//
[93m  9 [m//  Unless required by applicable law or agreed to in writing, software
[93m 10 [m//  distributed under the License is distributed on an "AS IS" BASIS,
[93m 11 [m//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
[93m 12 [m//  See the License for the specific language governing permissions and
[93m 13 [m//  limitations under the License.
[93m 14 
 15 [m#include <stdio.h>
[93m 16 [m#include <stdlib.h>
[93m 17 [m#include <string.h>
[93m 18 [m#include <math.h>
[93m 19 [m#include <pthread.h>
[93m 20 
 21 [m#define MAX_STRING 100 /* 最大文字数は100字まで */
[93m 22 [m#define EXP_TABLE_SIZE 1000
[93m 23 [m#define MAX_EXP 6
[93m 24 [m#define MAX_SENTENCE_LENGTH 1000
[93m 25 [m#define MAX_CODE_LENGTH 40 /* 最大コード長は40字まで */
[93m 26 
 27 [mconst int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in the vocabull[28;1H[93m    [mary[1;5H[?12l[?25h[?25l[29;1H[K[29;1H:[?12l[?25hs[?25l[29;2H[K[29;2H[?12l[?25h290[?25l[27m[m[H[2J[1;1H[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[2;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[7;1H[93m    [mb */
[93m284 [m    if (i == -1) {
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);
[93m296 [m  fclose(fin);
[93m297 [m}
[93m298 
299 [mvoid SaveVocab() {
[93m300 [m  long long i;
[93m301 [m  FILE *fo = fopen(save_vocab_file, "wb");
[93m302 [m  for (i = 0; i < vocab_size; i++) fprintf(fo, "%s %lld\n", vocab[i].word, vocab[i].cc[27;1H[93m    [mn);
[93m303 [m  fclose(fo);[14;7H[?12l[?25hSortVoca[?25lb[46m()[?12l[?25h[?25l([?12l[?25h[?25l[m()[?12l[?25h[13;7H[12;18H[11;18H[?25l[10;16H[46m[[ma[46m][?12l[?25h[?25l[m[a][9;18H[?12l[?25h[8;18H-[?25l[8;12H[46m([7C)[?12l[?25h[?25l[m[8;12H([7C)[?12l[?25h[?25l [46m{[11;9H}[8;22H[?12l[?25h[?25l[m[29;1H[1m-- INSERT --[8;23H[?12l[?25h[?25l[m{[11;9H}[8;24H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l i */[?12l[?25h[?25li= */[?12l[?25h[?25l== */[?12l[?25h[?25l  */[?12l[?25h[?25li ==  */[?12l[?25h== [?25l - */[?12l[?25h[?25l-1 */[?12l[?25h[?25l1の */[?12l[?25h[?25l[8;37H[K[9;5H */[9;11H[K[10;10H a = AddWordToVocab(word);[11;8H   vocab[a].cn = 1;[11;27H[K[12;8H } else vocab[i].cn++;[12;30H[K[13;6H   if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();[14;6H }[14;8H[K[15;6H SortVocab();[15;19H[K[16;6H if (debug_mode > 0) {[16;29H[K[17;16H"Vocab size: %lld\n", vocab_size);[17;50H[K[18;6H   printf("Words in train file: %lld\n", train_words);[19;6H }[19;8H[K[20;7Hfile_size = ftell(fin);[21;4H[93m [m  fclose(fin);[22;4H[93m [m}[23;5H[K[24;4H[93m [mvoid SaveVocab() {[25;6H long long i;[25;19H[K[26;6H FILE *fo = fopen(save_vocab_file, "wb");[26;47H[K[27;1H[93m303 [m  for (i = 0; i < vocab_size; i++) fprintf(fo, "%s %lld\n", vocab[i].word, vocab[i].cc[28;1H[93m    [mn);[28;8H[K[9;5H[?12l[?25h[?25l[8;36H */[9;5H      a = AddWordToVocab(word);[10;10H vocab[a].cn = 1;[10;27H[K[11;8H } else vocab[i].cn++;[12;8H if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();[13;6H }[13;9H[K[14;6H SortVocab();[15;6H if (debug_mode > 0) {[16;6H   printf("Vocab size: %lld\n", vocab_size);[17;16H"Words in train file: %lld\n", train_words);[18;6H }[18;9H[K[19;6H file_size = ftell(fin);[20;7Hfclose(fin);[20;19H[K[21;4H[93m [m}[21;7H[K[22;5H[K[23;4H[93m [mvoid SaveVocab() {[24;4H[93m [m  long long i;[24;19H[K[25;6H FILE *fo = fopen(save_vocab_file, "wb");[26;6H for (i = 0; i < vocab_size; i++) fprintf(fo, "%s %lld\n", vocab[i].word, vocab[i].cc[27;1H[93m    [mn);[27;8H[K[28;1H[93m303 [m  fclose(fo);[8;36H[?12l[?25h[?25l時 */[?12l[?25h[9;36H[10;27H[11;30H[12;38H[?25l[13;8H[?12l[?25h[14;19H[29;1H[K[14;18H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hSortT[?25l[29;6H[K[29;6H[?12l[?25hVocab[?25l[27m[m[H[2J[1;1H[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) {
[93m318 [m    ReadWord(word, fin);
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 [14;7H[?12l[?25h[?25l[m[29;1H?SortVocab[27m[m[H[2J[1;1H[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[2;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[7;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);
[93m296 [m  fclose(fin);
[93m297 [m}
[93m298 
299 [mvoid SaveVocab() {
[93m300 [m  long long i;
[93m301 [m  FILE *fo = fopen(save_vocab_file, "wb");
[93m302 [m  for (i = 0; i < vocab_size; i++) fprintf(fo, "%s %lld\n", vocab[i].word, vocab[i].cc[27;1H[93m    [mn);
[93m303 [m  fclose(fo);[14;7H[?12l[?25h[?25l[29;1H?SortVocab[27m[m[H[2J[1;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;
[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 
140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[13;1H[93m    [mに並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[18;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[20;1H[93m    [m1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[26;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが[28;1H[93m    [m0でない時 */[14;35H[?12l[?25h[?25l[29;1H/SortVocab[27m[m[H[2J[1;1H[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[2;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[7;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);
[93m296 [m  fclose(fin);
[93m297 [m}
[93m298 
299 [mvoid SaveVocab() {
[93m300 [m  long long i;
[93m301 [m  FILE *fo = fopen(save_vocab_file, "wb");
[93m302 [m  for (i = 0; i < vocab_size; i++) fprintf(fo, "%s %lld\n", vocab[i].word, vocab[i].cc[27;1H[93m    [mn);
[93m303 [m  fclose(fo);[14;7H[?12l[?25hSortVoca[?25lb[46m()[?12l[?25h[?25l([?12l[?25h[?25l[m()[?12l[?25h[?25l[29;1H?SortVocab[14;7H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;
[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 
140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[13;1H[93m    [mに並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[18;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[20;1H[93m    [m1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[26;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが[28;1H[93m    [m0でない時 */[14;35H[?12l[?25h[?25l[29;1H/SortVocab[27m[m[H[2J[1;1H[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[2;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[7;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab();
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);
[93m296 [m  fclose(fin);
[93m297 [m}
[93m298 
299 [mvoid SaveVocab() {
[93m300 [m  long long i;
[93m301 [m  FILE *fo = fopen(save_vocab_file, "wb");
[93m302 [m  for (i = 0; i < vocab_size; i++) fprintf(fo, "%s %lld\n", vocab[i].word, vocab[i].cc[27;1H[93m    [mn);
[93m303 [m  fclose(fo);[14;7H[?12l[?25hSortVoca[?25lb[46m()[?12l[?25h[?25l([?12l[?25h[?25l[m()[?12l[?25h[?25l[29;1H[1m-- INSERT --[14;19H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l  */[?12l[?25h[?25l 1 */[?12l[?25h[?25l14 */[?12l[?25h[?25l46 */[?12l[?25h[?25l6行目 */[?12l[?25h[?25lで */[?12l[?25h[?25l定義した */[?12l[?25h[?25l 語彙を単語数を用いて頻度順>    に並替え */[?12l[?25h[?25l に並替え */[14;82H[K[14;71H[?12l[?25h[?25l に並替え */[14;81H[K[14;70H[?12l[?25h[?25l に並替え */[14;80H[K[14;69H[?12l[?25h[?25l>に並替え */[14;79H[K[14;68H[?12l[?25h[?25lに並替え */[14;78H[K[14;67H[?12l[?25h[?25l語彙を単語数を用いて頻度順に並替え */[14;77H[K[14;40H[?12l[?25h[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[?25lる */[?12l[?25h[?25l関数 */[?12l[?25h[?25lS */[?12l[?25h[?25lSo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25ldV */[?12l[?25h[?25lVo */[?12l[?25h[?25loc */[14;87H[?12l[?25h[?25l[15;28r[15;1H[L[1;29r[14;86Hca **[15;1H[93m    [m/[14;88H[?12l[?25h[?25lab  [15;1H[93m    [m*/[14;89H[?12l[?25h[29;1H[K[14;88H[?25l[?12l[?25h[?25l[29;1H?SortVocab[14;7H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;
[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 
140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[13;1H[93m    [mに並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[18;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[20;1H[93m    [m1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[26;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが[28;1H[93m    [m0でない時 */[14;35H[?12l[?25h[?25l[29;1H?SortVocab[14;10H[?12l[?25h[?25l[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) {
[93m318 [m    ReadWord(word, fin);
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 [m
[38;5;224msearch hit TOP, continuing at BOTTOM[14;7H[?12l[?25h[?25l[m[29;1H/SortVocab[29;11H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;
[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 
140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[13;1H[93m    [mに並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[18;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[20;1H[93m    [m1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[26;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが[28;1H[93m    [m0でない時 */
[38;5;224msearch hit BOTTOM, continuing at TOP[14;10H[?12l[?25h[?25l[m[29;1H/SortVocab[29;11H[K[29;1H[14;35H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[2;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[7;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab(); /* 146行目で定義した語彙を単語数を用いて頻度順に並替える関数SordVocab  [15;1H[93m    [m*/
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);
[93m296 [m  fclose(fin);
[93m297 [m}
[93m298 
299 [mvoid SaveVocab() {
[93m300 [m  long long i;
[93m301 [m  FILE *fo = fopen(save_vocab_file, "wb");
[93m302 [m  for (i = 0; i < vocab_size; i++) fprintf(fo, "%s %lld\n", vocab[i].word, vocab[i].cc[28;1H[93m    [mn);[14;7H[?12l[?25hSortVoca[?25lb[46m()[m[71C  [15;1H[93m [14;16H[?12l[?25h[?25l[m[73C  [15;1H[93m [14;17H[?12l[?25h[?25l[m()[71C  [15;1H[93m [14;18H[?12l[?25h[m; /* 146[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2CSor[?25l[29;1H[1m-- INSERT --[14;84H[?12l[?25h[?25l[mrVocab **[15;1H[93m    [m/[15;6H[K[14;83H[?12l[?25h[?25lrtVocab  [15;1H[93m    [m*/[14;84H[?12l[?25hVocab[?25lb(([15;1H[93m    [m */[?12l[?25h[?25l[14;89H[46m(([m[15;1H[93m    [m[46m)[m */[?12l[?25h[?25l[14;89H(([15;1H[93m [m[3C)[16;27H[46m{[19;7H}[16;28H[?12l[?25h[?25l[m{[19;7H}[17;50H[?12l[?25h[18;60H[?25l[16;27H[46m{[19;7H}[?12l[?25h[?25l[m[16;27H{[19;7H}[20;30H[?12l[?25h[21;19H[?25l [?12l[?25h[?25l[22;6H[?12l[?25h[23;5H[?25l[24;19H[46m()[?12l[?25h[?25l)[?12l[?25h[?25l[m() [?12l[?25h[?25l{[?12l[?25h[29;1H[K[24;22H[?25l[?12l[?25h[?25l[29;1H/SortVocab[27m[m[H[2J[1;1H[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) {
[93m318 [m    ReadWord(word, fin);
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 [14;7H[?12l[?25h[?25l[m[29;1H/SortVocab[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;
[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 
140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[13;1H[93m    [mに並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[18;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[20;1H[93m    [m1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[26;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが[28;1H[93m    [m0でない時 */
[38;5;224msearch hit BOTTOM, continuing at TOP[14;10H[?12l[?25h[?25l[m[29;1H/SortVocab[29;11H[K[29;1H[14;35H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[2;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[7;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }
[93m290 [m  SortVocab(); /* 146行目で定義した語彙を単語数を用いて頻度順に並替える関数SortVocab(([15;1H[93m    [m) */
[93m291 [m  if (debug_mode > 0) {
[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);
[93m296 [m  fclose(fin);
[93m297 [m}
[93m298 
299 [mvoid SaveVocab() {
[93m300 [m  long long i;
[93m301 [m  FILE *fo = fopen(save_vocab_file, "wb");
[93m302 [m  for (i = 0; i < vocab_size; i++) fprintf(fo, "%s %lld\n", vocab[i].word, vocab[i].cc[28;1H[93m    [mn);[14;7H[?12l[?25h[?25l[29;1H[1m-- INSERT --[14;8H[?12l[?25h[16;8H[17;8H[18;8H[?25l[m[16;27H[46m{[19;7H}[?12l[?25h[?25l[m[16;27H{[19;7H}[20;8H[?12l[?25h[21;8H[?25l[22;6H[?12l[?25h[29;1H[K[22;5H[?25l[?12l[?25h[23;5H[24;5H[25;5H[26;5H[27;5H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m303 [m  fclose(fo);
[93m304 [m}[27;5H[?12l[?25h[?25l[22;22H[46m{[28;5H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;22H{[27;5H}
[93m305 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m306 [mvoid ReadVocab() {[28;5H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m307 [m  long long a, i = 0;[28;5H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];[27;5H[?12l[?25h[28;5H[?25l[1;28r[28;1H
[1;29r[28;1H[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb");[28;5H[?12l[?25h[27;5H[26;5H[25;5H[24;5H[23;5H[?25l[16;22H[46m{[22;5H}[?12l[?25h[?25l[m[16;22H{[22;5H}[21;5H[?12l[?25h[19;5H[18;5H[17;5H[16;5Hvoid SaveVoca[?25lb[46m()[?12l[?25h[?25l([?12l[?25h[?25l[m()[?12l[?25h[?25l [46m{[22;5H}[16;22H[?12l[?25h[?25l[m{[22;5H}[17;18H[?12l[?25h[18;22H[19;22H[21;17H[?25l[16;22H[46m{[22;5H}[?12l[?25h[?25l[m[16;22H{[22;5H}[23;5H[?12l[?25h[24;22H[25;22H[26;13H[27;22H[28;22H[?25l[1;28r[28;1H
[1;29r[28;1H[93m311 [m  if [46m([mfin == NULL[46m)[m {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;10H([11C)
[93m312 [m    printf("Vocabulary file not found\n");[28;22H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m313 [m    exit(1);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;24H[46m{[m


[93m314 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[24;24H{[27;7H}
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[28;22H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) {[27;21H[?12l[?25h[28;17H[?25l[1;28r[28;1H
[1;29r[28;1H[93m318 [m    ReadWord(word, fin);[28;22H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m319 [m    if [46m([mfeof(fin)[46m)[m break;[28;22H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;12H([9C)
[93m320 [m    a = AddWordToVocab(word);[28;22H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);[28;22H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m322 [m    i++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;17H[46m{[m[28;1H[93m323 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;17H{[27;7H}
[93m324 [m  SortVocab();[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m325 [m  if (debug_mode > 0) {[?12l[?25h[27;18H[?25l[20;17H[46m{[26;7H}[?12l[?25h[?25l[m[20;17H{[26;7H}[25;12H[?12l[?25h[24;22H[23;22H[?25l[22;12H[46m([9C)[?12l[?25h[?25l[m[22;12H([9C)[21;22H[?12l[?25h[?25l[20;17H[46m{[26;7H}[20;17H[?12l[?25h[?25l[m{[26;7H}[19;21H[?12l[?25h[18;22H[?25l[14;24H[46m{[17;7H}[?12l[?25h[?25l[m[14;24H{[17;7H}[16;16H[?12l[?25h[15;22H[?25l[14;10H[46m([11C)[?12l[?25h[?25l[m[14;10H([11C)[13;22H[?12l[?25h[?25l[14;10H[46m([11C)[?12l[?25h[?25l[m[14;10H([11C)[15;22H[?12l[?25h[16;16H[15;22H[?25l[14;10H[46m([11C)[?12l[?25h[?25l[m[14;10H([11C)[13;22H[?12l[?25h[12;22H[11;13H[10;22H[9;22H[10;22H[11;13H[12;22H[13;22H[?25l[14;10H[46m([11C)[?12l[?25h[?25l[m[14;10H([11C)[15;22H[?12l[?25h[16;16H[?25l[14;24H[46m{[17;7H}[?12l[?25h[?25l[m[14;24H{[17;7H}[18;22H[?12l[?25h[19;21H[18;22H[?25l[14;24H[46m{[17;7H}[?12l[?25h[?25l[m[14;24H{[17;7H}[16;16H[?12l[?25h[15;22H[?25l[14;10H[46m([11C)[?12l[?25h[?25l[m[14;10H([11C)[13;22H[?12l[?25h[12;22H[11;13H[10;22H[9;22H[8;5H[9;22H[?25l[29;1H[1m-- INSERT --[9;23H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/:[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[9;25H[K[9;25H[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loi */[?12l[?25h[?25lid */[?12l[?25h[?25ld型 */[?12l[?25h[?25l関数 */[?12l[?25h[?25lR */[?12l[?25h[?25lRe */[?12l[?25h[?25lea */[?12l[?25h[?25lad */[?12l[?25h[?25ldV */[?12l[?25h[?25lVo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[10;26H[11;14H[12;29H[?25l[13;24H[46m([21C)[?12l[?25h[?25l[m[13;24H([21C)[14;24H[46m{[17;7H}[14;25H[?12l[?25h[?25l[m{[15;15H[46m([29C)[m[17;7H}[15;46H[?12l[?25h[?25l[14;24H[46m{[m[15;15H([29C)[17;7H[46m}[14;25H[?12l[?25h[?25l[13;24H([21C)[m[14;24H{[17;7H}[13;46H[?12l[?25h[?25l[13;24H([21C)[12;29H[?12l[?25h[?25l[13;24H[46m([21C)[?12l[?25h[m[29;1H[K[13;45H[?25l[13;24H([21C)[?12l[?25h[?25l[29;1H/SortVocab[27;7H[?12l[?25h[?25l[20;17H[46m{[26;7H}[?12l[?25h[?25l[m[20;17H{[26;7H}[25;7H[?12l[?25h[?25l[20;17H[46m{[26;7H}[?12l[?25h[?25l[m[20;17H{[26;7H}[27;7H[?12l[?25h[28;7H[?25l[1;28r[28;1H
[1;29r[28;1H[93m326 [m    printf("Vocab size: %lld\n", vocab_size);[29;1H[K[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m327 [m    printf("Words in train file: %lld\n", train_words);[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;27H[46m{[m


[93m328 [m  [46m}[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[23;27H{[26;7H}
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {[27;7H[?12l[?25h[28;7H[?25l[1;28r[28;1H
[1;29r[28;1H[93m331 [m    printf("ERROR: training data file not found!\n");[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m332 [m    exit(1);[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;24H[46m{[m


[93m333 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[24;24H{[27;7H}
[93m334 [m  fseek(fin, 0, SEEK_END);[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m335 [m  file_size = ftell(fin);[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m336 [m  fclose(fin);[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m337 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m338 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m339 [mvoid InitNet() {[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m340 [m  long long a, b;[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m341 [m  unsigned long long next_random = 1;[28;7H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[28;1H[93m    [mf(real));[27;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}[28;7H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m344 [m  if (hs) {[28;7H[?12l[?25h[27;7H[25;7H[24;7H[23;7H[22;7H[21;5H[20;5H[19;7H[18;7H[17;7H[?25l[13;24H[46m{[16;7H}[?12l[?25h[?25l[m[13;24H{[16;7H}[15;7H[?12l[?25h[14;7H[13;7H[12;7H[?25l[8;27H[46m{[11;7H}[?12l[?25h[?25l[m[8;27H{[11;7H}[10;7H[?12l[?25h[9;7H[8;7H[7;7H[6;7H[5;7H[4;7H[3;7H[2;7H[1;7H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m317 [m  while (1) {[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m316 [m  vocab_size = 0;[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[28;1H[94m@                                                                                        [1;7H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m314 [m  }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m313 [m    exit(1);[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m312 [m    printf("Vocabulary file not found\n");[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m311 [m  if (fin == NULL) {[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb");[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m309 [m  char word[MAX_STRING];[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m308 [m  char c;[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m307 [m  long long a, i = 0;[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m306 [mvoid ReadVocab() { /* void型関数ReadVocab */[1;7H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m305 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m304 [m}[?12l[?25h[2;5H[3;7H[4;7H[5;7H[4;7Hlong long a,[5;13H[6;19HX_STRIN[?25l[6;16H[46m[[10C][?12l[?25h[?25l[m[6;16H[[10C][?12l[?25h[7;28H[?25l[8;24H[46m{[11;7H}[8;24H[?12l[?25h[?25l[m{[11;7H}[7;28H[?12l[?25h[6;28H[7;28Hd_vocab_file, "rb[?25l[7;24H[46m([21C)[?12l[?25h[?25l[m[7;24H([21C)[?12l[?25h[?25l[29;1H[1m-- INSERT --[7;48H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [?25l 読込 */[?12l[?25h[?25lモード */[?12l[?25h[?25lで */[?12l[?25h[?25lr */[?12l[?25h[?25lre */[?12l[?25h[?25lea */[?12l[?25h[?25lad */[?12l[?25h[?25ld_ */[?12l[?25h[?25l_v */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_f */[?12l[?25h[?25lfi */[?12l[?25h[?25lil */[?12l[?25h[?25lle */[?12l[?25h[?25leを */[?12l[?25h[?25l開く */[?12l[?25h[?25l[8;24H[46m{[11;7H}[8;25H[?12l[?25h[?25l[m{[11;7H}[9;47H[?12l[?25h[10;17H[9;47H[?25l[8;24H[46m{[11;7H}[8;25H[?12l[?25h[?25l[m{[11;7H}[7;85H[?12l[?25h[?25l[8;24H[46m{[11;7H}[8;25H[?12l[?25h[?25l[m{[11;7H}[9;47H[?12l[?25h[10;17H[?25l[8;24H[46m{[11;7H}[?12l[?25h[?25l[m[8;24H{[11;7H}[12;64H[?12l[?25h[13;22H[12;64H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25la */[12;75H[K[12;72H[?12l[?25h[?25lc */[12;74H[K[12;71H[?12l[?25h[?25lo */[12;73H[K[12;70H[?12l[?25h[?25lv */[12;72H[K[12;69H[?12l[?25h[?25l  */[12;71H[K[12;68H[?12l[?25h[?25l 0 */[?12l[?25h[?25l  */[?12l[?25h[?25l < */[?12l[?25h[?25l<= */[?12l[?25h[?25l  */[?12l[?25h[?25l a */[?12l[?25h[?25l  */[?12l[?25h[?25l < */[?12l[?25h[?25l  */[?12l[?25h[?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_h */[?12l[?25h[?25lha */[?12l[?25h[?25las */[?12l[?25h[?25lsh */[12;87H[?12l[?25h[?25l[13;28r[13;1H[L[1;29r[12;86Hh_ **[13;1H[93m    [m/[12;88H[?12l[?25h[?25l_s  [13;1H[93m    [m*/[12;89H[?12l[?25h[?25lsii[13;1H[93m    [m */[?12l[?25h[?25l[93m [mz */[?12l[?25h[?25lze */[?12l[?25h[?25leの */[?12l[?25h[?25l時 */[?12l[?25h[14;22H[?25l[15;17H[46m{[21;7H}[15;18H[?12l[?25h[?25l[m{[21;7H}[15;19H[?12l[?25h[?25l [46m{[21;7H}[15;20H[?12l[?25h[?25l[m[15;19H[K[21;7H}[15;19H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 無限ループ */[?12l[?25h[16;29H[17;30H[?25l[18;27H[46m([mword[46m)[?12l[?25h[?25l[m(word)[19;32H[?12l[?25h[20;13H[?25l[15;17H[46m{[21;7H}[?12l[?25h[?25l[m[15;17H{[21;7H}[22;19H[?12l[?25h[?25l[23;27H[46m{[26;7H}[23;28H[?12l[?25h[?25l[m{[26;7H}[24;32H[?12l[?25h[25;32H[?25l[23;27H[46m{[26;7H}[?12l[?25h[?25l[m[23;27H{[26;7H}[27;32H[?12l[?25h[?25l[28;25H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m331 [m    printf("ERROR: training data file not found!\n");[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m332 [m    exit(1);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;24H[46m{[m


[93m333 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[24;24H{[27;7H}
[93m334 [m  fseek(fin, 0, SEEK_END);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m335 [m  file_size = ftell(fin);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m336 [m  fclose(fin);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m337 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m338 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m339 [mvoid InitNet() {[?12l[?25h[27;5H[?25l[26;6H[?12l[?25h[25;19H[24;30H[23;31H[?25l[19;24H[46m{[22;7H}[?12l[?25h[?25l[m[19;24H{[22;7H}[21;17H[?12l[?25h[20;32H[?25l[19;24H[46m{[22;7H}[19;25H[?12l[?25h[?25l[m{[22;7H}[18;32H[?12l[?25h[?25l[14;27H[46m{[17;7H}[?12l[?25h[?25l[m[14;27H{[17;7H}[16;32H[?12l[?25h[15;32H[?25l[14;27H[46m{[17;7H}[14;28H[?12l[?25h[?25l[m{[17;7H}[13;19H[?12l[?25h[?25l[6;17H[46m{[12;7H}[?12l[?25h[?25l[m[6;17H{[12;7H}[11;13H[?12l[?25h[29;1H[K[11;12H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hReadWord([?25l[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [13;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引[15;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[18;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[22;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [25;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[38;5;224msearch hit BOTTOM, continuing at TOP[14;10H[?12l[?25h[?25l[m[29;1H/ReadWord([29;11H[K[29;1H[15;19H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]; /* 文字[2;1H[93m    [m列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返す */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sizeを返す  [4;1H[93m    [m*/
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語彙中での単[10;1H[93m    [m語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数ReadWordIndd[12;1H[93m    [mex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイルポインタff[15;1H[93m    [minを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[22;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字[24;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[26;1H[93m    [mlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[28;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */[14;7H[?12l[?25h[?25l[29;1H/ReadWord([27m[m[H[2J[1;1H[93m264 [m  char word[MAX_STRING];
[93m265 [m  FILE *fin; /* FILE型ポインタfin */
[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[5;1H[93m    [mzeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */
[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を読み込む  [15;1H[93m    [m*/
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[19;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[24;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;[14;9H[?12l[?25h[?25l[29;1H/ReadWord([27m[m[H[2J[1;1H[93m306 [mvoid ReadVocab() { /* void型関数ReadVocab */
[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb"); /* 読込モードでread_vocab_fileを開く */
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[11;1H[93m    [mzeの時 */
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) { /* 無限ループ */
[93m318 [m    ReadWord(word, fin);
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);[14;9H[?12l[?25h[?25l[29;1H?ReadWord([27m[m[H[2J[1;1H[93m264 [m  char word[MAX_STRING];
[93m265 [m  FILE *fin; /* FILE型ポインタfin */
[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[5;1H[93m    [mzeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */
[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を読み込む  [15;1H[93m    [m*/
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[19;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[24;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;[14;9H[?12l[?25h[?25l[29;1H?ReadWord([27m[m[H[2J[1;1H[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]; /* 文字[2;1H[93m    [m列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返す */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sizeを返す  [4;1H[93m    [m*/
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語彙中での単[10;1H[93m    [m語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数ReadWordIndd[12;1H[93m    [mex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイルポインタff[15;1H[93m    [minを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[22;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字[24;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[26;1H[93m    [mlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[28;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */[14;7H[?12l[?25h[?25l[29;1H?ReadWord([27m[m[H[2J[1;1H[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [13;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引[15;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[18;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[22;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [25;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */[15;19H[?12l[?25h[?25l[29;1H/ReadWord([27m[m[H[2J[1;1H[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]; /* 文字[2;1H[93m    [m列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返す */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sizeを返す  [4;1H[93m    [m*/
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語彙中での単[10;1H[93m    [m語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数ReadWordIndd[12;1H[93m    [mex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイルポインタff[15;1H[93m    [minを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[22;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字[24;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[26;1H[93m    [mlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[28;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */[14;7H[?12l[?25h[?25l[29;1H/ReadWord([27m[m[H[2J[1;1H[93m264 [m  char word[MAX_STRING];
[93m265 [m  FILE *fin; /* FILE型ポインタfin */
[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[5;1H[93m    [mzeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */
[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を読み込む  [15;1H[93m    [m*/
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[19;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[24;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;[14;9H[?12l[?25h[?25l[29;1H/ReadWord([27m[m[H[2J[1;1H[93m306 [mvoid ReadVocab() { /* void型関数ReadVocab */
[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb"); /* 読込モードでread_vocab_fileを開く */
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[11;1H[93m    [mzeの時 */
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) { /* 無限ループ */
[93m318 [m    ReadWord(word, fin);
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);[14;9H[?12l[?25hReadWor[?25ld[46m([9C)[14;17H[?12l[?25h[?25l[m([9C)[14;18H[?12l[?25hword, fi[?25l[14;17H[46m([9C)[?12l[?25h[?25l[m[14;17H([9C)[?12l[?25h[?25l[29;1H[1m-- INSERT --[14;29H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 7 */[?12l[?25h[?25l72 */[?12l[?25h[?25l2g */[?12l[?25h[?25lgy */[?12l[?25h[?25lyo */[?12l[?25h[?25lom */[?12l[?25h[?25lo */[14;41H[K[14;38H[?12l[?25h[?25ly */[14;40H[K[14;37H[?12l[?25h[?25lg */[14;39H[K[14;36H[?12l[?25h[?25l2 */[14;38H[K[14;35H[?12l[?25h[?25l2行目 */[?12l[?25h[?25lで */[?12l[?25h[?25l定義した */[?12l[?25h[?25lR */[?12l[?25h[?25lRe */[?12l[?25h[?25lea */[?12l[?25h[?25lad */[?12l[?25h[?25ldW */[?12l[?25h[?25lWo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25ld関数 */[?12l[?25h[15;30H[29;1H[K[15;29H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hfeof(fin[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [10;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引[12;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[15;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[19;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [22;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;
[38;5;224msearch hit BOTTOM, continuing at TOP[14;15H[?12l[?25h[?25l[m[29;1H/feof(fin[29;10H[K[29;1H[27m[m[H[2J[1;1H[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sizeを返す  [2;1H[93m    [m*/
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語彙中での単[8;1H[93m    [m語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数ReadWordIndd[10;1H[93m    [mex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイルポインタff[13;1H[93m    [minを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[20;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字[22;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[24;1H[93m    [mlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[26;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */[14;11H[?12l[?25h[?25l[29;1H?feof(fin[27m[m[H[2J[1;1H[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [10;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引[12;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[15;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[19;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [22;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;[14;15H[?12l[?25h[?25l[29;1H/feof(fin[27m[m[H[2J[1;1H[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sizeを返す  [2;1H[93m    [m*/
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語彙中での単[8;1H[93m    [m語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数ReadWordIndd[10;1H[93m    [mex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイルポインタff[13;1H[93m    [minを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[20;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字[22;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[24;1H[93m    [mlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[26;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */[14;11H[?12l[?25h[?25l[29;1H/feof(fin[27m[m[H[2J[1;1H[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[3;1H[93m    [mzeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */
[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を読み込む  [13;1H[93m    [m*/
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[17;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[22;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }[14;13H[?12l[?25h[?25l[29;1H?feof(fin[27m[m[H[2J[1;1H[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sizeを返す  [2;1H[93m    [m*/
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語彙中での単[8;1H[93m    [m語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数ReadWordIndd[10;1H[93m    [mex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイルポインタff[13;1H[93m    [minを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[20;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字[22;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[24;1H[93m    [mlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[26;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */[14;11H[?12l[?25h[?25l[29;1H?feof(fin[27m[m[H[2J[1;1H[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [10;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引[12;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[15;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[19;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [22;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;[14;15H[?12l[?25h[?25l[29;1H/feof(fin[27m[m[H[2J[1;1H[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sizeを返す  [2;1H[93m    [m*/
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語彙中での単[8;1H[93m    [m語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数ReadWordIndd[10;1H[93m    [mex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイルポインタff[13;1H[93m    [minを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[20;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字[22;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[24;1H[93m    [mlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[26;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */[14;11H[?12l[?25h[?25l[29;1H/feof(fin[27m[m[H[2J[1;1H[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[3;1H[93m    [mzeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */
[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を読み込む  [13;1H[93m    [m*/
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[17;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[22;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }[14;13H[?12l[?25h[?25l[29;1H/feof(fin[27m[m[H[2J[1;1H[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb"); /* 読込モードでread_vocab_fileを開く */
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[10;1H[93m    [mzeの時 */
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) { /* 無限ループ */
[93m318 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数 */
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);
[93m333 [m  }[14;13H[?12l[?25h[?25l[29;1H?feof(fin[27m[m[H[2J[1;1H[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[3;1H[93m    [mzeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */
[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を読み込む  [13;1H[93m    [m*/
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[17;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[22;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }[14;13H[?12l[?25h[?25l[29;1H/feof(fin[27m[m[H[2J[1;1H[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb"); /* 読込モードでread_vocab_fileを開く */
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[10;1H[93m    [mzeの時 */
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) { /* 無限ループ */
[93m318 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数 */
[93m319 [m    if (feof(fin)) break;
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);
[93m333 [m  }[14;13H[?12l[?25h[16C[?25l[29;1H[1m-- INSERT --[14;30H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l ファイルポインタが終端に達した時無限ループから脱出[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[15;34H[29;1H[K[15;33H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hAdd [?25l[?12l[?25hWordToVocab[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語彙中での単[3;1H[93m    [m語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数ReadWordIndd[5;1H[93m    [mex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイルポインタff[8;1H[93m    [minを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[15;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字[17;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[19;1H[93m    [mlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[21;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */
[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */
[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */
[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size以上の時 **[27;1H[93m    [m/
[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */
[38;5;224msearch hit BOTTOM, continuing at TOP[14;9H[?12l[?25h[?25l[m[29;1H/AddWordToVocab[29;16H[K[29;1H[14;80H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m262 
263 [mvoid LearnVocabFromTrainFile() { /* void型関数LearnVocabFromTrainFile() */
[93m264 [m  char word[MAX_STRING];
[93m265 [m  FILE *fin; /* FILE型ポインタfin */
[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[7;1H[93m    [mzeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */
[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を読み込む  [17;1H[93m    [m*/
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[21;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[26;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);[14;7H[?12l[?25h[?25l[29;1H/AddWordToVocab[14;64H[?12l[?25h[?25l[29;1H[28;15H[?12l[?25h[?25l
[27m[m[H[2J[1;1H[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb"); /* 読込モードでread_vocab_fileを開く */
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[9;1H[93m    [mzeの時 */
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) { /* 無限ループ */
[93m318 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数 */
[93m319 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m320 [m    a = AddWordToVocab(word);
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c);
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb");
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);[14;13H[?12l[?25hAddWordToVoca[?25lb[46m([mword[46m)[?12l[?25h[?25l[m(word)[?12l[?25hwor[?25l[46m([mword[46m)[?12l[?25h[?25l[m(word)[?12l[?25h[?25l[29;1H[1m-- INSERT --[14;34H[?12l[?25h[?25l[m [?12l[?25h[?25l /* 単語を語彙に加える */[?12l[?25h[?25l関数 */[?12l[?25h[?25lA */[?12l[?25h[?25lAd */[?12l[?25h[?25ldd */[?12l[?25h[?25ldV */[?12l[?25h[?25ld */[14;66H[K[14;63H[?12l[?25h[?25ldW */[?12l[?25h[?25lWo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25ldT */[?12l[?25h[?25lTo */[?12l[?25h[?25loV */[?12l[?25h[?25lVo */[?12l[?25h[?25loc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[15;49H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l ファイル */[?12l[?25h[?25lポインタ */[?12l[?25h[?25lf */[?12l[?25h[?25lfi */[?12l[?25h[?25lin */[?12l[?25h[?25lnから */[?12l[?25h[?25l読み出した */[?12l[?25h[?25l出した */[15;87H[K[15;78H[?12l[?25h[2C[2C[2C[?25l値 */[?12l[?25h[?25l[16;28r[16;1H[L[1;29r[15;86Hを **[16;1H[93m    [m/[15;88H[?12l[?25h[?25lv  [16;1H[93m    [m*/[15;89H[?12l[?25h[?25lvoo[16;1H[93m    [m */[?12l[?25h[?25l[93m [mc */[?12l[?25h[?25lca */[?12l[?25h[?25lab */[?12l[?25h[?25lb[ */[?12l[?25h[?25l[a */[?12l[?25h[?25l[46m[[ma[46m][m */[?12l[?25h[?25l[a]. */[?12l[?25h[?25l.c */[?12l[?25h[?25lcn */[?12l[?25h[?25lnに */[?12l[?25h[?25l取り込み */[?12l[?25h[?25l込み */[16;25H[K[16;18H[?12l[?25h[2C[2C[?25l， */[?12l[?25h[17;13H[?25l[11;17H[46m{[18;7H}[?12l[?25h[?25l[m[11;17H{[18;7H}[19;19H[?12l[?25h[?25l[20;27H[46m{[23;7H}[20;28H[?12l[?25h[?25l[m{[23;7H}[21;50H[?12l[?25h[22;60H[?25l[20;27H[46m{[23;7H}[?12l[?25h[?25l[m[20;27H{[23;7H}[24;37H[?12l[?25h[?25l[25;24H[46m{[28;7H}[25;25H[?12l[?25h[?25l[m{[28;7H}[26;58H[?12l[?25h[27;17H[?25l[25;24H[46m{[28;7H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[24;24H{[27;7H}
[93m334 [m  fseek(fin, 0, SEEK_END);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m335 [m  file_size = ftell(fin);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m336 [m  fclose(fin);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m337 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m338 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m339 [mvoid InitNet() {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m340 [m  long long a, b;[?12l[?25h[?25l[27;21H[?12l[?25h[26;5H[?25l[25;6H[?12l[?25h[24;19H[23;30H[22;31H[?25l[18;24H[46m{[21;7H}[?12l[?25h[?25l[m[18;24H{[21;7H}[20;17H[?12l[?25h[19;58H[?25l[18;24H[46m{[21;7H}[18;25H[?12l[?25h[?25l[m{[21;7H}[17;37H[?12l[?25h[?25l[13;27H[46m{[16;7H}[?12l[?25h[?25l[m[13;27H{[16;7H}[17;37H[?12l[?25h[?25l;　[?12l[?25h[?25l[17;37H[K[17;37H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [?25l 読み取り */[?12l[?25h[?25l */[17;50H[K[17;47H[?12l[?25h[?25l取 */[17;48H[K[17;43H[?12l[?25h[2C[?25lモード */[?12l[?25h[?25lで */[?12l[?25h[?25lt */[?12l[?25h[?25ltr */[?12l[?25h[?25lra */[?12l[?25h[?25lai */[?12l[?25h[?25lin */[?12l[?25h[?25ln_ */[?12l[?25h[?25l_f */[?12l[?25h[?25lfi */[?12l[?25h[?25lil */[?12l[?25h[?25lle */[?12l[?25h[?25leを */[?12l[?25h[?25l開く */[?12l[?25h[?25l[18;24H[46m{[21;7H}[18;25H[?12l[?25h[?25l[m{[21;7H}[19;58H[?12l[?25h[20;17H[?25l[18;24H[46m{[21;7H}[?12l[?25h[?25l[m[18;24H{[21;7H}[22;31H[?12l[?25h[23;30H[22;31H[?25l[18;24H[46m{[21;7H}[?12l[?25h[?25l[m[18;24H{[21;7H}[20;17H[?12l[?25h[19;58H[?25l[18;24H[46m{[21;7H}[18;25H[?12l[?25h[?25l[m{[21;7H}[17;69H[?12l[?25h[?25l[18;24H[46m{[21;7H}[18;25H[?12l[?25h[?25l[m{[21;7H}[19;58H[?12l[?25h[20;17H[?25l[18;24H[46m{[21;7H}[?12l[?25h[?25l[m[18;24H{[21;7H}[22;31H[?12l[?25h[23;30H[24;19H[?25l[25;6H[?12l[?25h[26;5H[?25l[27;21H[?12l[?25h[28;22H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m341 [m  unsigned long long next_random = 1;
[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeo[28;1H[94m@                                                                                        [27;42H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[28;1H[93m    [mf(real));[27;69H[?12l[?25h[26;42H[25;22H[?25l[24;21H[?12l[?25h[23;5H[?25l[22;6H[?12l[?25h[21;19H[20;30H[19;31H[?25l[15;24H[46m{[18;7H}[?12l[?25h[?25l[m[15;24H{[18;7H}[17;17H[?12l[?25h[16;58H[?25l[15;24H[46m{[18;7H}[15;25H[?12l[?25h[?25l[m{[18;7H}[16;58H[?12l[?25h[17;17H[?25l[15;24H[46m{[18;7H}[?12l[?25h[?25l[m[15;24H{[18;7H}[19;31H[?12l[?25h[20;30H[21;19H[?25l[22;6H[?12l[?25h[23;5H[?25l[24;21H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loi */[?12l[?25h[?25lid */[?12l[?25h[?25ld関数 */[?12l[?25h[?25lI */[?12l[?25h[?25lIn */[?12l[?25h[?25lni */[?12l[?25h[?25liN */[?12l[?25h[?25lNe */[?12l[?25h[?25let */[?12l[?25h[?25lt( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l()[25;22H[?12l[?25h[26;41H[27;41H[?25l[1;28r[28;1H
[1;29r[28;1H[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}[28;41H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m344 [m  if (hs) {[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[28;1H[93m    [meof(real));[27;41H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)[27;41H[?12l[?25h[?25l[28;13H[46m([26C)[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;13H([26C)
[93m348 [m     syn1[a * layer1_size + b] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;15H[46m{[m[28;1H[93m349 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;15H{[27;7H}
[93m350 [m  if (negative>0) {[?12l[?25h[?25l[21;15H[46m{[27;7H}[?12l[?25h[?25l[m[21;15H{[27;7H}[26;40H[?12l[?25h[?25l[25;13H[46m([26C)[?12l[?25h[?25l[m[25;13H([26C)[24;41H[?12l[?25h[22;41H[?25l[21;15H[46m{[27;7H}[21;16H[?12l[?25h[?25l[m{[27;7H}[20;41H[?12l[?25h[18;41H[17;41H[16;22H[17;41H[18;41H[20;41H[?25l[21;15H[46m{[27;7H}[21;16H[?12l[?25h[?25l[m{[27;7H}[22;41H[?12l[?25h[24;41H[?25l[25;13H[46m([26C)[?12l[?25h[?25l[m[25;13H([26C)[26;40H[?12l[?25h[?25l[21;15H[46m{[27;7H}[?12l[?25h[?25l[m[21;15H{[27;7H}[28;24H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [28;1H[93m    [msizeof(real));[27;41H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}[28;41H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m353 [m    for [46m([ma = 0; a < vocab_size; a++[46m)[m for (b = 0; b < layer1_size; b++)[28;41H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;13H([26C)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;23H[46m{[m[28;1H[93m355 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;23H{[27;7H}
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {[28;41H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[28;41H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m358 [m    syn0[a * layer1_size + b] = (((next_random & 0xFFFF) / (real)65536) - 0.5) / layee[28;1H[93m    [mr1_size;[27;41H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[24;74H[46m{[m[28;1H[93m359 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[23;74H{[27;7H}
[93m360 [m  CreateBinaryTree();[?12l[?25h[?25l[1;28r[28;1H
[1;29r[2;20H[46m{[m[28;1H[93m361 [m[46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[1;20H{[27;5H}
[93m362 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m363 [mvoid *TrainModelThread(void *id) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[28;41H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];[28;41H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;[27;41H[?12l[?25h[26;41H[25;41H[?25l[24;39H[?12l[?25h[23;5H[?25l[22;6H[?12l[?25h[21;26H[?25l[16;74H[46m{[20;7H}[?12l[?25h[?25l[m[16;74H{[20;7H}[18;41H[?12l[?25h[?25l[16;74H[46m{[20;7H}[?12l[?25h[?25l[m[16;74H{[20;7H}[21;26H[?12l[?25h[?25l[22;6H[?12l[?25h[21;26H[?25l[16;74H[46m{[20;7H}[?12l[?25h[?25l[m[16;74H{[20;7H}[18;41H[?12l[?25h[17;41H[16;41H[?25l[9;23H[46m{[15;7H}[?12l[?25h[?25l[m[9;23H{[15;7H}[14;41H[?12l[?25h[?25l[13;13H[46m([26C)[?12l[?25h[?25l[m[13;13H([26C)[12;41H[?12l[?25h[10;41H[?25l[9;23H[46m{[15;7H}[9;24H[?12l[?25h[?25l[2;15H{[8;7H}[m[9;23H{[15;7H}[8;8H[?12l[?25h[?25l[2;15H{[8;7H}[7;40H[?12l[?25h[?25l[6;13H[46m([26C)[?12l[?25h[?25l[m[6;13H([26C)[5;41H[?12l[?25h[3;41H[?25l[2;15H[46m{[8;7H}[2;16H[?12l[?25h[?25l[m{[8;7H}[1;41H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[2;1H[93m    [mf(real));[1;41H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m341 [m  unsigned long long next_random = 1;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m340 [m  long long a, b;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m339 [mvoid InitNet() { /* void関数IniNet[46m()[m */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m338 [m[2;39H()[1;5H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m337 [m}[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m336 [m  fclose(fin);[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m335 [m  file_size = ftell(fin);[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m334 [m  fseek(fin, 0, SEEK_END);[28;1H[94m@                                                                                        [1;31H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m333 [m  }[?12l[?25h[2;31H[3;30H[4;19H[?25l[5;6H[?12l[?25h[6;5H[?25l[7;39H[46m()[?12l[?25h[?25l[m()[8;22H[?12l[?25h[9;41H[8;22H[9;41H[10;41H[12;41H[10;41H[29;1H[K[10;40H[?25l[?12l[?25h[11;13H[?25l[29;1H[1m-- INSERT --[11;14H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [29;1H[K[11;18H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hposix[?25l[14;13H[?12l[?25h[?25l[29;1H?[10;11H[?12l[?25h[?25l[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[21;13H[?12l[?25h[?25l[m[29;1H?posix[29;7H[K[29;1H[14;13H[?12l[?25h[?25l[29;1H[10;11H[?12l[?25h[?25l[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[21;13H[?12l[?25h[?25l[m[29;1H?posix[29;7H[K[29;1H[14;13H[?12l[?25h[?25l[29;1H[10;11H[?12l[?25h[?25l[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[21;13H[?12l[?25h[?25l[m[29;1H?posix[29;7H[K[29;1H[14;13H[?12l[?25h[16;13H[14;13H[15;15H[?25l[29;1H[1m-- INSERT --[15;16H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l**[?12l[?25h[?25l[15;19H[K[15;19H[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h  */[?25l[13;15H[46m{[19;7H}[13;16H[?12l[?25h[?25l[m{[19;7H}[15;23H[?12l[?25h[?25l[13;15H[46m{[19;7H}[13;16H[?12l[?25h[?25l[m{[19;7H}[15;23H[?12l[?25h[?25l 1 */[?12l[?25h[?25l12 */[?12l[?25h[?25l28 */[?12l[?25h[?25l8b */[?12l[?25h[?25lby */[?12l[?25h[?25lyt */[?12l[?25h[?25lte */[?12l[?25h[?25les */[?12l[?25h[?25lsの */[?12l[?25h[?25lメモリ */[?12l[?25h[?25lを */[?12l[?25h[?25l割当 */[?12l[?25h[?25lて */[?12l[?25h128[?25l2bytesのメモリを割当て */[15;46H[K[15;22H[?12l[?25h[?25l1bytesのメモリを割当て */[15;45H[K[15;21H[?12l[?25h[?25l bytesのメモリを割当て */[15;44H[K[15;20H[?12l[?25h[?25l (bytesのメモリを割当て */[15;21H[?12l[?25h[?25l[46m()[mbytesのメモリを割当て */[15;22H[?12l[?25h[?25l[?12l[?25h[?25l[46m([ml[46m)[mbytesのメモリを割当て */[15;22H[?12l[?25h[?25llo[46m)[mbytesのメモリを割当て */[15;23H[?12l[?25h[?25lon[46m)[mbytesのメモリを割当て */[15;24H[?12l[?25h[?25lng[46m)[mbytesのメモリを割当て */[15;25H[?12l[?25h[?25lg [46m)[mbytesのメモリを割当て */[15;26H[?12l[?25h[?25l l[46m)[mbytesのメモリを割当て */[15;27H[?12l[?25h[?25llo[46m)[mbytesのメモリを割当て */[15;28H[?12l[?25h[?25lon[46m)[mbytesのメモリを割当て */[15;29H[?12l[?25h[?25lng[46m)[mbytesのメモリを割当て */[15;30H[?12l[?25h[?25l[1C[?12l[?25h[?25l[15;20H([9C)vbytesのメモリを割当て */[15;32H[?12l[?25h[?25lvobytesのメモリを割当て */[15;33H[?12l[?25h[?25locbytesのメモリを割当て */[15;34H[?12l[?25h[?25lcabytesのメモリを割当て */[15;35H[?12l[?25h[?25lbbytesのメモリを割当て */[15;36H[?12l[?25h[?25lb_bytesのメモリを割当て */[15;37H[?12l[?25h[?25l_sbytesのメモリを割当て */[15;38H[?12l[?25h[?25lsibytesのメモリを割当て */[15;39H[?12l[?25h[?25lizbytesのメモリを割当て */[15;40H[?12l[?25h[?25lzebytesのメモリを割当て */[15;41H[?12l[?25h[?25le bytesのメモリを割当て */[15;42H[?12l[?25h[?25l *bytesのメモリを割当て */[15;43H[?12l[?25h[?25l* bytesのメモリを割当て */[15;44H[?12l[?25h[?25l lbytesのメモリを割当て */[15;45H[?12l[?25h[?25llabytesのメモリを割当て */[15;46H[?12l[?25h[?25laybytesのメモリを割当て */[15;47H[?12l[?25h[?25lyebytesのメモリを割当て */[15;48H[?12l[?25h[?25lerbytesのメモリを割当て */[15;49H[?12l[?25h[?25lr1bytesのメモリを割当て */[15;50H[?12l[?25h[?25l1_bytesのメモリを割当て */[15;51H[?12l[?25h[?25l_sbytesのメモリを割当て */[15;52H[?12l[?25h[?25lsibytesのメモリを割当て */[15;53H[?12l[?25h[?25lizbytesのメモリを割当て */[15;54H[?12l[?25h[?25lzebytesのメモリを割当て */[15;55H[?12l[?25h[?25le bytesのメモリを割当て */[15;56H[?12l[?25h[?25l *bytesのメモリを割当て */[15;57H[?12l[?25h[?25l* bytesのメモリを割当て */[15;58H[?12l[?25h[?25l sbytesのメモリを割当て */[15;59H[?12l[?25h[?25lsibytesのメモリを割当て */[15;60H[?12l[?25h[?25lizbytesのメモリを割当て */[15;61H[?12l[?25h[?25lzebytesのメモリを割当て */[15;62H[?12l[?25h[?25leobytesのメモリを割当て */[15;63H[?12l[?25h[?25lofbytesのメモリを割当て */[15;64H[?12l[?25h[?25lf(bytesのメモリを割当て */[15;65H[?12l[?25h[?25l[46m()[mbytesのメモリを割当て */[15;66H[?12l[?25h[?25l[?12l[?25h[?25l[16;28r[16;1H[L[1;29r[15;64H[46m([mr[46m)[mbytesのメモリを割当て **[16;1H[93m    [m/[15;66H[?12l[?25h[?25lre[46m)[mbytesのメモリを割当て  [16;1H[93m    [m*/[15;67H[?12l[?25h[?25lea[46m)[mbytesのメモリを割当て [16;1H[93m    [m */[15;68H[?12l[?25h[?25lal[46m)[mbytesのメモリを割当[94m>>[m[16;1H[93m    [mて */[15;69H[?12l[?25h[?25l[20C[94m>>[m[16;1H[93m [15;70H[?12l[?25h[?25l[m(real) bytesのメモリを割当 [16;1H[93m [15;71H[?12l[?25h[mbytes[2C[2C[2C[2C[2C[2C[16;5H[2C */[?25lて */[?12l[?25h[?25l */[16;10H[K[16;7H[?12l[?25h[?25l， */[?12l[?25h[?25l割当た */[?12l[?25h[?25lメモリの */[?12l[?25h[?25lアドレスを */[?12l[?25h[?25l( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[1C[?12l[?25h[?25l[46m([mv[46m)[m */[?12l[?25h[?25lvo[46m)[m */[?12l[?25h[?25loi[46m)[m */[?12l[?25h[?25lid[46m)[m */[?12l[?25h[?25l[1C[?12l[?25h[?25l(void */[16;41H[K[16;38H[?12l[?25h[?25li */[16;40H[K[16;37H[?12l[?25h[?25lo */[16;39H[K[16;36H[?12l[?25h[?25lv */[16;38H[K[16;35H[?12l[?25h[?25l( */[16;37H[K[16;34H[?12l[?25h[?25l */[16;36H[K[16;33H[?12l[?25h[?25ls */[?12l[?25h[?25lsy */[?12l[?25h[?25ls */[16;37H[K[16;34H[?12l[?25h[?25l */[16;36H[K[16;33H[?12l[?25h[?25l( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l[?12l[?25h[?25l[46m([mv[46m)[m */[?12l[?25h[?25lvo[46m)[m */[?12l[?25h[?25loi[46m)[m */[?12l[?25h[?25lis[46m)[m */[?12l[?25h[?25li[46m)[m */[16;41H[K[16;37H[?12l[?25h[?25lid[46m)[m */[?12l[?25h[?25ld [46m)[m */[?12l[?25h[?25l *[46m)[m */[?12l[?25h[?25l**[46m)[m */[?12l[?25h[?25l[1C[?12l[?25h[?25l[16;33H([7C)& */[?12l[?25h[?25l&s */[?12l[?25h[?25lsy */[?12l[?25h[?25lyn */[?12l[?25h[?25ln1 */[?12l[?25h[?25l1に */[?12l[?25h[?25l割当 */[?12l[?25h[?25lる */[?12l[?25h[?25l． */[?12l[?25h[?25l割当た */[?12l[?25h[?25lメモリの */[?12l[?25h[?25lアドレスは */[?12l[?25h[?25l1 */[?12l[?25h[?25l12 */[?12l[?25h[?25l28 */[?12l[?25h[?25l8の */[?12l[?25h[?25l[17;28r[17;1H[L[1;29r[16;86H倍数 [17;1H[93m    [m */[?12l[?25h[?25l[18;27H[46m{[46C}[?12l[?25h[?25l[?12l[?25h[?25l[m[18;27H{[42C[46m([m1[46m)[m;}[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l(1)[?12l[?25h[?25lt[46m([m1[46m)[?12l[?25h[?25l([?12l[?25h[?25l[m1[?12l[?25h[?25l[1C[?12l[?25h[?25l[18;27H[46m{[m[42C(1);[46m}[?12l[?25h[?25l[m[18;27H{[46C}[19;46H[46m([27C)[?12l[?25h[?25l[m[19;46H([27C)[20;40H[?12l[?25h[?25l[13;15H[46m{[21;7H}[?12l[?25h[?25l[m[13;15H{[21;7H}[22;23H[46m{[28;7H}[22;24H[?12l[?25h[?25l[m{[28;7H}[23;74H[?12l[?25h[?25l[15C  [24;1H[93m [m[25;73H[46m([m1[46m)[?12l[?25h[?25l[m(1)[26;46H[46m([27C)[?12l[?25h[?25l[m[26;46H([27C)[27;43H[?12l[?25h[?25l[22;23H[46m{[28;7H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;23H{[27;7H}
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[27;74H[?25l[20;23H[46m{[26;7H}[?12l[?25h[?25l[m[20;23H{[26;7H}[25;43H[?12l[?25h[?25l[24;46H[46m([27C)[?12l[?25h[?25l[23;73H([m1[46m)[m[24;46H([27C)[23;74H[?12l[?25h[?25l(1)[21;74H[?12l[?25h[?25l[20;23H[46m{[26;7H}[20;24H[?12l[?25h[?25l[11;15H{[19;7H}[m[20;23H{[26;7H}[19;8H[?12l[?25h[?25l[11;15H{[19;7H}[18;40H[?12l[?25h[?25l[17;46H[46m([27C)[?12l[?25h[?25l[16;27H{[46C}[m[17;46H([27C)[16;74H[?12l[?25h[?25l[16;27H{[46C}[12;74H[?12l[?25h[?25l[11;15H[46m{[19;7H}[11;16H[?12l[?25h[?25l[10;25H{[46C}[m[11;15H{[19;7H}[10;73H[?12l[?25h[?25l[10;25H{[46C}[11;15H[46m{[19;7H}[11;16H[?12l[?25h[m[29;1H[K[11;15H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hhs[?25l[27m[m[H[2J[1;1H[93m425 [m      cw = 0;
[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {
[93m427 [m[7C c = sentence_position - window + a;
[93m428 [m[7C if (c < 0) continue;
[93m429 [m[7C if (c >= sentence_length) continue;
[93m430 [m[7C last_word = sen[c];
[93m431 [m[7C if (last_word == -1) continue;
[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_sizee[9;1H[93m    [m];
[93m433 [m[7C cw++;
[93m434 [m      }
[93m435 [m      if (cw) {
[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;
[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {
[93m438 [m[9C f = 0;
[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;
[93m440 [m[9C // Propagate hidden -> output
[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1[c + l2];
[93m442 [m[9C if (f <= -MAX_EXP) continue;
[93m443 [m[9C else if (f >= MAX_EXP) continue;
[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];
[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate
[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;
[93m447 [m[9C // Propagate errors output -> hidden
[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];
[93m449 [m[9C // Learn weights hidden -> output
[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];
[93m451 [m[7C }[14;17H[?12l[?25h[?25l[29;1H?hs[27m[m[H[2J[1;1H[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 
339 [mvoid InitNet() { /* void関数IniNet() */
[93m340 [m  long long a, b;
[93m341 [m  unsigned long long next_random = 1;
[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[12;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) {
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[16;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [17;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[18;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [25;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;[14;11H[?12l[?25h[?25l[29;1H?hs[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;[14;9H[?12l[?25h[?25l[29;1H?hs[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m678 [m  if ((i = ArgPos((char *)"-save-vocab", argc, argv)) > 0) strcpy(save_vocab_file, arr[2;1H[93m    [mgv[i + 1]);
[93m679 [m  if ((i = ArgPos((char *)"-read-vocab", argc, argv)) > 0) strcpy(read_vocab_file, arr[4;1H[93m    [mgv[i + 1]);
[93m680 [m  if ((i = ArgPos((char *)"-debug", argc, argv)) > 0) debug_mode = atoi(argv[i + 1]);[6;1H[93m681 [m  if ((i = ArgPos((char *)"-binary", argc, argv)) > 0) binary = atoi(argv[i + 1]);
[93m682 [m  if ((i = ArgPos((char *)"-cbow", argc, argv)) > 0) cbow = atoi(argv[i + 1]);
[93m683 [m  if (cbow) alpha = 0.05;
[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);
[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[11;1H[93m    [m]);
[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);
[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);
[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argv[i + 1]))[16;1H[93m    [m;
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 11[18;1H[93m    [m]);
[93m691 [m  if ((i = ArgPos((char *)"-iter", argc, argv)) > 0) iter = atoi(argv[i + 1]);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 11[21;1H[93m    [m]);
[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[i + 1]);
[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word));
[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));
[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {
[93m698 [m    expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precompute thh[28;1H[93m    [me exp() table
[38;5;224msearch hit TOP, continuing at BOTTOM[14;56H[?12l[?25h[?25l[m[29;1H/hs[29;4H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[38;5;224msearch hit BOTTOM, continuing at TOP[14;9H[?12l[?25h[?25l[m[29;1H/hs[29;4H[K[29;1H[27m[m[H[2J[1;1H[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 
339 [mvoid InitNet() { /* void関数IniNet() */
[93m340 [m  long long a, b;
[93m341 [m  unsigned long long next_random = 1;
[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[12;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) {
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[16;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [17;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[18;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [25;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;[14;11H[?12l[?25h[?25l[29;1H?hs[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5;
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;[14;9H[?12l[?25hhs = 0, negative = 5[?25l[29;1H[1m-- INSERT --[14;30H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l h */[?12l[?25h[?25lhs */[?12l[?25h[?25lsは */[?12l[?25h[?25l3 */[?12l[?25h[?25l30 */[?12l[?25h[?25l04 */[?12l[?25h[?25l4行目 */[?12l[?25h[?25lで */[?12l[?25h[?25l初出 */[?12l[?25h[29;1H[K[14;49H[?25l[?12l[?25h[?25l[29;1H:[?12l[?25h304[?25l[27m[m[H[2J[1;1H[93m292 [m    printf("Vocab size: %lld\n", vocab_size);
[93m293 [m    printf("Words in train file: %lld\n", train_words);
[93m294 [m  }
[93m295 [m  file_size = ftell(fin);
[93m296 [m  fclose(fin);
[93m297 [m}
[93m298 
299 [mvoid SaveVocab() {
[93m300 [m  long long i;
[93m301 [m  FILE *fo = fopen(save_vocab_file, "wb");
[93m302 [m  for (i = 0; i < vocab_size; i++) fprintf(fo, "%s %lld\n", vocab[i].word, vocab[i].cc[12;1H[93m    [mn);
[93m303 [m  fclose(fo);
[93m304 [m}
[93m305 
306 [mvoid ReadVocab() { /* void型関数ReadVocab */
[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb"); /* 読込モードでread_vocab_fileを開く */
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[26;1H[93m    [mzeの時 */
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) { /* 無限ループ */[14;5H[?12l[?25h[?25l[29;1H/[?12l[?25hhs[?25l[27m[m[H[2J[1;1H[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 
339 [mvoid InitNet() { /* void関数IniNet() */
[93m340 [m  long long a, b;
[93m341 [m  unsigned long long next_random = 1;
[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[12;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) {
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[16;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [17;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[18;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [25;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;[14;11H[?12l[?25h[?25l[29;1H?hs[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5; /* hsは304行目で初出 */
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;[14;34H[?12l[?25hhs[2C30[?25l[29;1H[1m-- INSERT --[14;40H[?12l[?25h[?25l[m34行目で初出 */[14;53H[K[14;39H[?12l[?25h[?25l44行目で初出 */[14;40H[?12l[?25h[29;1H[K[14;39H[?25l[?12l[?25h[?25l[29;1H:[?12l[?25h30[?25l[29;3H[K[29;3H[?12l[?25h44[?25l[27m[m[H[2J[1;1H[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 
339 [mvoid InitNet() { /* void関数IniNet() */
[93m340 [m  long long a, b;
[93m341 [m  unsigned long long next_random = 1;
[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[12;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) {
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[16;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [17;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[18;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [25;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;[14;7H[?12l[?25hif[?25l [46m([mhs[46m)[?12l[?25h[?25l[m(hs)[?12l[?25hh[?25l[46m([mhs[46m)[?12l[?25h[?25l[m(hs)[?12l[?25h[?25l [46m{[22;7H}[14;15H[?12l[?25h[?25l[m[29;1H[1m-- INSERT --[14;16H[?12l[?25h[?25l[m{a[22;7H}[14;17H[?12l[?25h[?25l[46m{[m[14;16H[K[22;7H[46m}[14;16H[?12l[?25h[?25l[m{[22;7H}[14;17H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l h */[?12l[?25h[?25lhs */[?12l[?25h[?25ls0 */[?12l[?25h[?25ls */[14;25H[K[14;22H[?12l[?25h[?25ls= */[?12l[?25h[?25l=0 */[?12l[?25hhs=0[?25l0より */[?12l[?25h[29;1H[K[14;26H[?25l[?12l[?25h[?25l[29;1H?hs[14;20H[?12l[?25h[?25l[29;1H[14;11H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5; /* hsは344行目で初出 */
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;[14;34H[?12l[?25h[?25l[29;1H/hs[27m[m[H[2J[1;1H[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 
339 [mvoid InitNet() { /* void関数IniNet() */
[93m340 [m  long long a, b;
[93m341 [m  unsigned long long next_random = 1;
[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[12;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) { /* hs=0より */
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[16;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [17;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[18;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [25;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;[14;11H[?12l[?25h[?25l[29;1H/hs[14;20H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m425 [m      cw = 0;
[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {
[93m427 [m[7C c = sentence_position - window + a;
[93m428 [m[7C if (c < 0) continue;
[93m429 [m[7C if (c >= sentence_length) continue;
[93m430 [m[7C last_word = sen[c];
[93m431 [m[7C if (last_word == -1) continue;
[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_sizee[9;1H[93m    [m];
[93m433 [m[7C cw++;
[93m434 [m      }
[93m435 [m      if (cw) {
[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;
[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {
[93m438 [m[9C f = 0;
[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;
[93m440 [m[9C // Propagate hidden -> output
[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1[c + l2];
[93m442 [m[9C if (f <= -MAX_EXP) continue;
[93m443 [m[9C else if (f >= MAX_EXP) continue;
[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];
[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate
[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;
[93m447 [m[9C // Propagate errors output -> hidden
[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];
[93m449 [m[9C // Learn weights hidden -> output
[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];
[93m451 [m[7C }[14;17H[?12l[?25h[?25l[29;1H?hs[27m[m[H[2J[1;1H[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 
339 [mvoid InitNet() { /* void関数IniNet() */
[93m340 [m  long long a, b;
[93m341 [m  unsigned long long next_random = 1;
[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[12;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) { /* hs=0より */
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[16;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [17;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[18;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [25;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;[14;20H[?12l[?25h[15;20H[19;20H[20;20H[21;20H[?25l[14;15H[46m{[22;7H}[?12l[?25h[?25l[m[14;15H{[22;7H}[23;20H[?12l[?25h[?25l[14;15H[46m{[22;7H}[?12l[?25h[?25l[m[14;15H{[22;7H}[21;20H[?12l[?25h[20;20H[19;20H[15;20H[14;20H[15;20H[19;20H[20;20H[21;20H[?25l[14;15H[46m{[22;7H}[?12l[?25h[?25l[m[14;15H{[22;7H}[23;20H[?12l[?25h[24;20H[23;20H[?25l[14;15H[46m{[22;7H}[?12l[?25h[?25l[m[14;15H{[22;7H}[21;20H[?12l[?25h[?25l[14;15H[46m{[22;7H}[?12l[?25h[?25l[m[14;15H{[22;7H}[23;20H[?12l[?25h[24;20H[23;20H[?25l[14;15H[46m{[22;7H}[?12l[?25h[?25l[m[14;15H{[22;7H}[21;20H[?12l[?25h[20;20H[19;20H[15;20H[14;20H[15;20H[14;20Hhs=0[2C[2C *[15;30H[14;29H=0[2C[2C[?25l[29;1H[1m-- INSERT --[14;28H[?12l[?25h[?25l[mi */[?12l[?25h[?25lif */[?12l[?25h[?25lf文 */[?12l[?25h[?25l内は */[?12l[?25h[?25lF */[?12l[?25h[?25lFA */[?12l[?25h[?25lAL */[?12l[?25h[?25lLS */[?12l[?25h[?25lSE */[?12l[?25h[?25lはFALSE */[14;42H[K[14;32H[?12l[?25h[?25lこのif文はFALSE */[14;32H[?12l[?25hif[2C[2CFALSE [15;44H[19;44H[20;44H[21;40H[20;44H[19;44Hllocation failed\n[?25l[19;34H[46m([28C)[?12l[?25h[?25l)[?12l[?25h[?25l[m[19;34H([28C);[?12l[?25h exi[?25lt[46m([m1[46m)[?12l[?25h[?25l([?12l[?25h[?25l[m1[?12l[?25h[?25l[1C[?12l[?25h[?25l[19;27H[46m{[m[42C(1);[46m}[?12l[?25h[?25l}[?12l[?25h[?25l[m[19;27H{[46C} [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l**[?12l[?25h[?25l*/[?12l[?25h[?25l* */[?12l[?25h[?25l  */[?12l[?25h[?25l 上で */[?12l[?25h[?25l[20;28r[20;1H[L[1;29r[19;83Hメモリ  [20;1H[93m    [m*/[19;89H[?12l[?25h[?25l[94m>>[m[20;1H[93m    [mの */[?12l[?25h[?25l割当 */[?12l[?25h[?25lに */[?12l[?25h[?25l失敗した時に */[?12l[?25h[?25l表示 */[?12l[?25h[29;1H[K[20;27H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hhs[?25l[27m[m[H[2J[1;1H[93m425 [m      cw = 0;
[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {
[93m427 [m[7C c = sentence_position - window + a;
[93m428 [m[7C if (c < 0) continue;
[93m429 [m[7C if (c >= sentence_length) continue;
[93m430 [m[7C last_word = sen[c];
[93m431 [m[7C if (last_word == -1) continue;
[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_sizee[9;1H[93m    [m];
[93m433 [m[7C cw++;
[93m434 [m      }
[93m435 [m      if (cw) {
[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;
[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {
[93m438 [m[9C f = 0;
[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;
[93m440 [m[9C // Propagate hidden -> output
[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1[c + l2];
[93m442 [m[9C if (f <= -MAX_EXP) continue;
[93m443 [m[9C else if (f >= MAX_EXP) continue;
[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];
[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate
[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;
[93m447 [m[9C // Propagate errors output -> hidden
[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];
[93m449 [m[9C // Learn weights hidden -> output
[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];
[93m451 [m[7C }[14;17H[?12l[?25h[?25l[29;1H/hs[27m[m[H[2J[1;1H[93m480 [m[9C for (c = 0; c < layer1_size; c++) syn0[c + last_word * layer1_size] += neu11[2;1H[93m    [me[c];
[93m481 [m[7C }
[93m482 [m      }
[93m483 [m    } else {  //train skip-gram
[93m484 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {
[93m485 [m[7C c = sentence_position - window + a;
[93m486 [m[7C if (c < 0) continue;
[93m487 [m[7C if (c >= sentence_length) continue;
[93m488 [m[7C last_word = sen[c];
[93m489 [m[7C if (last_word == -1) continue;
[93m490 [m[7C l1 = last_word * layer1_size;
[93m491 [m[7C for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
[93m492 [m[7C // HIERARCHICAL SOFTMAX
[93m493 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {
[93m494 [m[9C f = 0;
[93m495 [m[9C l2 = vocab[word].point[d] * layer1_size;
[93m496 [m[9C // Propagate hidden -> output
[93m497 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1[c + l2];
[93m498 [m[9C if (f <= -MAX_EXP) continue;
[93m499 [m[9C else if (f >= MAX_EXP) continue;
[93m500 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];
[93m501 [m[9C // 'g' is the gradient multiplied by the learning rate
[93m502 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;
[93m503 [m[9C // Propagate errors output -> hidden
[93m504 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];
[93m505 [m[9C // Learn weights hidden -> output
[93m506 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * syn0[c + l1];[15;17H[?12l[?25h[?25l[29;1H/hs[27m[m[H[2J[1;1H[93m634 [m    printf("\t-train <file>\n");
[93m635 [m    printf("\t\tUse text data from <file> to train the model\n");
[93m636 [m    printf("\t-output <file>\n");
[93m637 [m    printf("\t\tUse <file> to save the resulting word vectors / word clusters\n");
[93m638 [m    printf("\t-size <int>\n");
[93m639 [m    printf("\t\tSet size of word vectors; default is 100\n");
[93m640 [m    printf("\t-window <int>\n");
[93m641 [m    printf("\t\tSet max skip length between words; default is 5\n");
[93m642 [m    printf("\t-sample <float>\n");
[93m643 [m    printf("\t\tSet threshold for occurrence of words. Those that appear with higher  [11;1H[93m    [mfrequency in the training data\n");
[93m644 [m    printf("\t\twill be randomly down-sampled; default is 1e-3, useful range is (0, 11[13;1H[93m    [me-5)\n");
[93m645 [m    printf("\t-hs <int>\n");
[93m646 [m    printf("\t\tUse Hierarchical Softmax; default is 0 (not used)\n");
[93m647 [m    printf("\t-negative <int>\n");
[93m648 [m    printf("\t\tNumber of negative examples; default is 5, common values are 3 - 10 (([18;1H[93m    [m0 = not used)\n");
[93m649 [m    printf("\t-threads <int>\n");
[93m650 [m    printf("\t\tUse <int> threads (default 12)\n");
[93m651 [m    printf("\t-iter <int>\n");
[93m652 [m    printf("\t\tRun more training iterations (default 5)\n");
[93m653 [m    printf("\t-min-count <int>\n");
[93m654 [m    printf("\t\tThis will discard words that appear less than <int> times; default iss[25;1H[93m    [m 5\n");
[93m655 [m    printf("\t-alpha <float>\n");
[93m656 [m    printf("\t\tSet the starting learning rate; default is 0.025 for skip-gram and 0..[28;1H[93m    [m05 for CBOW\n");[14;20H[?12l[?25h[?25l[29;1H/hs[27m[m[H[2J[1;1H[93m659 [m    printf("\t-debug <int>\n");
[93m660 [m    printf("\t\tSet the debug mode (default = 2 = more info during training)\n");
[93m661 [m    printf("\t-binary <int>\n");
[93m662 [m    printf("\t\tSave the resulting vectors in binary moded; default is 0 (off)\n");
[93m663 [m    printf("\t-save-vocab <file>\n");
[93m664 [m    printf("\t\tThe vocabulary will be saved to <file>\n");
[93m665 [m    printf("\t-read-vocab <file>\n");
[93m666 [m    printf("\t\tThe vocabulary will be read from <file>, not constructed from the traa[9;1H[93m    [mining data\n");
[93m667 [m    printf("\t-cbow <int>\n");
[93m668 [m    printf("\t\tUse the continuous bag of words model; default is 1 (use 0 for skip-gg[12;1H[93m    [mram model)\n");
[93m669 [m    printf("\nExamples:\n");
[93m670 [m    printf("./word2vec -train data.txt -output vec.txt -size 200 -window 5 -sample 1ee[15;1H[93m    [m-4 -negative 5 -hs 0 -binary 0 -cbow 1 -iter 3\n\n");
[93m671 [m    return 0;
[93m672 [m  }
[93m673 [m  output_file[0] = 0;
[93m674 [m  save_vocab_file[0] = 0;
[93m675 [m  read_vocab_file[0] = 0;
[93m676 [m  if ((i = ArgPos((char *)"-size", argc, argv)) > 0) layer1_size = atoi(argv[i + 1]);[22;1H[93m677 [m  if ((i = ArgPos((char *)"-train", argc, argv)) > 0) strcpy(train_file, argv[i + 1]))[23;1H[93m    [m;
[93m678 [m  if ((i = ArgPos((char *)"-save-vocab", argc, argv)) > 0) strcpy(save_vocab_file, arr[25;1H[93m    [mgv[i + 1]);
[93m679 [m  if ((i = ArgPos((char *)"-read-vocab", argc, argv)) > 0) strcpy(read_vocab_file, arr[27;1H[93m    [mgv[i + 1]);
[93m680 [m  if ((i = ArgPos((char *)"-debug", argc, argv)) > 0) debug_mode = atoi(argv[i + 1]);[15;21H[?12l[?25h[?25l[29;1H/hs[1;28r[1;1H[9M[1;29r[20;1H[93m681 [m  if ((i = ArgPos((char *)"-binary", argc, argv)) > 0) binary = atoi(argv[i + 1]);
[93m682 [m  if ((i = ArgPos((char *)"-cbow", argc, argv)) > 0) cbow = atoi(argv[i + 1]);
[93m683 [m  if (cbow) alpha = 0.05;
[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);
[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[25;1H[93m    [m]);
[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);
[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);[29;1H[K[28;33H[?12l[?25h[?25l
/hs[28;56H[?12l[?25h[?25l
[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5; /* hsは344行目で初出 */
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[38;5;224msearch hit BOTTOM, continuing at TOP[14;9H[?12l[?25h[?25l[m[29;1H/hs[29;4H[K[29;1H[14;34H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m332 [m    exit(1);
[93m333 [m  }
[93m334 [m  fseek(fin, 0, SEEK_END);
[93m335 [m  file_size = ftell(fin);
[93m336 [m  fclose(fin);
[93m337 [m}
[93m338 
339 [mvoid InitNet() { /* void関数IniNet() */
[93m340 [m  long long a, b;
[93m341 [m  unsigned long long next_random = 1;
[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[12;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) { /* hs=0よりこのif文はFALSE */
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[16;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当[17;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[18;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);} /* 上でメモリ[94m>>[m[20;1H[93m    [mの割当に失敗した時に表示 */
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [26;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)[14;11H[?12l[?25h[15;11H[19;11H[21;11H[22;11H[?25l[14;15H[46m{[23;7H}[?12l[?25h[?25l[m[14;15H{[23;7H}[24;11H[?12l[?25h[25;11H[27;11H[28;11H[?25l[1;28r[28;1H
[1;29r[28;1H[93m354 [m     syn1neg[a * layer1_size + b] = 0;[28;11H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;23H[46m{[m[28;1H[93m355 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;23H{[27;7H}
[93m356 [m  for [46m([ma = 0; a < vocab_size; a++[46m)[m for (b = 0; b < layer1_size; b++) {[28;11H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;11H([26C)
[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[28;11H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m358 [m    syn0[a * layer1_size + b] = (((next_random & 0xFFFF) / (real)65536) - 0.5) / layee[28;1H[93m    [mr1_size;[27;11H[?12l[?25h[26;11H[27;11H[?25l[1;28r[28;1H
[1;29r[24;74H[46m{[m[28;1H[93m359 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[23;74H{[27;7H}
[93m360 [m  CreateBinaryTree();[28;11H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m361 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m362 [?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[27;1H[93m363 [mvoid *TrainModelThread(void *id) {
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[27;11H[?12l[?25h[26;5H[25;5H[24;11H[?25l[19;74H[46m{[23;7H}[?12l[?25h[?25l[m[19;74H{[23;7H}[21;11H[?12l[?25h[20;11H[?25l[19;11H[46m([26C)[19;11H[?12l[?25h[?25l[12;23H{[18;7H}[m[19;11H([26C)[18;7H[?12l[?25h[?25l[12;23H{[18;7H}[17;11H[?12l[?25h[16;11H[15;11H[13;11H[12;11H[?25l[2;15H[46m{[11;7H}[?12l[?25h[?25l[m[2;15H{[11;7H}[10;11H[?12l[?25h[9;11H[7;11H[3;11H[2;11H[1;11H[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[2;1H[93m    [mf(real)); /*  */[1;11H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m341 [m  unsigned long long next_random = 1;[1;11H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m340 [m  long long a, b;[1;11H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m339 [mvoid InitNet() { /* void関数IniNet() */[1;11H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m338 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m337 [m}[28;1H[94m@                                                                                        [1;5H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m336 [m  fclose(fin);[1;11H[?12l[?25h[2;5H[3;5H[4;11H[5;11H[6;11H[7;11H[9;11H[10;11H[11;11H[15;11H[17;11H[18;11H[?25l[10;15H[46m{[19;7H}[?12l[?25h[?25l[m[10;15H{[19;7H}[20;11H[?12l[?25h[21;11H[23;11H[24;11H[25;11H[?25l[20;23H[46m{[26;7H}[?12l[?25h[?25l[m[20;23H{[26;7H}[25;11H[?12l[?25h[?25l[29;1H/[?12l[?25hneb[?25l[29;4H[K[29;4H[?12l[?25hgative[?25l[27m[m[H[2J[1;1H[93m440 [m[9C // Propagate hidden -> output
[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1[c + l2];
[93m442 [m[9C if (f <= -MAX_EXP) continue;
[93m443 [m[9C else if (f >= MAX_EXP) continue;
[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];
[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate
[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;
[93m447 [m[9C // Propagate errors output -> hidden
[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];
[93m449 [m[9C // Learn weights hidden -> output
[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];
[93m451 [m[7C }
[93m452 [m[7C // NEGATIVE SAMPLING
[93m453 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {
[93m454 [m[9C if (d == 0) {
[93m455 [m[11C target = word;
[93m456 [m[11C label = 1;
[93m457 [m[9C } else {
[93m458 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m459 [m[11C target = table[(next_random >> 16) % table_size];
[93m460 [m[11C if (target == 0) target = next_random % (vocab_size - 1) + 1;
[93m461 [m[11C if (target == word) continue;
[93m462 [m[11C label = 0;
[93m463 [m[9C }
[93m464 [m[9C l2 = target * layer1_size;
[93m465 [m[9C f = 0;
[93m466 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1neg[c + l2];
[93m467 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[14;17H[?12l[?25h[?25l[29;1H?negative[27m[m[H[2J[1;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[2;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) { /* hs=0よりこのif文はFALSE */
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[6;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [7;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[8;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);} /* 上でメモリ[94m>>[m[10;1H[93m    [mの割当に失敗した時に表示 */
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [16;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;
[93m355 [m  }
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {
[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m358 [m    syn0[a * layer1_size + b] = (((next_random & 0xFFFF) / (real)65536) - 0.5) / layee[24;1H[93m    [mr1_size;
[93m359 [m  }
[93m360 [m  CreateBinaryTree();
[93m361 [m}
[93m362 [14;11H[?12l[?25h[?25l[m[29;1H?negative[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5; /* hsは344行目で初出 */
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;[14;17H[?12l[?25h[?25l[29;1H?negative[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m679 [m  if ((i = ArgPos((char *)"-read-vocab", argc, argv)) > 0) strcpy(read_vocab_file, arr[2;1H[93m    [mgv[i + 1]);
[93m680 [m  if ((i = ArgPos((char *)"-debug", argc, argv)) > 0) debug_mode = atoi(argv[i + 1]);[4;1H[93m681 [m  if ((i = ArgPos((char *)"-binary", argc, argv)) > 0) binary = atoi(argv[i + 1]);
[93m682 [m  if ((i = ArgPos((char *)"-cbow", argc, argv)) > 0) cbow = atoi(argv[i + 1]);
[93m683 [m  if (cbow) alpha = 0.05;
[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);
[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[9;1H[93m    [m]);
[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);
[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);
[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argv[i + 1]))[14;1H[93m    [m;
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 11[16;1H[93m    [m]);
[93m691 [m  if ((i = ArgPos((char *)"-iter", argc, argv)) > 0) iter = atoi(argv[i + 1]);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 11[19;1H[93m    [m]);
[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[i + 1]);
[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word));
[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));
[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {
[93m698 [m    expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precompute thh[26;1H[93m    [me exp() table
[93m699 [m    expTable[i] = expTable[i] / (expTable[i] + 1);[18C // Precompute f(([28;1H[93m    [mx) = x / (x + 1)
[38;5;224msearch hit TOP, continuing at BOTTOM[13;62H[?12l[?25h[?25l[m[29;1H/negative[29;10H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5; /* hsは344行目で初出 */
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[38;5;224msearch hit BOTTOM, continuing at TOP[14;17H[?12l[?25h[?25l[m[29;1H/negative[29;10H[K[29;1H[27m[m[H[2J[1;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[2;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) { /* hs=0よりこのif文はFALSE */
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[6;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [7;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[8;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);} /* 上でメモリ[94m>>[m[10;1H[93m    [mの割当に失敗した時に表示 */
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [16;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;
[93m355 [m  }
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {
[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m358 [m    syn0[a * layer1_size + b] = (((next_random & 0xFFFF) / (real)65536) - 0.5) / layee[24;1H[93m    [mr1_size;
[93m359 [m  }
[93m360 [m  CreateBinaryTree();
[93m361 [m}
[93m362 [14;11H[?12l[?25h[?25l[m[29;1H?negative[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5; /* hsは344行目で初出 */
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;[14;17H[?12l[?25hnegative = 5; /* hs[2C344[2C[2C[?25l[29;1H[1m-- INSERT --[14;47H[?12l[?25h[?25l[m，で初出 */[14;47H[?12l[?25h[?25lnで初出 */[14;48H[?12l[?25h[?25lneで初出 */[14;49H[?12l[?25h[?25legで初出 */[14;50H[?12l[?25h[?25lgaで初出 */[14;51H[?12l[?25h[?25latで初出 */[14;52H[?12l[?25h[?25ltiで初出 */[14;53H[?12l[?25h[?25livで初出 */[14;54H[?12l[?25h[?25lveで初出 */[14;55H[?12l[?25h[?25lはで初出 */[14;57H[?12l[?25h[?25l3で初出 */[14;58H[?12l[?25h[?25l35で初出 */[14;59H[?12l[?25h[?25l50で初出 */[14;60H[?12l[?25h[?25l0行目で初出 */[14;64H[?12l[?25h[29;1H[K[14;62H[?25l[?12l[?25h[?25l[29;1H/negative[27m[m[H[2J[1;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[2;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) { /* hs=0よりこのif文はFALSE */
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[6;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [7;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[8;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);} /* 上でメモリ[94m>>[m[10;1H[93m    [mの割当に失敗した時に表示 */
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [16;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;
[93m355 [m  }
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {
[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m358 [m    syn0[a * layer1_size + b] = (((next_random & 0xFFFF) / (real)65536) - 0.5) / layee[24;1H[93m    [mr1_size;
[93m359 [m  }
[93m360 [m  CreateBinaryTree();
[93m361 [m}
[93m362 [14;11H[?12l[?25h[?25l[m[29;1H?negative[27m[m[H[2J[1;1H[93m 40 [mstruct vocab_word *vocab; /* 構造体型struct vocab_wordでポインタvocab(これは変数だか[94m>>[m[2;1H[93m    [mらvocab.cn, vocab.point, vocab.word, vocab.code, vocab.codelenを持つ)を宣言 */
[93m 41 [mint binary = 0, cbow = 1, debug_mode = 2, window = 5, min_count = 5, num_threads = 122[4;1H[93m    [m, min_reduce = 1;
[93m 42 [mint *vocab_hash; /* int型ポインタvocab_hash(SearchVocab()で使用) */
[93m 43 [mlong long vocab_max_size = 1000, vocab_size = 0, layer1_size = 100; /* long long型vocc[7;1H[93m    [mab_max_size, vocab_sizeとlayer1_sizeを宣言 */
[93m 44 [mlong long train_words = 0, word_count_actual = 0, iter = 5, file_size = 0, classes =  [9;1H[93m    [m0;
[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5; /* hsは344行目，negativeは350行目で初出 */
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[23;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;[14;47H[?12l[?25h[?25l[29;1H/negative[27m[m[H[2J[1;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[2;1H[93m    [mf(real)); /*  */
[93m343 [m  if (syn0 == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m344 [m  if (hs) { /* hs=0よりこのif文はFALSE */
[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[6;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [7;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[8;1H[93m    [m */
[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);} /* 上でメモリ[94m>>[m[10;1H[93m    [mの割当に失敗した時に表示 */
[93m347 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m348 [m     syn1[a * layer1_size + b] = 0;
[93m349 [m  }
[93m350 [m  if (negative>0) {
[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [16;1H[93m    [msizeof(real));
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);}
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++)
[93m354 [m     syn1neg[a * layer1_size + b] = 0;
[93m355 [m  }
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {
[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m358 [m    syn0[a * layer1_size + b] = (((next_random & 0xFFFF) / (real)65536) - 0.5) / layee[24;1H[93m    [mr1_size;
[93m359 [m  }
[93m360 [m  CreateBinaryTree();
[93m361 [m}
[93m362 [14;11H[?12l[?25h[mnegative>[?25l[14;10H[46m([10C)[?12l[?25h[?25l[m[14;10H([10C)[?12l[?25h[?25l [46m{[20;7H}[14;23H[?12l[?25h[?25l[m[29;1H[1m-- INSERT --[14;24H[?12l[?25h[?25l[m{[20;7H}[14;25H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l n */[?12l[?25h[?25lne */[?12l[?25h[?25leg */[?12l[?25h[?25lga */[?12l[?25h[?25lat */[?12l[?25h[?25lti */[?12l[?25h[?25liv */[?12l[?25h[?25lve */[?12l[?25h[?25le= */[?12l[?25h[?25l=5 */[?12l[?25h[?25l5より */[?12l[?25h[?25lこの */[?12l[?25h[?25li */[?12l[?25h[?25lif */[?12l[?25h[?25lf文 */[?12l[?25h[?25lは */[?12l[?25h[?25lT */[?12l[?25h[?25lTU */[?12l[?25h[?25lT */[14;56H[K[14;53H[?12l[?25h[?25lTR */[?12l[?25h[?25lRU */[?12l[?25h[?25lUE */[?12l[?25h[15;56H[17;56H[18;56H[17;56H[29;1H[K[17;55H[?25l[?12l[?25h[?25l[17;30H[46m{[46C}[?12l[?25h[?25l[m[29;1H[1m-- INSERT --[17;78H[?12l[?25h[?25l[m[17;30H{[46C} [?12l[?25h[?25l[18;28r[18;1H[L[1;29r[17;78H /* 上でメモ[18;1H[93m    [mリ>    の割当に失敗した時に表示 */[?12l[?25h[?25l の割当に失敗した時に表示 */[18;38H[K[18;11H[?12l[?25h[?25l の割当に失敗した時に表示 */[18;37H[K[18;10H[?12l[?25h[?25l の割当に失敗した時に表示 */[18;36H[K[18;9H[?12l[?25h[?25l>の割当に失敗した時に表示 */[18;35H[K[18;8H[?12l[?25h[?25lの割当に失敗した時に表示 */[18;34H[K[18;7H[?12l[?25h[17;88H[15;86H[14;59H[15;86H[29;1H[K[15;85H[?25l[?12l[?25h[14;58H[?25l[4;15H[46m{[13;7H}[?12l[?25h[?25l[m[4;15H{[13;7H}[12;39H[?12l[?25h[?25l[11;46H[46m([27C)[?12l[?25h[?25l[m[11;46H([27C)[9;85H[?12l[?25h[5;85H[?25l[29;1H/negative[14;11H[?12l[?25h[15;11H[17;11H[15;11H[16;18H[?25l[29;1H[1m-- INSERT --[16;19H[?12l[?25h[?25l[m [?12l[?25h[?25l /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモ[?12l[?25h[?25l[17;28r[17;1H[2L[1;29r[16;85Hリを[94m>>[m[17;1H[93m    [m割当    て，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは11[18;1H[93m    [m28の倍数     */[?12l[?25h[?25l */[18;19H[K[18;16H[?12l[?25h[?25l */[18;18H[K[18;15H[?12l[?25h[?25l */[18;17H[K[18;14H[?12l[?25h[?25l */[18;16H[K[18;13H[?12l[?25h [?25l*/[18;15H[K[18;13H[?12l[?25h[?25l */[?12l[?25h[14;59H[18;14H[17;89H[?25l[17;41H[46m([7C)[m[39C11[18;1H[93m [17;50H[?12l[?25h[?25l[m[39C11[18;1H[93m [17;49H[?12l[?25h[?25l[m[17;41H([7C)[39C11[18;1H[93m [17;48H[?12l[?25h[?25l[m[46m([7C)[m[39C11[18;1H[93m [17;42H[?12l[?25h[?25l[m[47C11[18;1H[93m [17;41H[?12l[?25h[?25l[m([7C)[39C11[18;1H[93m [17;39H[?12l[?25h[?25l[m て，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは122[18;1H[93m    [m8の倍数 */[18;15H[K[17;12H[?12l[?25h[?25l て，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは1288[18;1H[93m    [mの倍数 */[18;14H[K[17;11H[?12l[?25h[?25l て，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128[94m>>[m[18;1H[93m [17;10H[?12l[?25h[?25l[mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の[18;4H[93m [m倍数 */[18;12H[K[17;9H[?12l[?25h[16;87H[?25l[16;67H[46m([mreal[46m)[m[16C[94m>>[m[17;1H[93m [16;73H[?12l[?25h[?25l[m[16C[94m>>[m[17;1H[93m [16;72H[?12l[?25h[?25l[m(real)[16C[94m>>[m[17;1H[93m [16;71H[?12l[?25h[?25l[m[46m([mreal[46m)[m[16C[94m>>[m[17;1H[93m [16;68H[?12l[?25h[?25l[m[21C[94m>>[m[17;1H[93m [16;67H[?12l[?25h[?25l[m(real)[16C[94m>>[m[17;1H[93m [16;66H[?12l[?25h[msize * layer1_size * sizeo[?25lf[46m([mreal[46m)[m[16C[94m>>[m[17;1H[93m [16;67H[?12l[?25h[?25l[m[22C[94m>>[m[17;1H[93m [16;68H[?12l[?25h[?25l[m(real)[16C[94m>>[m[17;1H[93m [16;69H[?12l[?25h[mea[?25l[46m([mreal[46m)[m[16C[94m>>[m[17;1H[93m [16;72H[?12l[?25h[?25l[m[17C[94m>>[m[17;1H[93m [16;73H[?12l[?25h[?25l[m(real)[16C[94m>>[m[17;1H[93m [16;74H[?12l[?25h[mbytes[2C[2C[2C[2C[17;5H[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[?25l[2C[46m([7C)[17;37H[?12l[?25h[?25l([?12l[?25h[?25l[m([7C)[17;39H[?12l[?25hoid *[?25l[17;37H[46m([7C)[?12l[?25h[?25l)[?12l[?25h[?25l[m[17;37H([7C)&[?12l[?25hsyn1[?25l1nに割当る．割当たメモリのアドレスは128[94m>>[m[18;1H[93m    [mの倍数 */[17;52H[?12l[?25h[?25lneに割当る．割当たメモリのアドレスは1288[18;1H[93m [17;53H[?12l[?25h[?25l[megに割当る．割当たメモリのアドレスは122[18;1H[93m    [m8の倍数 */[17;54H[?12l[?25h[?25l[17;37H[46m([7C)[m[43C22[18;1H[93m [17;46H[?12l[?25h[?25l[m[43C22[18;1H[93m [17;45H[?12l[?25h[?25l[m[17;37H([7C)[43C22[18;1H[93m [17;44H[?12l[?25h[20;34H[?25l[m[21;46H[46m([27C)[?12l[?25h[?25l[m[21;46H([27C)[22;43H[?12l[?25h[?25l[21;46H[46m([27C)[?12l[?25h[?25l[m[21;46H([27C)[22;43H[?12l[?25h[?25l[21;46H[46m([27C)[?12l[?25h[?25l[?12l[?25h[?25l)[?12l[?25h[?25l[m[21;46H([27C) [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 0 */[?12l[?25h[?25l  */[?12l[?25h[?25l < */[?12l[?25h[?25l<= */[?12l[?25h[?25l  */[?12l[?25h[?25l A */[?12l[?25h[?25l  */[?12l[?25h[?25l */[21;88H[K[21;85H[?12l[?25h[?25l  */[21;87H[K[21;84H[?12l[?25h[?25l A */[?12l[?25h[?25l  */[?12l[?25h[?25l */[21;88H[K[21;85H[?12l[?25h[?25l  */[21;87H[K[21;84H[?12l[?25h[?25l a */[?12l[?25h[?25l  */[?12l[?25h[?25l < */[21;87H[?12l[?25h[?25l[22;28r[22;1H[L[1;29r[21;87H  **[22;1H[93m    [m/[21;88H[?12l[?25h[?25l v  [22;1H[93m    [m*/[21;89H[?12l[?25h[?25lvoo[22;1H[93m    [m */[?12l[?25h[?25l[93m [mc */[?12l[?25h[?25lca */[?12l[?25h[?25la_ */[?12l[?25h[?25la */[22;10H[K[22;7H[?12l[?25h[?25lab */[?12l[?25h[?25lb_ */[?12l[?25h[?25l_s */[?12l[?25h[?25lsi */[?12l[?25h[?25liz */[?12l[?25h[?25lze */[?12l[?25h[?25leの */[?12l[?25h[?25l時 */[?12l[?25he[?25le&の時 */[22;14H[?12l[?25h[?25le &の時 */[22;14H[?12l[?25h&[?25l& の時 */[22;16H[?12l[?25h[?25l 0の時 */[22;17H[?12l[?25h[?25l0>の時 */[22;18H[?12l[?25h[?25l0の時 */[22;24H[K[22;17H[?12l[?25h[?25l0<の時 */[22;18H[?12l[?25h[?25l<=の時 */[22;19H[?12l[?25h[?25l= の時 */[22;20H[?12l[?25h[?25l bの時 */[22;21H[?12l[?25h[?25l0 <= bの時 */[22;18H[?12l[?25h<= b[?25lb の時 */[22;23H[?12l[?25h[?25l <の時 */[22;24H[?12l[?25h[?25l< の時 */[22;25H[?12l[?25h[?25l lの時 */[22;26H[?12l[?25h[?25llaの時 */[22;27H[?12l[?25h[?25layの時 */[22;28H[?12l[?25h[?25lyeの時 */[22;29H[?12l[?25h[?25lerの時 */[22;30H[?12l[?25h[?25lr1の時 */[22;31H[?12l[?25h[?25l1_の時 */[22;32H[?12l[?25h[?25l_sの時 */[22;33H[?12l[?25h[?25lsiの時 */[22;34H[?12l[?25h[?25lizの時 */[22;35H[?12l[?25h[?25lzeの時 */[22;36H[?12l[?25h[2C[2C */[23;43H[?25l [?12l[?25h[?25l[?12l[?25h[?25l[14;23H[46m{[24;7H}[?12l[?25h[?25l[m[14;23H{[24;7H}[25;43H[?12l[?25h[26;43H[27;43H[?25l[1;28r[1;1H[2M[1;29r[23;74H[46m{[m[27;1H[93m359 [m  [46m}[m
[93m360 [m  CreateBinaryTree();[27;8H[?12l[?25h[?25l[23;74H{[27;7H}[28;26H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m361 [m}[?12l[?25h[27;26H[?25l[22;74H[46m{[26;7H}[?12l[?25h[?25l[m[22;74H{[26;7H}[24;43H[?12l[?25h[23;43Hned long lon[?25l[23;37H[46m([18C)[?12l[?25h[?25l)[?12l[?25h[?25l[m[23;37H([18C)2[?12l[?25h521[?25l[24;39H[46m([20C)[m[28Cee[25;1H[93m [24;61H[?12l[?25h[?25l[m[22;74H[46m{[m[24;39H([20C)[28Cee[25;1H[93m [m[26;7H[46m}[?12l[?25h[?25l[m[22;74H{[26;7H}[27;26H[?12l[?25h[?25l[28;6H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m362 [?12l[?25h[?25l[27;6H[?12l[?25h[26;26H[?25l[27;6H[?12l[?25h
362 [?25l[1;28r[m[1;1H[4M[1;29r[25;1H[93m363 [mvoid *TrainModelThread(void *id) {
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[27;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;[25;39H[?12l[?25h[26;61H[27;61H[26;61H[?25l[25;39H[?12l[?25h[24;5H[?25l[23;6H[?12l[?25h[22;26H[?25l[17;74H[46m{[21;7H}[?12l[?25h[?25l[m[17;74H{[19;39H[46m([20C)[m[28Cee[20;1H[93m [m[21;7H}[19;61H[?12l[?25h[?25l[19;39H([20C)[28Cee[20;1H[93m [18;61H[?12l[?25h[17;61H[?25l[m[6;23H[46m{[16;7H}[?12l[?25h[?25l[m[6;23H{[16;7H}[15;43H[?12l[?25h[13;61H[11;61H[7;61H[6;59H[?25l[5;8H[?12l[?25h[4;40H[3;61H[1;61H[?25l[1;28r[1;1H[4L[1;29r[1;1H[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[2;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当 [3;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数[4;1H[93m    [m */[1;61H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m344 [m  if (hs) { /* hs=0よりこのif文はFALSE */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m343 [m  if (syn0 == NULL) {printf[46m([m"Memory allocation failed\n"[46m)[m; exit(1);}[1;61H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[2;1H[93m    [mf(real)); /*  */[3;32H([28C)[1;61H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m341 [m  unsigned long long next_random = 1;[28;1H[94m@                                                                                        [1;42H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m340 [m  long long a, b;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m339 [mvoid InitNet() { /* void関数IniNet() */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m338 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m337 [m}[?12l[?25h[2;5H[3;44H[4;22H[5;42H[6;61H[?25l[28Coo[7;1H[93m [m[8;32H[46m([28C)[?12l[?25h[?25l[m[8;32H([28C)[9;46H[?12l[?25h[10;61H[14;61H[16;61H[17;40H[?25l[9;15H[46m{[18;7H}[?12l[?25h[?25l[m[9;15H{[18;7H}[19;59H[?12l[?25h[20;61H[24;61H[29;1H[K[24;60H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hCreateBinaryTree[?25l[1;28r[1;1H[7M[1;29r[22;1H[93m355 [m  }
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {
[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m358 [m    syn0[a * layer1_size + b] = (((next_random & 0xFFFF) / (real)65536) - 0.5) / layee[26;1H[93m    [mr1_size;
[93m359 [m  }
[93m360 [m  CreateBinaryTree();[29;1H[K[28;7H[?12l[?25h[?25l
?CreateBinaryTree[27m[m[H[2J[1;1H[93m187 [m    // Hash will be re-computed, as it is not actual
[93m188 [m    hash = GetWordHash(vocab[a].word);
[93m189 [m    while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m190 [m    vocab_hash[hash] = a;
[93m191 [m  }
[93m192 [m  fflush(stdout);
[93m193 [m  min_reduce++;
[93m194 [m}
[93m195 
196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffman木を作成[11;1H[93m    [m */
[93m197 [m// Frequent words will have short uniqe binary codes /* 高頻度の単語に短い一意的な2進[13;1H[93m    [m数を割当る */
[93m198 [mvoid CreateBinaryTree() { /* void関数CreateBinaryTree() */
[93m199 [m  long long a, b, i, min1i, min2i, pos1, pos2, point[MAX_CODE_LENGTH];
[93m200 [m  char code[MAX_CODE_LENGTH]; /* char型code[最大コード長MAX_CODE_LENGTH] */
[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long long)); /* ll[18;1H[93m    [mong long型ポインタcountに(vocab_size * 2 * 1) * (long long)分のメモリを確保 */
[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long long)); /*  [20;1H[93m    [mlong long型ポインタbinaryに(vocab_size * 2 * 1) * (long long)分のメモリを確保 */
[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(long long)))[22;1H[93m    [m; /* long long型ポインタparent_nodeに(vocab_size * 2 * 1) * (long long)分のメモリを確[23;1H[93m    [m保 */
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn; /* ポインタcountの0 <= a <<[25;1H[93m    [m vocab_size番目ににvocab[a].cnを代入 */
[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15; /* ポインタcountのvoo[27;1H[93m    [mcab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */
[93m206 [m  pos1 = vocab_size - 1;[14;42H[?12l[?25h[?25l[29;1H/CreateBinaryTree[27m[m[H[2J[1;1H[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [2;1H[93m    [msizeof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを[94m>>[m[3;1H[93m    [m割当て，割当たメモリのアドレスを(void **)&syn1negに割当る．割当たメモリのアドレスは122[4;1H[93m    [m8の倍数 */
[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);} /* 上でメモ[6;1H[93m    [mリの割当に失敗した時に表示 */
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) /* 0 <= a < voo[8;1H[93m    [mcab_size & 0 <= b < layer1_sizeの時 */
[93m354 [m     syn1neg[a * layer1_size + b] = 0;
[93m355 [m  }
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {
[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m358 [m    syn0[a * layer1_size + b] = (((next_random & 0xFFFF) / (real)65536) - 0.5) / layee[14;1H[93m    [mr1_size;
[93m359 [m  }
[93m360 [m  CreateBinaryTree();
[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) {
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[21;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");[16;7H[?12l[?25hCreateBinaryTre[?25le[46m()[?12l[?25h[?25l([?12l[?25h[?25l[m()[?12l[?25h[?25l[29;1H[1m-- INSERT --[16;26H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 1 */[?12l[?25h[?25l19 */[?12l[?25h[?25l98 */[?12l[?25h[?25l8行目 */[?12l[?25h[?25lで */[?12l[?25h[?25l定義した */[?12l[?25h[?25lC */[?12l[?25h[?25lCr */[?12l[?25h[?25lre */[?12l[?25h[?25lea */[?12l[?25h[?25lat */[?12l[?25h[?25lte */[?12l[?25h[?25leE */[?12l[?25h[?25le */[16;56H[K[16;53H[?12l[?25h[?25leB */[?12l[?25h[?25lBi */[?12l[?25h[?25lin */[?12l[?25h[?25lna */[?12l[?25h[?25lar */[?12l[?25h[?25lry */[?12l[?25h[?25lyT */[?12l[?25h[?25lTr */[?12l[?25h[?25lre */[?12l[?25h[?25lee */[?12l[?25h[?25le( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l[?12l[?25h[?25l[1C[?12l[?25h[?25l()で */[?12l[?25h[?25lH */[?12l[?25h[?25lHu */[?12l[?25h[?25luf */[?12l[?25h[?25lff */[?12l[?25h[?25lfm */[?12l[?25h[?25lma */[?12l[?25h[?25lan */[?12l[?25h[?25lnぎ */[?12l[?25h[?25ln */[16;77H[K[16;74H[?12l[?25h[?25ln木 */[?12l[?25h[?25lを */[?12l[?25h[?25l生成 */[?12l[?25h[?25l[11;74H[46m{[15;7H}[?12l[?25h[?25l[m[11;74H{[13;37H[46m([44C)[m / layee[14;1H[93m [m[15;7H}[13;82H[?12l[?25h[?25l[13;37H([44C) / layee[14;1H[93m [12;74H[?12l[?25h[?25l[m[11;74H[46m{[15;7H}[11;75H[?12l[?25h[?25l[m{[15;7H}[10;8H[?12l[?25h[9;43H[7;82H[5;82H[1;82H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m350 [m  if (negative>0) { /* negative=5よりこのif文はTRUE */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m349 [m  }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m348 [m     syn1[a * layer1_size + b] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m347 [m    for (a = 0; a < vocab_size; a++) for [46m([mb = 0; b < layer1_size; b++[46m)[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m346 [m    if (syn1 == NULL) {printf("Memory allocation failed\n"); exit(1);} /* 上でメモリ[94m>>[m[2;1H[93m    [mの割当に失敗した時に表示 */[3;46H([27C)[1;81H[?12l[?25h[?25l[1;28r[1;1H[4L[1;29r[1;1H[93m345 [m    a = posix_memalign((void **)&syn1, 128, (long long)vocab_size * layer1_size * sizz[2;1H[93m    [meof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを割当[3;1H[93m    [mて，割当たメモリのアドレスを(void **)&syn1に割当る．割当たメモリのアドレスは128の倍数 [4;1H[93m    [m */[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m344 [m  if (hs) { /* hs=0よりこのif文はFALSE */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m343 [m  if (syn0 == NULL) [46m{[mprintf("Memory allocation failed\n"); exit(1);[46m}[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m342 [m  a = posix_memalign((void **)&syn0, 128, (long long)vocab_size * layer1_size * sizeoo[2;1H[93m    [mf(real)); /*  */[3;25H{[46C}[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m341 [m  unsigned long long next_random = 1;[28;1H[94m@                                                                                        [1;42H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m340 [m  long long a, b;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m339 [mvoid InitNet() { /* void関数IniNet() */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m338 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m337 [m}[?12l[?25h[2;5H[3;44H[4;22H[5;42H[6;82H[?25l[7Coo[7;1H[93m [m[8;25H[46m{[46C}[?12l[?25h[?25l[m[8;25H{[46C}[9;46H[?12l[?25h[10;82H[14;81H[?25l[8C[94m>>[m[15;1H[93m [m[16;46H[46m([27C)[?12l[?25h[?25l[m[16;46H([27C)[17;40H[?12l[?25h[?25l[9;15H[46m{[18;7H}[?12l[?25h[?25l[m[9;15H{[18;7H}[19;59H[?12l[?25h[20;82H[24;82H[26;82H[28;43H[?25l[1;28r[28;1H
[1;29r[18;23H[46m{[m[28;1H[93m355 [m  [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[17;23H{[27;7H}
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m358 [m    syn0[a * layer1_size + b] = [46m([m((next_random & 0xFFFF) / (real)65536) - 0.5[46m)[m / layee[28;1H[93m    [mr1_size;[27;82H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[23;74H[46m{[m[25;37H([44C) / layee[26;1H[93m 
359 [m  [46m}[m
[93m360 [m  CreateBinaryTree(); /* 198行目で定義したCreateBinaryTree()でHuffman木を生成 */[27;8H[?12l[?25h[?25l[23;74H{[27;7H}[28;82H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m361 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m362 [?12l[?25h[?25l[1;28r[m[1;1H[4M[1;29r[25;1H[93m363 [mvoid *TrainModelThread(void *id) {
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[27;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;[25;39H[?12l[?25h[26;82H[?25l[27;57H[46m[[23C][?12l[?25h[?25l[m[27;57H[[23C][28;61H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;[27;54H[?12l[?25h[28;17H[?25l[1;28r[28;1H
[1;29r[28;1H[93m369 [m  clock_t now;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m372 [m  FILE *fi = fopen(train_file, "rb");[?12l[?25h[?25l[1;28r[1;1H[4M[1;29r[25;1H[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) {
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;[25;79H[?12l[?25h[?25l[26;18H[?12l[?25h[?25l[27;52H[?12l[?25h[28;61H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {[27;40H[?12l[?25h[?25l[28;34H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[27;25H[?12l[?25h[28;82H[?25l[1;28r[28;1H
[1;29r[28;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,[?12l[?25h[27;82H[26;25H[?25l[25;34H[?12l[?25h[24;40H[23;61H[?25l[22;52H[?12l[?25h[?25l[21;18H[?12l[?25h[20;79H[19;42H[18;63H[17;62H[16;19H[15;17H[14;54H[13;61H[?25l[12;57H[46m[[23C][?12l[?25h[?25l[m[12;57H[[23C][11;82H[?12l[?25h[?25l[10;39H[?12l[?25h[11;82H[?25l[12;57H[46m[[23C][?12l[?25h[?25l[m[12;57H[[23C][13;61H[?12l[?25h[14;54H[15;17H[16;19H[17;62H[18;63H[19;42H[20;79H[?25l[21;18H[?12l[?25h[?25l[22;52H[?12l[?25h[23;61H[24;40H[?25l[25;34H[?12l[?25h[26;25H[27;82H[28;71H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[28;1H[93m    [m;[27;82H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m383 [m[7C fflush(stdout);[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[20;33H[46m{[m[27;1H[93m384 [m      [46m}[m
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 1[28;1H[94m@                                                                                        [27;12H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[19;33H{[26;11H}
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[28;1H[93m    [m));[27;82H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[14;51H[46m{[m[28;1H[93m387 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[13;51H{[27;9H}
[93m388 [m    if (sentence_length == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m389 [m      while (1) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m390 [m[7C word = ReadWordIndex(fi);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m391 [m[7C if (feof(fi)) break;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m392 [m[7C if (word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m393 [m[7C word_count++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m394 [m[7C if (word == 0) break;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[28;1H[93m    [m same[27;82H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m396 [m[7C if (sample > 0) {[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [28;1H[93m    [mtrain_words) / vocab[word].cn;[27;82H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[23;29H[46m{[m[28;1H[93m400 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[22;29H{[27;13H}
[93m401 [m[7C sen[sentence_length] = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m402 [m[7C sentence_length++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[11;21H[46m{[m[28;1H[93m404 [m      [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[10;21H{[27;11H}
[93m405 [m      sentence_position = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[7;35H[46m{[m[27;1H[93m406 [m    [46m}[m
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {[27;10H[?12l[?25h[?25l[7;35H{[27;9H}[28;68H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m408 [m      word_count_actual += word_count - last_word_count;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m409 [m      local_iter--;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;[27;38H[?12l[?25h[28;26H[?25l[1;28r[28;1H
[1;29r[28;1H[93m412 [m      last_word_count = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m413 [m      sentence_length = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m414 [m      fseek[46m([mfi, file_size / (long long)num_threads * (long long)id, SEEK_SET[46m)[m;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;16H([64C)
[93m415 [m      continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[19;67H[46m{[m[28;1H[93m416 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;67H{[27;9H}
[93m417 [m    word = sen[sentence_position];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m418 [m    if (word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m422 [m    b = next_random % window;[27;74H[?12l[?25h[28;34H[?25l[1;28r[28;1H
[1;29r[28;1H[93m423 [m    if (cbow) {  //train the cbow architecture[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m424 [m      // in -> hidden
[93m425 [m      cw = 0;[27;26H[?12l[?25h[28;18H[?25l[1;28r[28;1H
[1;29r[28;1H[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m427 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m428 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m429 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m430 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m431 [m[7C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_sizee[28;1H[93m    [m];[27;82H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m433 [m[7C cw++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[19;69H[46m{[m[28;1H[93m434 [m      [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;69H{[27;11H}
[93m435 [m      if (cw) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m438 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m440 [m[9C // Propagate hidden -> output[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1[c + l2];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m442 [m[9C if (f <= -MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m443 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m447 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m449 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[14;63H[46m{[m[28;1H[93m451 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[13;63H{[27;13H}
[93m452 [m[7C // NEGATIVE SAMPLING[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m453 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m454 [m[9C if (d == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m455 [m[11C target = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m456 [m[11C label = 1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m457 [m[9C } else {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m458 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m459 [m[11C target = table[(next_random >> 16) % table_size];
[93m460 [m[11C if (target == 0) target = next_random % (vocab_size - 1) + 1;[27;66H[?12l[?25h[28;78H[?25l[1;28r[28;1H
[1;29r[28;1H[93m461 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m462 [m[11C label = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;22H[46m{[m[28;1H[93m463 [m[9C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;22H{[27;15H}
[93m464 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m465 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m466 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1neg[c + l2];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m467 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m468 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m469 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [28;1H[93m    [m/ 2))]) * alpha;[27;82H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m470 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m471 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * neu1[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[8;66H[46m{[m[28;1H[93m472 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[7;66H{[27;13H}
[93m473 [m[7C // hidden -> in[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m474 [m[7C for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m475 [m[9C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m476 [m[9C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m477 [m[9C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m478 [m[9C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m479 [m[9C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m480 [m[9C for (c = 0; c < layer1_size; c++) syn0[46m[[mc + last_word * layer1_size[46m][m += neu11[28;1H[93m    [me[c];[27;82H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[20;71H[46m{[m[26;53H[[27C][7C11[27;1H[93m 
481 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[19;71H{[27;13H}
[93m482 [m      }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m483 [m    } else {  //train skip-gram[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m484 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m485 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m486 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m487 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m488 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m489 [m[7C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m490 [m[7C l1 = last_word * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m491 [m[7C for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m492 [m[7C // HIERARCHICAL SOFTMAX[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m493 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m494 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m495 [m[9C l2 = vocab[word].point[d] * layer1_size;
[93m496 [m[9C // Propagate hidden -> output[27;55H[?12l[?25h[28;44H[?25l[1;28r[28;1H
[1;29r[28;1H[93m497 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1[c + l2];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m498 [m[9C if (f <= -MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m499 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m500 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m501 [m[9C // 'g' is the gradient multiplied by the learning rate[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m502 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m503 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m504 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m505 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m506 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * syn0[c + l1];[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[13;63H[46m{[m[27;1H[93m507 [m[7C [46m}[m
[93m508 [m[7C // NEGATIVE SAMPLING[27;14H[?12l[?25h[?25l[13;63H{[27;13H}[28;33H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m509 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m510 [m[9C if (d == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m511 [m[11C target = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m512 [m[11C label = 1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m513 [m[9C } else {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m514 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m515 [m[11C target = table[(next_random >> 16) % table_size];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m516 [m[11C if (target == 0) target = next_random % (vocab_size - 1) + 1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m517 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m518 [m[11C label = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;22H[46m{[m[28;1H[93m519 [m[9C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;22H{[27;15H}
[93m520 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m521 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m522 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m523 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m524 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [28;1H[93m    [m/ 2))]) * alpha;[27;82H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[8;66H[46m{[m[28;1H[93m528 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[7;66H{[27;13H}
[93m529 [m[7C // Learn weights input -> hidden[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m531 [m      }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m532 [m    }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m533 [m    sentence_position++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m534 [m    if (sentence_position >= sentence_length) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m535 [m      sentence_length = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m536 [m      continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;51H[46m{[m


[93m537 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[24;51H{[27;9H}
[93m538 [m  }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m539 [m  fclose(fi);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m540 [m  free(neu1);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m541 [m  free(neu1e);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m542 [m  pthread_exit(NULL);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m543 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m544 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m545 [mvoid TrainModel() {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m546 [m  long a, b, c, d;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m547 [m  FILE *fo;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m549 [m  printf("Starting training using file %s\n", train_file);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m550 [m  starting_alpha = alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();[?12l[?25h[27;30H[26;63H[25;76H[24;16H[23;23H[?25l[22;24H[?12l[?25h[21;5H[?25l[20;6H[?12l[?25h[19;26H[18;19H[17;18H[16;18H[?25l[15;8H[?12l[?25h[?25l[11;51H[46m{[14;9H}[?12l[?25h[?25l[m[11;51H{[14;9H}[13;20H[?12l[?25h[12;31H[?25l[11;51H[46m{[14;9H}[11;52H[?12l[?25h[?25l[m{[14;9H}[10;29H[?12l[?25h[?25l[9;10H[?12l[?25h[?25l[8;12H[?12l[?25h[7;72H[6;45H[?25l[5;14H[?12l[?25h[4;82H[3;81H[1;82H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m524 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m523 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m522 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m521 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m520 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m519 [m[9C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m518 [m[11C label = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m517 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m516 [m[11C if (target == 0) target = next_random % (vocab_size - 1) + 1;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m515 [m[11C target = table[(next_random >> 16) % table_size];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m514 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m513 [m[9C } else [46m{[7;15H}[1;23H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m512 [m[11C label = 1;[2;22H{[8;15H}[1;27H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m511 [m[11C target = word;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m510 [m[9C if (d == 0) [46m{[4;15H}[1;28H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m509 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) [46m{[m[2;27H{[5;15H}[21;13H[46m}[1;67H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m508 [m[7C // NEGATIVE SAMPLING[2;66H{[22;13H}[1;33H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m507 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m506 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * syn0[c + l1];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m505 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m504 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m503 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m502 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m501 [m[9C // 'g' is the gradient multiplied by the learning rate[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m500 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m499 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m498 [m[9C if (f <= -MAX_EXP) continue;[28;1H[94m@                                                                                        [1;43H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m497 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1[c + l2];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m496 [m[9C // Propagate hidden -> output[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m495 [m[9C l2 = vocab[word].point[d] * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m494 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m493 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) [46m{[15;13H}[1;64H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m492 [m[7C // HIERARCHICAL SOFTMAX[2;63H{[16;13H}[1;36H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m491 [m[7C for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m490 [m[7C l1 = last_word * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m489 [m[7C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m488 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m487 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m486 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m485 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m484 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m483 [m    } else {  //train skip-gram[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m482 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m481 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m480 [m[9C for (c = 0; c < layer1_size; c++) syn0[46m[[mc + last_word * layer1_size[46m][m += neu11[2;1H[93m    [me[c];[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m479 [m[9C if (last_word == -1) continue;[2;53H[[27C][7C11[3;1H[93m [1;45H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m478 [m[9C last_word = sen[c];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m477 [m[9C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m476 [m[9C if (c < 0) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m475 [m[9C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m474 [m[7C for (a = b; a < window * 2 + 1 - b; a++) if (a != window) [46m{[9;13H}[1;72H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m473 [m[7C // hidden -> in[2;71H{[10;13H}[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m472 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m471 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * neu1[c];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m470 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m469 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [2;1H[93m    [m/ 2))]) * alpha;[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m468 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m467 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m466 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1neg[c + l2];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m465 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m464 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m463 [m[9C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m462 [m[11C label = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m461 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m460 [m[11C if (target == 0) target = next_random % (vocab_size - 1) + 1;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m459 [m[11C target = table[(next_random >> 16) % table_size];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m458 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m457 [m[9C } else [46m{[7;15H}[1;23H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m456 [m[11C label = 1;[2;22H{[8;15H}[1;27H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m455 [m[11C target = word;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m454 [m[9C if (d == 0) [46m{[4;15H}[m[28;1H[94m@                                                                                        [1;28H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m453 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) [46m{[m[2;27H{[5;15H}[21;13H[46m}[1;67H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m452 [m[7C // NEGATIVE SAMPLING[2;66H{[22;13H}[1;33H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m451 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m449 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m447 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m443 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m442 [m[9C if (f <= -MAX_EXP) continue;[28;1H[94m@                                                                                        [1;43H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1[c + l2];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m440 [m[9C // Propagate hidden -> output[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m438 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) [46m{[15;13H}[1;64H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;[2;63H{[16;13H}[1;61H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m435 [m      if (cw) {[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m434 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m433 [m[7C cw++;[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_sizee[2;1H[93m    [m];[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m431 [m[7C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m430 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m429 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m428 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m427 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) [46m{[10;11H}[1;70H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m425 [m      cw = 0;[2;69H{[11;11H}[1;18H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m424 [m      // in -> hidden[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m423 [m    if (cbow) {  //train the cbow architecture[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m422 [m    b = next_random % window;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m418 [m    if (word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m417 [m    word = sen[sentence_position];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m416 [m    }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m415 [m      continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m414 [m      fseek[46m([mfi, file_size / (long long)num_threads * (long long)id, SEEK_SET[46m)[m;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m413 [m      sentence_length = 0;[2;16H([64C)[1;31H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m412 [m      last_word_count = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m411 [m      word_count = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m410 [m      if (local_iter == 0) break;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m409 [m      local_iter--;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m408 [m      word_count_actual += word_count - last_word_count;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) [46m{[10;9H}[1;68H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m406 [m    }[2;67H{[11;9H}[1;10H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m405 [m      sentence_position = 0;[28;1H[94m@                                                                                        [1;33H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m404 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m402 [m[7C sentence_length++;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m401 [m[7C sen[sentence_length] = word;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m400 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [2;1H[93m    [mtrain_words) / vocab[word].cn;[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m396 [m[7C if (sample > 0) [46m{[6;13H}[1;30H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[2;1H[93m    [m same[3;29H{[8;13H}[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m394 [m[7C if (word == 0) break;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m393 [m[7C word_count++;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m392 [m[7C if (word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m391 [m[7C if (feof(fi)) break;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m390 [m[7C word = ReadWordIndex(fi);[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m389 [m      while (1) [46m{[18;11H}[1;22H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m388 [m    if (sentence_length == 0) [46m{[m[2;21H{[19;11H}[21;9H[46m}[1;36H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m387 [m    }[2;35H{[22;9H}[1;10H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[2;1H[93m    [m));[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m384 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m383 [m[7C fflush(stdout);[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[2;1H[93m    [m;[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m379 [m[7C now=clock();[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m378 [m      if ((debug_mode > 1)) [46m{[8;11H}[1;34H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m377 [m      last_word_count = word_count;[2;33H{[9;11H}[1;40H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m376 [m      word_count_actual += word_count - last_word_count;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m375 [m    if (word_count - last_word_count > 10000) [46m{[15;9H}[1;52H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m374 [m  while (1) {[2;51H{[16;9H}[1;18H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;1H[94m@                                                                                        [1;79H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m372 [m  FILE *fi = fopen(train_file, "rb");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));[28;1H[94m@                                                                                        [1;62H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m369 [m  clock_t now;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m368 [m  real f, g;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m367 [m  unsigned long long next_random = (long long)id;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[46m[[mMAX_SENTENCE_LENGTH + 1[46m][m;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[2;57H[[23C][1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m363 [mvoid *TrainModelThread(void *id) {[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m362 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m361 [m}[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m360 [m  CreateBinaryTree(); /* 198行目で定義したCreateBinaryTree()でHuffman木を生成 */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m359 [m  }[28;1H[94m@                                                                                        [1;8H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m358 [m    syn0[a * layer1_size + b] = [46m([m((next_random & 0xFFFF) / (real)65536) - 0.5[46m)[m / layee[2;1H[93m    [mr1_size;[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[2;37H([44C) / layee[3;1H[93m [1;74H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) [46m{[5;7H}[m[28;1H[94m@                                                                                        [1;75H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m355 [m  }[2;74H{[6;7H}[1;8H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m354 [m     syn1neg[a * layer1_size + b] = 0;[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) /* 0 <= a < voo[2;1H[93m    [mcab_size & 0 <= b < layer1_sizeの時 */[1;82H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);} /* 上でメモ[2;1H[93m    [mリの割当に失敗した時に表示 */[1;82H[?12l[?25h[?25l[1;28r[1;1H[4L[1;29r[1;1H[93m351 [m    a = posix_memalign((void **)&syn1neg, 128, (long long)vocab_size * layer1_size *  [2;1H[93m    [msizeof(real)); /* (long long)vocab_size * layer1_size * sizeof(real) bytesのメモリを[94m>>[m[3;1H[93m    [m割当て，割当たメモリのアドレスを(void **)&syn1negに割当る．割当たメモリのアドレスは122[4;1H[93m    [m8の倍数 */[1;82H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m350 [m  if (negative>0) { /* negative=5よりこのif文はTRUE */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m349 [m  }[?12l[?25h[2;59H[3;82H[7;82H[9;82H[11;43H[?25l[2;23H[46m{[12;7H}[?12l[?25h[?25l[m[2;23H{[12;7H}[13;74H[46m{[17;7H}[13;75H[?12l[?25h[?25l[m{[17;7H}[14;74H[?12l[?25h[?25l[15;37H[46m([44C)[m / layee[16;1H[93m [15;82H[?12l[?25h[?25l[m[13;74H[46m{[m[15;37H([44C) / layee[16;1H[93m [m[17;7H[46m}[?12l[?25h[?25l[m[13;74H{[17;7H}[18;82H[?12l[?25h[?25l[19;6H[?12l[?25h[20;5H[?25l[21;39H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 5 */[?12l[?25h[?25l54 */[?12l[?25h[?25l43 */[?12l[?25h[?25l3行目 */[?12l[?25h[?25lまで */[?12l[?25h[?25lある */[?12l[?25h[22;58H[?25l[23;57H[46m[[23C][23;58H[?12l[?25h[?25l[m[[23C][24;58H[?12l[?25h[25;54H[26;17H[27;19H[28;58H[?25l[1;28r[28;1H
[1;29r[28;1H[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m372 [m  FILE *fi = fopen(train_file, "rb");[?12l[?25h[?25l[1;28r[1;1H[4M[1;29r[25;1H[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) {
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;[25;58H[?12l[?25h[?25l[26;18H[?12l[?25h[?25l[27;52H[?12l[?25h[28;58H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {[27;40H[?12l[?25h[?25l[28;34H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[27;25H[?12l[?25h[28;58H[?25l[1;28r[28;1H
[1;29r[28;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,[28;58H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m382 [m[8C word_count_actual / ((real)[46m([mnow - start + 1[46m)[m / (real)CLOCKS_PER_SEC * 1000)))[28;1H[93m    [m;[27;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[26;41H([15C)[31C))[27;1H[93m 
383 [m[7C fflush(stdout);[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[20;33H[46m{[m[27;1H[93m384 [m      [46m}[m
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 1[28;1H[94m@                                                                                        [27;12H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[19;33H{[26;11H}
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[28;1H[93m    [m));[27;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[14;51H[46m{[m[28;1H[93m387 [m    [46m}[?12l[?25h[?25l[m[14;51H{[28;9H}[27;58H[?12l[?25h[25;58H[?25l[17;33H[46m{[24;11H}[?12l[?25h[?25l[m[17;33H{[24;11H}[23;28H[?12l[?25h[?25l[21;41H[46m([15C)[m[31C))[22;1H[93m [21;58H[?12l[?25h[?25l[m[21;41H([15C)[31C))[22;1H[93m [20;58H[?12l[?25h[19;58H[18;25H[?25l[m[17;33H[46m{[24;11H}[17;34H[?12l[?25h[?25l[m{[24;11H}[16;40H[?12l[?25h[?25l[17;33H[46m{[24;11H}[17;34H[?12l[?25h[?25l[m{[24;11H}[18;25H[?12l[?25h[19;58H[20;58H[?25l[21;41H[46m([15C)[m[31C))[22;1H[93m [21;58H[?12l[?25h[?25l[m[21;41H([15C)[31C))[22;1H[93m [23;28H[?12l[?25h[?25l[m[17;33H[46m{[24;11H}[?12l[?25h[?25l[m[17;33H{[24;11H}[25;58H[?12l[?25h[27;58H[?25l[14;51H[46m{[28;9H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[13;51H{[27;9H}
[93m388 [m    if (sentence_length == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m389 [m      while (1) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m390 [m[7C word = ReadWordIndex(fi);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m391 [m[7C if (feof(fi)) break;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m392 [m[7C if (word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m393 [m[7C word_count++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m394 [m[7C if (word == 0) break;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[28;1H[93m    [m same[27;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m396 [m[7C if (sample > 0) {[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [28;1H[93m    [mtrain_words) / vocab[word].cn;[27;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[23;29H[46m{[m[28;1H[93m400 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[22;29H{[27;13H}
[93m401 [m[7C sen[sentence_length] = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m402 [m[7C sentence_length++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[11;21H[46m{[m[28;1H[93m404 [m      [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[10;21H{[27;11H}
[93m405 [m      sentence_position = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[7;35H[46m{[m[27;1H[93m406 [m    [46m}[m
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {[27;10H[?12l[?25h[?25l[7;35H{[27;9H}[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m408 [m      word_count_actual += word_count - last_word_count;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m409 [m      local_iter--;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;[27;38H[?12l[?25h[28;26H[?25l[1;28r[28;1H
[1;29r[28;1H[93m412 [m      last_word_count = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m413 [m      sentence_length = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m414 [m      fseek(fi, file_size / (long long)num_threads * [46m([mlong long[46m)[mid, SEEK_SET);[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;58H([9C)
[93m415 [m      continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[19;67H[46m{[m[28;1H[93m416 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;67H{[27;9H}
[93m417 [m    word = sen[sentence_position];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m418 [m    if (word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m422 [m    b = next_random % window;[27;58H[?12l[?25h[28;34H[?25l[1;28r[28;1H
[1;29r[28;1H[93m423 [m    if (cbow) {  //train the cbow architecture[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m424 [m      // in -> hidden
[93m425 [m      cw = 0;[27;26H[?12l[?25h[28;18H[?25l[1;28r[28;1H
[1;29r[28;1H[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m427 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m428 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m429 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m430 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m431 [m[7C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_sizee[28;1H[93m    [m];[27;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m433 [m[7C cw++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[19;69H[46m{[m[28;1H[93m434 [m      [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;69H{[27;11H}
[93m435 [m      if (cw) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m438 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m440 [m[9C // Propagate hidden -> output[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[46m[[mc[46m][m * syn1[c + l2];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;58H[c]
[93m442 [m[9C if (f <= -MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m443 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m447 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m449 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[14;63H[46m{[m[28;1H[93m451 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[13;63H{[27;13H}
[93m452 [m[7C // NEGATIVE SAMPLING[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m453 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m454 [m[9C if (d == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m455 [m[11C target = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m456 [m[11C label = 1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m457 [m[9C } else {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m458 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[28;58H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m459 [m[11C target = table[(next_random >> 16) % table_size];
[93m460 [m[11C if (target == 0) target = next_random % (vocab_size - 1) + 1;[27;58H[?12l[?25h[?25l[28;57H[46m([14C)[28;58H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;57H([14C)
[93m461 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m462 [m[11C label = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;22H[46m{[m[28;1H[93m463 [m[9C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;22H{[27;15H}
[93m464 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m465 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m466 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[46m[[mc[46m][m * syn1neg[c + l2];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;58H[c]
[93m467 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m468 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m469 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [28;1H[93m    [m/ 2))]) * alpha;[27;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m470 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m471 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * neu1[c];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[8;66H[46m{[m[28;1H[93m472 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[7;66H{[27;13H}
[93m473 [m[7C // hidden -> in[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m474 [m[7C for (a = b; a < window * 2 + 1 - b; a++) if [46m([ma != window[46m)[m {[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;57H([11C)
[93m475 [m[9C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m476 [m[9C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m477 [m[9C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m478 [m[9C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m479 [m[9C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m480 [m[9C for (c = 0; c < layer1_size; c++) syn0[c + last_word * layer1_size] += neu11[28;1H[93m    [me[c];[27;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[20;71H[46m{[m[28;1H[93m481 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[19;71H{[27;13H}
[93m482 [m      }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m483 [m    } else {  //train skip-gram[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m484 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m485 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m486 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m487 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m488 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m489 [m[7C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m490 [m[7C l1 = last_word * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m491 [m[7C for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m492 [m[7C // HIERARCHICAL SOFTMAX[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m493 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m494 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m495 [m[9C l2 = vocab[word].point[d] * layer1_size;
[93m496 [m[9C // Propagate hidden -> output[27;55H[?12l[?25h[28;44H[?25l[1;28r[28;1H
[1;29r[28;1H[93m497 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[46m[[mc + l1[46m][m * syn1[c + l2];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;58H[c + l1]
[93m498 [m[9C if (f <= -MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m499 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m500 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m501 [m[9C // 'g' is the gradient multiplied by the learning rate[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m502 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m503 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m504 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m505 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m506 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * syn0[c + l1];[28;58H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[13;63H[46m{[m[27;1H[93m507 [m[7C [46m}[m
[93m508 [m[7C // NEGATIVE SAMPLING[27;14H[?12l[?25h[?25l[13;63H{[27;13H}[28;33H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m509 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m510 [m[9C if (d == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m511 [m[11C target = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m512 [m[11C label = 1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m513 [m[9C } else {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m514 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m515 [m[11C target = table[(next_random >> 16) % table_size];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m516 [m[11C if (target == 0) target = next_random % [46m([mvocab_size - 1[46m)[m + 1;[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;57H([14C)
[93m517 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m518 [m[11C label = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;22H[46m{[m[28;1H[93m519 [m[9C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;22H{[27;15H}
[93m520 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m521 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m522 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[46m[[mc + l1[46m][m * syn1neg[c + l2];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;58H[c + l1]
[93m523 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m524 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [28;1H[93m    [m/ 2))]) * alpha;[27;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[8;66H[46m{[m[28;1H[93m528 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[7;66H{[27;13H}
[93m529 [m[7C // Learn weights input -> hidden[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[46m[[mc + l1[46m][m += neu1e[c];[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;51H[c + l1]
[93m531 [m      }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m532 [m    }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m533 [m    sentence_position++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m534 [m    if (sentence_position >= sentence_length) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m535 [m      sentence_length = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m536 [m      continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;51H[46m{[m


[93m537 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[24;51H{[27;9H}
[93m538 [m  }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m539 [m  fclose(fi);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m540 [m  free(neu1);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m541 [m  free(neu1e);[?12l[?25h[27;18H[26;18H[?25l[25;8H[?12l[?25h[?25l[21;51H[46m{[24;9H}[?12l[?25h[?25l[m[21;51H{[24;9H}[23;20H[?12l[?25h[22;31H[?25l[21;51H[46m{[24;9H}[21;52H[?12l[?25h[?25l[m{[24;9H}[20;29H[?12l[?25h[?25l[19;10H[?12l[?25h[?25l[18;12H[?12l[?25h[?25l[17;51H[46m[[mc + l1[46m][?12l[?25h[?25l[m[17;51H[c + l1][16;45H[?12l[?25h[?25l[17;51H[46m[[mc + l1[46m][?12l[?25h[?25l[m[17;51H[c + l1][18;12H[?12l[?25h[?25l[19;10H[?12l[?25h[20;29H[?25l[21;51H[46m{[24;9H}[21;52H[?12l[?25h[?25l[m{[24;9H}[22;31H[?12l[?25h[23;20H[?25l[21;51H[46m{[24;9H}[?12l[?25h[?25l[m[21;51H{[24;9H}[25;8H[?12l[?25h[26;18H[27;18H[28;19H[?25l[1;28r[28;1H
[1;29r[28;1H[93m542 [m  pthread_exit(NULL);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m543 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m544 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m545 [mvoid TrainModel() {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m546 [m  long a, b, c, d;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m547 [m  FILE *fo;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));[28;58H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m549 [m  printf("Starting training using file %s\n", train_file);[?12l[?25h[27;58H[26;16H[25;23H[?25l[24;24H[?12l[?25h[23;5H[?25l[22;6H[?12l[?25h[21;26H[20;19H[19;18H[18;18H[?25l[17;8H[?12l[?25h[?25l[13;51H[46m{[16;9H}[?12l[?25h[?25l[m[13;51H{[16;9H}[15;20H[?12l[?25h[14;31H[?25l[13;51H[46m{[16;9H}[13;52H[?12l[?25h[?25l[m{[16;9H}[12;29H[?12l[?25h[?25l[11;10H[?12l[?25h[?25l[10;12H[?12l[?25h[?25l[9;51H[46m[[mc + l1[46m][?12l[?25h[?25l[m[9;51H[c + l1][8;45H[?12l[?25h[?25l[7;14H[?12l[?25h[6;58H[5;58H[3;58H[2;58H[1;56H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m522 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[46m[[mc + l1[46m][m * syn1neg[c + l2];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m521 [m[9C f = 0;[2;58H[c + l1][1;21H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m520 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m519 [m[9C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m518 [m[11C label = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m517 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m516 [m[11C if (target == 0) target = next_random % [46m([mvocab_size - 1[46m)[m + 1;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m515 [m[11C target = table[(next_random >> 16) % table_size];[2;57H([14C)[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m514 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m513 [m[9C } else [46m{[7;15H}[1;23H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m512 [m[11C label = 1;[2;22H{[8;15H}[1;27H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m511 [m[11C target = word;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m510 [m[9C if (d == 0) [46m{[4;15H}[1;28H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m509 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[2;27H{[5;15H}[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m508 [m[7C // NEGATIVE SAMPLING[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m507 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m506 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * syn0[c + l1];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m505 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m504 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m503 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m502 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m501 [m[9C // 'g' is the gradient multiplied by the learning rate[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m500 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m499 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m498 [m[9C if (f <= -MAX_EXP) continue;[28;1H[94m@                                                                                        [1;43H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m497 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[46m[[mc + l1[46m][m * syn1[c + l2];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m496 [m[9C // Propagate hidden -> output[2;58H[c + l1][1;44H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m495 [m[9C l2 = vocab[word].point[d] * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m494 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m493 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m492 [m[7C // HIERARCHICAL SOFTMAX[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m491 [m[7C for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m490 [m[7C l1 = last_word * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m489 [m[7C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m488 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m487 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m486 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m485 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m484 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m483 [m    } else {  //train skip-gram[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m482 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m481 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m480 [m[9C for (c = 0; c < layer1_size; c++) syn0[c + last_word * layer1_size] += neu11[2;1H[93m    [me[c];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m479 [m[9C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m478 [m[9C last_word = sen[c];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m477 [m[9C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m476 [m[9C if (c < 0) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m475 [m[9C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m474 [m[7C for (a = b; a < window * 2 + 1 - b; a++) if [46m([ma != window[46m)[m {[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m473 [m[7C // hidden -> in[2;57H([11C)[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m472 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m471 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * neu1[c];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m470 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[1;58H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m469 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [2;1H[93m    [m/ 2))]) * alpha;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m468 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m467 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m466 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[46m[[mc[46m][m * syn1neg[c + l2];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m465 [m[9C f = 0;[2;58H[c][1;21H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m464 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m463 [m[9C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m462 [m[11C label = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m461 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m460 [m[11C if (target == 0) target = next_random % [46m([mvocab_size - 1[46m)[m + 1;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m459 [m[11C target = table[(next_random >> 16) % table_size];[2;57H([14C)[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m458 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m457 [m[9C } else [46m{[7;15H}[1;23H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m456 [m[11C label = 1;[2;22H{[8;15H}[1;27H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m455 [m[11C target = word;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m454 [m[9C if (d == 0) [46m{[4;15H}[m[28;1H[94m@                                                                                        [1;28H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m453 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[2;27H{[5;15H}[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m452 [m[7C // NEGATIVE SAMPLING[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m451 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m449 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m447 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m443 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m442 [m[9C if (f <= -MAX_EXP) continue;[28;1H[94m@                                                                                        [1;43H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[46m[[mc[46m][m * syn1[c + l2];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m440 [m[9C // Propagate hidden -> output[2;58H[c][1;44H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m438 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m435 [m      if (cw) {[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m434 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m433 [m[7C cw++;[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_sizee[2;1H[93m    [m];[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m431 [m[7C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m430 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m429 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m428 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m427 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m425 [m      cw = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m424 [m      // in -> hidden[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m423 [m    if (cbow) {  //train the cbow architecture[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m422 [m    b = next_random % window;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m418 [m    if (word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m417 [m    word = sen[sentence_position];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m416 [m    }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m415 [m      continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m414 [m      fseek(fi, file_size / (long long)num_threads * [46m([mlong long[46m)[mid, SEEK_SET);[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m413 [m      sentence_length = 0;[2;58H([9C)[1;31H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m412 [m      last_word_count = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m411 [m      word_count = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m410 [m      if (local_iter == 0) break;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m409 [m      local_iter--;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m408 [m      word_count_actual += word_count - last_word_count;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m406 [m    }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m405 [m      sentence_position = 0;[28;1H[94m@                                                                                        [1;33H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m404 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m402 [m[7C sentence_length++;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m401 [m[7C sen[sentence_length] = word;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m400 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;[1;58H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [2;1H[93m    [mtrain_words) / vocab[word].cn;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m396 [m[7C if (sample > 0) [46m{[6;13H}[1;30H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[2;1H[93m    [m same[3;29H{[8;13H}[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m394 [m[7C if (word == 0) break;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m393 [m[7C word_count++;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m392 [m[7C if (word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m391 [m[7C if (feof(fi)) break;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m390 [m[7C word = ReadWordIndex(fi);[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m389 [m      while (1) [46m{[18;11H}[1;22H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m388 [m    if (sentence_length == 0) [46m{[m[2;21H{[19;11H}[21;9H[46m}[1;36H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m387 [m    }[2;35H{[22;9H}[1;10H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[1;58H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[2;1H[93m    [m));[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m384 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m383 [m[7C fflush(stdout);[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m382 [m[8C word_count_actual / ((real)[46m([mnow - start + 1[46m)[m / (real)CLOCKS_PER_SEC * 1000)))[2;1H[93m    [m;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,[2;41H([15C)[31C))[3;1H[93m [1;58H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m379 [m[7C now=clock();[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m378 [m      if ((debug_mode > 1)) [46m{[8;11H}[1;34H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m377 [m      last_word_count = word_count;[2;33H{[9;11H}[1;40H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m376 [m      word_count_actual += word_count - last_word_count;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m375 [m    if (word_count - last_word_count > 10000) [46m{[15;9H}[1;52H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m374 [m  while (1) {[2;51H{[16;9H}[1;18H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;1H[94m@                                                                                        [1;58H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m372 [m  FILE *fi = fopen(train_file, "rb");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));[28;1H[94m@                                                                                        [1;58H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m369 [m  clock_t now;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m368 [m  real f, g;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m367 [m  unsigned long long next_random = (long long)id;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[46m[[mMAX_SENTENCE_LENGTH + 1[46m][m;[1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[2;57H[[23C][1;58H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m362 [?12l[?25h[2;58H[3;58H[?25l[m[4;57H[46m[[23C][4;58H[?12l[?25h[?25l[m[[23C][5;58H[?12l[?25h[6;54H[7;17H[6;54H[5;58H[?25l[4;57H[46m[[23C][4;58H[?12l[?25h[?25l[m[[23C][3;58H[?12l[?25h[2;58H[1;5H[2;58H[3;58H[?25l[4;57H[46m[[23C][4;58H[?12l[?25h[?25l[m[[23C][5;58H[?12l[?25h[6;54H[7;17H[8;19H[9;58H[10;58H[11;42H[12;58H[?25l[13;18H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*?[?12l[?25h[?25l[13;24H[K[13;24H[?12l[?25h[?25l*/[?12l[?25h[?25l 無限ループ */[?12l[?25h[14;32H[15;32H[16;32H[?25l[17;14H[46m([16C)[?12l[?25h[?25l[m[17;14H([16C)[18;25H[?12l[?25h[19;32H[20;32H[21;32H[23;28H[?25l[17;33H[46m{[24;11H}[?12l[?25h[?25l[m[17;33H{[24;11H}[25;32H[?12l[?25h[27;32H[?25l[14;51H[46m{[28;9H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[13;51H{[27;9H}
[93m388 [m    if (sentence_length == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m389 [m      while (1) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m390 [m[7C word = ReadWordIndex(fi);[?12l[?25h[?25l[27;22H[?12l[?25h[26;32H[?25l[11;51H[46m{[25;9H}[?12l[?25h[?25l[m[11;51H{[25;9H}[24;32H[?12l[?25h[22;32H[?25l[14;33H[46m{[21;11H}[?12l[?25h[?25l[m[14;33H{[21;11H}[20;28H[?12l[?25h[18;32H[17;32H[16;32H[17;32H[18;32H[20;28H[?25l[14;33H[46m{[21;11H}[?12l[?25h[?25l[m[14;33H{[21;11H}[22;32H[?12l[?25h[24;32H[?25l[11;51H[46m{[25;9H}[?12l[?25h[?25l[m[11;51H{[25;9H}[26;32H[?12l[?25h[?25l[27;22H[?12l[?25h[28;32H[?25l[1;28r[28;1H
[1;29r[28;1H[93m391 [m[7C if (feof(fi)) break;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m392 [m[7C if (word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m393 [m[7C word_count++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m394 [m[7C if (word == 0) break;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[28;1H[93m    [m same[27;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m396 [m[7C if (sample > 0) {[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m397 [m[9C real ran = (sqrt[46m([mvocab[word].cn / (sample * train_words)[46m)[m + 1) * (sample *  [28;1H[93m    [mtrain_words) / vocab[word].cn;[27;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[26;31H([39C)[17C  [27;1H[93m 
398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[23;29H[46m{[m[28;1H[93m400 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[22;29H{[27;13H}
[93m401 [m[7C sen[46m[[msentence_length[46m][m = word;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;16H[[15C]
[93m402 [m[7C sentence_length++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[11;21H[46m{[m[28;1H[93m404 [m      [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[10;21H{[27;11H}
[93m405 [m      sentence_position = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[7;35H[46m{[m[27;1H[93m406 [m    [46m}[m
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {[27;10H[?12l[?25h[?25l[7;35H{[27;9H}[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m408 [m      word_count_actual += word_count - last_word_count;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m409 [m      local_iter--;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;[27;32H[?12l[?25h[28;26H[?25l[1;28r[28;1H
[1;29r[28;1H[93m412 [m      last_word_count = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m413 [m      sentence_length = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m415 [m      continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[19;67H[46m{[m[28;1H[93m416 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;67H{[27;9H}
[93m417 [m    word = sen[sentence_position];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m418 [m    if (word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[28;32H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m422 [m    b = next_random % window;[27;32H[?12l[?25h[28;32H[?25l[1;28r[28;1H
[1;29r[28;1H[93m423 [m    if (cbow) {  //train the cbow architecture[28;32H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m424 [m      // in -> hidden
[93m425 [m      cw = 0;[27;26H[?12l[?25h[28;18H[?25l[1;28r[28;1H
[1;29r[28;1H[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m427 [m[7C c = sentence_position - window + a;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m428 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m429 [m[7C if (c >= sentence_length) continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m430 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m431 [m[7C if [46m([mlast_word == -1[46m)[m continue;[28;32H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[26;16H([15C)
[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_sizee[28;1H[93m    [m];[27;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m433 [m[7C cw++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[19;69H[46m{[m[28;1H[93m434 [m      [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;69H{[27;11H}
[93m435 [m      if (cw) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m438 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m440 [m[9C // Propagate hidden -> output[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1[c + l2];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m442 [m[9C if [46m([mf <= -MAX_EXP[46m)[m continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;18H([13C)
[93m443 [m[9C else if (f >= MAX_EXP) continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m444 [m[9C else f = expTable[46m[[m(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))[46m][m;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;32H[[53C]
[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m447 [m[9C // Propagate errors output -> hidden[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m449 [m[9C // Learn weights hidden -> output[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[14;63H[46m{[m[28;1H[93m451 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[13;63H{[27;13H}
[93m452 [m[7C // NEGATIVE SAMPLING[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m453 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m454 [m[9C if (d == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m455 [m[11C target = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m456 [m[11C label = 1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m457 [m[9C } else {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m458 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[28;32H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m459 [m[11C target = table[[46m([mnext_random >> 16[46m)[m % table_size];
[93m460 [m[11C if (target == 0) target = next_random % (vocab_size - 1) + 1;[27;32H[?12l[?25h[?25l([17C)[28;20H[46m([11C)[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;20H([11C)
[93m461 [m[11C if (target == word) continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m462 [m[11C label = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;22H[46m{[m[28;1H[93m463 [m[9C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;22H{[27;15H}
[93m464 [m[9C l2 = target * layer1_size;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m465 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m466 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1neg[c + l2];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m467 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m468 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[28;32H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m469 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [28;1H[93m    [m/ 2))]) * alpha;[27;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m470 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m471 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * neu1[c];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[8;66H[46m{[m[28;1H[93m472 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[7;66H{[27;13H}
[93m473 [m[7C // hidden -> in[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m474 [m[7C for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m475 [m[9C c = sentence_position - window + a;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m476 [m[9C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m477 [m[9C if (c >= sentence_length) continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m478 [m[9C last_word = sen[46m[[mc[46m][m;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;30H[c]
[93m479 [m[9C if (last_word == -1) continue;[28;32H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m480 [m[9C for (c = 0; c < layer1_size; c++) syn0[c + last_word * layer1_size] += neu11[28;1H[93m    [me[c];[27;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[20;71H[46m{[m[28;1H[93m481 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[19;71H{[27;13H}
[93m482 [m      }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m483 [m    } else {  //train skip-gram[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m484 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m485 [m[7C c = sentence_position - window + a;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m486 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m487 [m[7C if (c >= sentence_length) continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m488 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m489 [m[7C if [46m([mlast_word == -1[46m)[m continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;16H([15C)
[93m490 [m[7C l1 = last_word * layer1_size;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m491 [m[7C for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m492 [m[7C // HIERARCHICAL SOFTMAX[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m493 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m494 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m495 [m[9C l2 = vocab[word].point[d] * layer1_size;
[93m496 [m[9C // Propagate hidden -> output[27;32H[?12l[?25h[28;32H[?25l[1;28r[28;1H
[1;29r[28;1H[93m497 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1[c + l2];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m498 [m[9C if [46m([mf <= -MAX_EXP[46m)[m continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;18H([13C)
[93m499 [m[9C else if (f >= MAX_EXP) continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m500 [m[9C else f = expTable[46m[[m(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))[46m][m;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;32H[[53C]
[93m501 [m[9C // 'g' is the gradient multiplied by the learning rate[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m502 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m503 [m[9C // Propagate errors output -> hidden[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m504 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[c + l2];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m505 [m[9C // Learn weights hidden -> output[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m506 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * syn0[c + l1];[28;32H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[13;63H[46m{[m[27;1H[93m507 [m[7C [46m}[m
[93m508 [m[7C // NEGATIVE SAMPLING[27;14H[?12l[?25h[?25l[13;63H{[27;13H}[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m509 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m510 [m[9C if (d == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m511 [m[11C target = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m512 [m[11C label = 1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m513 [m[9C } else {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m514 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m515 [m[11C target = table[[46m([mnext_random >> 16[46m)[m % table_size];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;32H([17C)
[93m516 [m[11C if [46m([mtarget == 0[46m)[m target = next_random % (vocab_size - 1) + 1;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;20H([11C)
[93m517 [m[11C if (target == word) continue;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m518 [m[11C label = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;22H[46m{[m[28;1H[93m519 [m[9C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;22H{[27;15H}
[93m520 [m[9C l2 = target * layer1_size;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m521 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m522 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m523 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m524 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[28;32H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [28;1H[93m    [m/ 2))]) * alpha;[27;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[8;66H[46m{[m[28;1H[93m528 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[7;66H{[27;13H}
[93m529 [m[7C // Learn weights input -> hidden[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m531 [m      }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m532 [m    }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m533 [m    sentence_position++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m534 [m    if (sentence_position >= sentence_length) {[28;32H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m535 [m      sentence_length = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m536 [m      continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;51H[46m{[m


[93m537 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[24;51H{[27;9H}
[93m538 [m  }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m539 [m  fclose(fi);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m540 [m  free(neu1);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m541 [m  free(neu1e);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m542 [m  pthread_exit(NULL);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m543 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m544 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m545 [mvoid TrainModel() {[?12l[?25h[27;5H[?25l[26;6H[?12l[?25h[25;26H[24;19H[23;18H[22;18H[?25l[21;8H[?12l[?25h[?25l[17;51H[46m{[20;9H}[?12l[?25h[?25l[m[17;51H{[20;9H}[19;20H[?12l[?25h[18;31H[17;32H[16;29H[?25l[15;10H[?12l[?25h[?25l[14;12H[?12l[?25h[13;32H[12;32H[?25l[11;14H[?12l[?25h[10;32H[9;32H[7;32H[6;32H[5;32H[4;32H[3;21H[2;32H[?25l[1;16H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m518 [m[11C label = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m517 [m[11C if (target == word) continue;[1;32H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m516 [m[11C if [46m([mtarget == 0[46m)[m target = next_random % (vocab_size - 1) + 1;[1;32H[?12l[?25h[?25l0/[46m)[m target = next_random % (vocab_size - 1) + 1;[1;33H[?12l[?25h[?25l0[46m)[m target = next_random % (vocab_size - 1) + 1;[1;78H[K[1;32H[?12l[?25h[29;1H[K[1;31H[?25l[1;20H([11C)[?12l[?25h[?25l[29;1H/[?12l[?25hbreak[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [2;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引[4;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[7;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[11;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [14;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;
[93m 86 [m    }
[93m 87 [m    word[a] = ch; /* 配列wordのa番目にint型chを代入 */
[93m 88 [m    a++;
[93m 89 [m    if (a >= MAX_STRING - 1) a--;   // Truncate too long words /* 長すぎる単語を削除  [25;1H[93m    [m*/
[93m 90 [m  }
[93m 91 [m  word[a] = 0;
[93m 92 [m}
[38;5;224msearch hit BOTTOM, continuing at TOP[15;13H[?12l[?25h[?25l[m[29;1H/break[29;7H[K[29;1H[27m[m[H[2J[1;1H[93m237 [m    parent_node[min2i] = vocab_size + a; /* min2iの親ノードにvocab_size + a を代入 */[2;1H[93m238 [m    binary[min2i] = 1;
[93m239 [m  }
[93m240 [m  // Now assign binary code to each vocabulary word /* 語彙の各単語に二進法コードを割[5;1H[93m    [m当 */
[93m241 [m  for (a = 0; a < vocab_size; a++) { /* 0 <= a < vocab_sizeの時 */
[93m242 [m    b = a;
[93m243 [m    i = 0;
[93m244 [m    while (1) { /* 無限ループ */
[93m245 [m      code[i] = binary[b]; /* code[i]にbinary[b](最初はb=a)を代入 */
[93m246 [m      point[i] = b; /* pont[i]にbを代入*/
[93m247 [m      i++;
[93m248 [m      b = parent_node[b]; /* bにparent_nodeを代入 */
[93m249 [m      if (b == vocab_size * 2 - 2) break; /* b == vocab_size * 2 - 2の時無限ループか[94m>>[m[15;1H[93m    [mら脱出 */
[93m250 [m    }
[93m251 [m    vocab[a].codelen = i;
[93m252 [m    vocab[a].point[0] = vocab_size - 2;
[93m253 [m    for (b = 0; b < i; b++) {
[93m254 [m      vocab[a].code[i - b - 1] = code[b];
[93m255 [m      vocab[a].point[i - b] = point[b] - vocab_size;
[93m256 [m    }
[93m257 [m  }
[93m258 [m  free(count); /* count分のメモリを解放 */
[93m259 [m  free(binary); /* binary分のメモリを解放 */
[93m260 [m  free(parent_node); /* parent_node分のメモリを解放 */
[93m261 [m}
[93m262 [14;40H[?12l[?25h[?25l[m[29;1H/break[27m[m[H[2J[1;1H[93m266 [m  long long a, i; /* long long型変数a, i */
[93m267 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[3;1H[93m    [mzeの時vocab_hash[a]に-1を代入 */
[93m268 [m  fin = fopen(train_file, "rb"); /* train_fileを読込モードで開く */
[93m269 [m  if (fin == NULL) { /* ポインタfinがNULLの時 */
[93m270 [m    printf("ERROR: training data file not found!\n");
[93m271 [m    exit(1);
[93m272 [m  }
[93m273 [m  vocab_size = 0;
[93m274 [m  AddWordToVocab((char *)"</s>"); /* 単語を語彙に加える関数AddWordToVocab */
[93m275 [m  while (1) { /* 無限ループ */
[93m276 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数でtrain_fileの単語を読み込む  [13;1H[93m    [m*/
[93m277 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m278 [m    train_words++; /* train_wordsに1を足す */
[93m279 [m    if ((debug_mode > 1) && (train_words % 100000 == 0)) { /* debug_mode > 1かつtrainn[17;1H[93m    [m_wordsが100000で割切れる時 */
[93m280 [m      printf("%lldK%c", train_words / 1000, 13);
[93m281 [m      fflush(stdout);
[93m282 [m    }
[93m283 [m    i = SearchVocab(word); /* 103行目で定義した語彙中の単語の位置を返す関数SearchVocaa[22;1H[93m    [mb */
[93m284 [m    if (i == -1) { /* i == -1の時 */
[93m285 [m      a = AddWordToVocab(word);
[93m286 [m      vocab[a].cn = 1;
[93m287 [m    } else vocab[i].cn++;
[93m288 [m    if (vocab_size > vocab_hash_size * 0.7) ReduceVocab();
[93m289 [m  }[14;24H[?12l[?25h[?25l[29;1H/break[27m[m[H[2J[1;1H[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb"); /* 読込モードでread_vocab_fileを開く */
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[10;1H[93m    [mzeの時 */
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) { /* 無限ループ */
[93m318 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数 */
[93m319 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m320 [m    a = AddWordToVocab(word); /* 単語を語彙に加える関数AddWordToVocab */
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c); /* ファイルポインタfinから読出した値をvoo[17;1H[93m    [mcab[a].cnに取込み， */
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb"); /* 読取モードでtrain_fileを開く */
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);[14;24H[?12l[?25h[?25l[29;1H/break[27m[m[H[2J[1;1H[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[2;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[4;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[8;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;
[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) {
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break;
[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break;
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[19;1H[93m    [m same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [22;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;[14;27H[?12l[?25h[?25l[29;1H/break[17;28H[?12l[?25h[?25l[29;1H[28;57H[?12l[?25h[?25l
?[17;28H[?12l[?25h[16;25H[15;28H[14;28H[13;28H[12;21H[?25l[29;1H[1m-- INSERT --[12;22H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l 無限ループ[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[13;38H[14;33H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l :[?12l[?25h[?25l[14;38H[K[14;38H[?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 3 */[?12l[?25h[?25l38 */[?12l[?25h[?25l89 */[?12l[?25h[?25l9行目 */[?12l[?25h[?25lからの */[?12l[?25h[?25l無限ループから */[?12l[?25h[?25l脱出 */[?12l[?25h[15;38H[16;26H[17;34H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [18;38H[?25l[51Cgg[19;1H[93m [m[20;29H[46m{[25;13H}[20;30H[?12l[?25h[?25l[m{[25;13H}[18;38H[?12l[?25h[17;38H*/[?25l[17;39H[K[17;39H[?12l[?25h[?25l[17;38H[K[17;38H[?12l[?25h[?25l[?12l[?25h[?25l[17;36H[K[17;36H[?12l[?25h[?25l[17;35H[K[17;35H[?12l[?25h[?25l /* 389行目からの無限ループから脱出 */[?12l[?25h[29;1H[K[17;71H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hbreak[?25l[28;57H[?12l[?25h[?25l
[1;28r[1;1H[8M[1;29r[21;1H[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;[29;1H[K[27;32H[?12l[?25h[?25l

/break[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [2;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引 [4;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[7;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[11;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [14;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;
[93m 86 [m    }
[93m 87 [m    word[a] = ch; /* 配列wordのa番目にint型chを代入 */
[93m 88 [m    a++;
[93m 89 [m    if (a >= MAX_STRING - 1) a--;   // Truncate too long words /* 長すぎる単語を削除  [25;1H[93m    [m*/
[93m 90 [m  }
[93m 91 [m  word[a] = 0;
[93m 92 [m}
[38;5;224msearch hit BOTTOM, continuing at TOP[15;13H[?12l[?25h[?25l[m[29;1H?break[29;7H[K[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [2;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;
[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;
[93m412 [m      last_word_count = 0;
[93m413 [m      sentence_length = 0;
[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m415 [m      continue;
[93m416 [m    }
[93m417 [m    word = sen[sentence_position];
[93m418 [m    if (word == -1) continue;
[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;
[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m422 [m    b = next_random % window;
[93m423 [m    if (cbow) {  //train the cbow architecture
[38;5;224msearch hit TOP, continuing at BOTTOM[15;32H[?12l[?25h[?25l[m[29;1H/break[29;7H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [2;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引 [4;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[7;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[11;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [14;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;
[93m 86 [m    }
[93m 87 [m    word[a] = ch; /* 配列wordのa番目にint型chを代入 */
[93m 88 [m    a++;
[93m 89 [m    if (a >= MAX_STRING - 1) a--;   // Truncate too long words /* 長すぎる単語を削除  [25;1H[93m    [m*/
[93m 90 [m  }
[93m 91 [m  word[a] = 0;
[93m 92 [m}
[38;5;224msearch hit BOTTOM, continuing at TOP[15;13H[?12l[?25h[?25l[m[29;1H?break[29;7H[K[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [2;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;
[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;
[93m412 [m      last_word_count = 0;
[93m413 [m      sentence_length = 0;
[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m415 [m      continue;
[93m416 [m    }
[93m417 [m    word = sen[sentence_position];
[93m418 [m    if (word == -1) continue;
[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;
[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m422 [m    b = next_random % window;
[93m423 [m    if (cbow) {  //train the cbow architecture
[38;5;224msearch hit TOP, continuing at BOTTOM[15;32H[?12l[?25h[?25l[m[29;1H/break[29;7H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [2;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引 [4;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[7;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[11;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [14;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;
[93m 86 [m    }
[93m 87 [m    word[a] = ch; /* 配列wordのa番目にint型chを代入 */
[93m 88 [m    a++;
[93m 89 [m    if (a >= MAX_STRING - 1) a--;   // Truncate too long words /* 長すぎる単語を削除  [25;1H[93m    [m*/
[93m 90 [m  }
[93m 91 [m  word[a] = 0;
[93m 92 [m}
[38;5;224msearch hit BOTTOM, continuing at TOP[15;13H[?12l[?25h[?25l[m[29;1H/break[29;7H[K[29;1H[27m[m[H[2J[1;1H[93m237 [m    parent_node[min2i] = vocab_size + a; /* min2iの親ノードにvocab_size + a を代入 */[2;1H[93m238 [m    binary[min2i] = 1;
[93m239 [m  }
[93m240 [m  // Now assign binary code to each vocabulary word /* 語彙の各単語に二進法コードを割[5;1H[93m    [m当 */
[93m241 [m  for (a = 0; a < vocab_size; a++) { /* 0 <= a < vocab_sizeの時 */
[93m242 [m    b = a;
[93m243 [m    i = 0;
[93m244 [m    while (1) { /* 無限ループ */
[93m245 [m      code[i] = binary[b]; /* code[i]にbinary[b](最初はb=a)を代入 */
[93m246 [m      point[i] = b; /* pont[i]にbを代入*/
[93m247 [m      i++;
[93m248 [m      b = parent_node[b]; /* bにparent_nodeを代入 */
[93m249 [m      if (b == vocab_size * 2 - 2) break; /* b == vocab_size * 2 - 2の時無限ループか[94m>>[m[15;1H[93m    [mら脱出 */
[93m250 [m    }
[93m251 [m    vocab[a].codelen = i;
[93m252 [m    vocab[a].point[0] = vocab_size - 2;
[93m253 [m    for (b = 0; b < i; b++) {
[93m254 [m      vocab[a].code[i - b - 1] = code[b];
[93m255 [m      vocab[a].point[i - b] = point[b] - vocab_size;
[93m256 [m    }
[93m257 [m  }
[93m258 [m  free(count); /* count分のメモリを解放 */
[93m259 [m  free(binary); /* binary分のメモリを解放 */
[93m260 [m  free(parent_node); /* parent_node分のメモリを解放 */
[93m261 [m}
[93m262 [14;40H[?12l[?25h[?25l[m[29;1H?break[27m[m[H[2J[1;1H[93m 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [2;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引 [4;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[7;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[11;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [14;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;
[93m 86 [m    }
[93m 87 [m    word[a] = ch; /* 配列wordのa番目にint型chを代入 */
[93m 88 [m    a++;
[93m 89 [m    if (a >= MAX_STRING - 1) a--;   // Truncate too long words /* 長すぎる単語を削除  [25;1H[93m    [m*/
[93m 90 [m  }
[93m 91 [m  word[a] = 0;
[93m 92 [m}[15;13H[?12l[?25h[?25l[29;1H?break[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [2;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;
[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;
[93m412 [m      last_word_count = 0;
[93m413 [m      sentence_length = 0;
[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m415 [m      continue;
[93m416 [m    }
[93m417 [m    word = sen[sentence_position];
[93m418 [m    if (word == -1) continue;
[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;
[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m422 [m    b = next_random % window;
[93m423 [m    if (cbow) {  //train the cbow architecture
[38;5;224msearch hit TOP, continuing at BOTTOM[15;32H[?12l[?25h[?25l[m[29;1H?break[29;7H[K[29;1H[8;57H[?12l[?25h[?25l[29;1H[1;28r[1;1H[4L[1;29r[1;1H[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[3;1H[93m    [m same
[93m396 [m[7C if (sample > 0) {[29;1H[K[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m393 [m[7C word_count++;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m392 [m[7C if (word == -1) continue;[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m390 [m[7C word = ReadWordIndex(fi);[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m389 [m      while (1) { /* 無限ループ */[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m388 [m    if (sentence_length == 0) {[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m387 [m    }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[1;28H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[2;1H[93m    [m));[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m384 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m383 [m[7C fflush(stdout);[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[2;1H[93m    [m;[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m379 [m[7C now=clock();[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m378 [m      if ((debug_mode > 1)) {[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m377 [m      last_word_count = word_count;[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m376 [m      word_count_actual += word_count - last_word_count;[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m375 [m    if (word_count - last_word_count > 10000) {[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m374 [m  while (1) { /* 無限ループ */[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;1H[94m@                                                                                        [1;28H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m372 [m  FILE *fi = fopen(train_file, "rb");[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m371 [m  real *neu1e = [46m([mreal *[46m)[mcalloc(layer1_size, sizeof(real));[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));[2;21H(real *)[28;1H[94m@                                                                                        [1;28H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m369 [m  clock_t now;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m368 [m  real f, g;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m367 [m  unsigned long long next_random = (long long)id;[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[1;28H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */[1;28H[?12l[?25h[2;28H[3;28H[4;28H[5;28H[6;16H[7;18H[8;28H[?25l[9;21H[46m([mreal *[46m)[?12l[?25h[?25l[m[9;21H(real *)[10;28H[?12l[?25h[11;28H[12;28H[?25l[27m[m[H[2J[1;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [2;1H[93m    [m/ 2))]) * alpha;
[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
[93m528 [m[7C }
[93m529 [m[7C // Learn weights input -> hidden
[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
[93m531 [m      }
[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() {
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();[15;7H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[5;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");
[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) [46m{[m /* 無限ループ */
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;
[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {
[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[21;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[23;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[27;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[14;17H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [2;1H[93m    [m/ 2))]) * alpha;
[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
[93m528 [m[7C }
[93m529 [m[7C // Learn weights input -> hidden
[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
[93m531 [m      }
[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() {
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();[15;7H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[5;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");
[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) [46m{[m /* 無限ループ */
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;
[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {
[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[21;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[23;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[27;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[14;17H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [2;1H[93m    [m/ 2))]) * alpha;
[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
[93m528 [m[7C }
[93m529 [m[7C // Learn weights input -> hidden
[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
[93m531 [m      }
[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() {
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();[15;7H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[5;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");
[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) [46m{[m /* 無限ループ */
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;
[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {
[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[21;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[23;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[27;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[14;17H[?12l[?25h[?25l{[?12l[?25h /* [2C[2C[2C[2C[2C[3;5H[?25l[27m[m[H[2J[1;1H[93m531 [m      }
[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() {
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();
[93m552 [m  if (save_vocab_file[0] != 0) SaveVocab();
[93m553 [m  if (output_file[0] == 0) return;
[93m554 [m  InitNet();
[93m555 [m  if (negative > 0) InitUnigramTable();
[93m556 [m  start = clock();
[93m557 [m  for (a = 0; a < num_threads; a++) pthread_create(&pt[a], NULL, TrainModelThread, (vv[28;1H[93m    [moid *)a);[14;5H[?12l[?25h[?25l[29;1H1 change; before #93  85 seconds ago[27m[m[H[2J[1;1H[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[2;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[6;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;
[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) { /* 無限ループ */
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */
[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break; /* */
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[17;1H[93m    [m same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [20;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;
[93m404 [m      }
[93m405 [m      sentence_position = 0;[15;39H[?12l[?25h[?25l[29;1H1 change; after #93  90 seconds ago[15;37H 389行目からの無限ループから脱出 */[15;40H[?12l[?25h[14;25H[13;37H[12;40H[11;37H[10;38H[9;35H[8;9H[7;40H[5;40H[4;11H[3;27H[?25l[1;35H[46m([mreal[46m)[m[48C))[2;1H[93m [1;40H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m381 [m[8C word_count_actual / (real)[46m([miter * train_words + 1[46m)[m * 100,[2;35H(real)[48C))[3;1H[93m [m[29;1H[K[1;40H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[2;40H([22C)[1;40H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m379 [m[7C now=clock();[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m378 [m      if ((debug_mode > 1)) [46m{[8;11H}[1;33H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m377 [m      last_word_count = word_count;[2;33H{[9;11H}[1;39H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m376 [m      word_count_actual += word_count - last_word_count;[1;40H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m375 [m    if (word_count - last_word_count > 10000) {[1;40H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m374 [m  while (1) { /* 無限ループ */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;1H[94m@                                                                                        [1;40H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m372 [m  FILE *fi = fopen[46m([mtrain_file, "rb"[46m)[m;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));[2;23H([16C)[1;40H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));[28;1H[94m@                                                                                        [1;40H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m369 [m  clock_t now;[?12l[?25h[?25l[29;1H/break[25;27H[?12l[?25h[?25l[29;1H[28;28H[?12l[?25h[27;25H[26;28H[25;28H[24;28H[23;28H[22;28H[?25l[7;51H[46m{[21;9H}[?12l[?25h[?25l[m[7;51H{[21;9H}[20;28H[?12l[?25h[18;28H[?25l[10;33H[46m{[17;11H}[?12l[?25h[?25l[m[10;33H{[17;11H}[16;27H[?12l[?25h[14;28H[13;28H[12;28H[11;24H[10;28H[9;28H[8;28H[7;28H[6;28H[?25l[27m[m[H[2J[1;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [2;1H[93m    [m/ 2))]) * alpha;
[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
[93m528 [m[7C }
[93m529 [m[7C // Learn weights input -> hidden
[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
[93m531 [m      }
[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() {
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();[15;7H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[5;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");
[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) [46m{[m /* 無限ループ */
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;
[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {
[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[21;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[23;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[27;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[14;17H[?12l[?25h[?25l{[?12l[?25h /* [2C[2C[2C[2C[2C[?25l[29;1H[1m-- INSERT --[14;33H[?12l[?25h[?25l[m( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l[?12l[?25h[?25l[46m([m5[46m)[m */[?12l[?25h[?25l53[46m)[m */[?12l[?25h[?25l38[46m)[m */[?12l[?25h[?25l8行目[46m)[m */[?12l[?25h[?25lまで[46m)[m */[?12l[?25h[?25l[1C[?12l[?25h[?25l[14;32H([11C)1 */[?12l[?25h[29;1H[K[14;45H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hbreak[?25l[1;28r[1;1H[5M[1;29r[24;1H[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) { /* 無限ループ */
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[29;1H[K[28;27H[?12l[?25h[?25l
/break[1;28r[1;1H[3M[1;29r[26;1H[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */[29;1H[K[28;28H[?12l[?25h[?25l
/break[1;28r[1;1H[11M[1;29r[18;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[19;1H[93m    [m same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [22;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;[29;1H[K[28;57H[?12l[?25h[27;30H[26;40H[?25l[20;29H[46m{[25;13H}[?12l[?25h[?25l[m[20;29H{[25;13H}[24;57H[?12l[?25h[23;57H[21;57H[?25l[20;29H[46m{[25;13H}[20;29H[?12l[?25h[?25l[m{[25;13H}[18;57H[?12l[?25h[17;57H[16;25H[15;37H[14;56H[13;37H[12;38H[11;35H[?25l[1;28r[1;1H[4M[1;29r[7;35H[46m{[m[25;1H[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    [46m}[m
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {[27;9H[?12l[?25h[?25l[7;35H[?12l[?25h[?25l[27;9H[?12l[?25h[?25l[7;35H[?12l[?25h[?25l[27;9H[?12l[?25h[?25l[7;35H[?12l[?25h[?25l[27;9H[?12l[?25h[?25l[7;35H[?12l[?25h[?25l[27;9H[?12l[?25h[?25l[7;35H{[27;9H}[28;9H[?12l[?25h[?25l if [46m([52C)[?12l[?25h[?25l[7;35H{[27;9H}[m[28;12H([52C)[27;9H[?12l[?25h[?25l[7;35H[?12l[?25h[?25l{[27;9H}[8;34H[?12l[?25h[?25l[46m{[25;11H}[8;21H[?12l[?25h[?25l[25;11H[?12l[?25h[?25l[8;21H[?12l[?25h[?25l[25;11H[?12l[?25h[?25l[8;21H[?12l[?25h[?25l[25;11H[?12l[?25h[?25l[8;21H[?12l[?25h[?25l[25;11H[?12l[?25h[?25l[8;21H[?12l[?25h[?25l[m{[25;11H}[8;22H[?12l[?25h /* [2C[2C[2C[2C[2C[?25l[27m[m[H[2J[1;1H[93m352 [m    if (syn1neg == NULL) {printf("Memory allocation failed\n"); exit(1);} /* 上でメモ[2;1H[93m    [mリの割当に失敗した時に表示 */
[93m353 [m    for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) /* 0 <= a < voo[4;1H[93m    [mcab_size & 0 <= b < layer1_sizeの時 */
[93m354 [m     syn1neg[a * layer1_size + b] = 0;
[93m355 [m  }
[93m356 [m  for (a = 0; a < vocab_size; a++) for (b = 0; b < layer1_size; b++) {
[93m357 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m358 [m    syn0[a * layer1_size + b] = (((next_random & 0xFFFF) / (real)65536) - 0.5) / layee[10;1H[93m    [mr1_size;
[93m359 [m  }
[93m360 [m  CreateBinaryTree(); /* 198行目で定義したCreateBinaryTree()でHuffman木を生成 */
[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[17;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");
[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) { /* 無限ループ(538行目まで)1 */
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;[15;5H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m531 [m      }
[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() {
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();
[93m552 [m  if (save_vocab_file[0] != 0) SaveVocab();
[93m553 [m  if (output_file[0] == 0) return;
[93m554 [m  InitNet();
[93m555 [m  if (negative > 0) InitUnigramTable();
[93m556 [m  start = clock();
[93m557 [m  for (a = 0; a < num_threads; a++) pthread_create(&pt[a], NULL, TrainModelThread, (vv[28;1H[93m    [moid *)a);[14;5H[?12l[?25h[?25l[29;1H1 change; before #96  49 seconds ago[27m[m[H[2J[1;1H[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[5;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");
[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) { /* 無限ループ(538行目まで) */
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;
[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {
[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[21;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[23;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[27;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[14;45H[?12l[?25h[?25l[29;1H1 change; after #96  53 seconds ago[14;44H)1 */[?12l[?25h[?25l[29;1HAlready at newest change[29;25H[K[14;45H[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[?25l) */[14;48H[K[14;45H[?12l[?25h[?25l[29;1H[K[29;1H/[?12l[?25hbreak[?25l[1;28r[1;1H[5M[1;29r[24;1H[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) { /* 無限ループ */
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[29;1H[K[28;27H[?12l[?25h[27;27H[26;26H[?25l[1;28r[1;1H[15M[1;29r[11;21H[46m{[m


[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[18;1H[93m    [m same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [21;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;
[93m404 [m      [46m}[?12l[?25h[?25l[11;21H[?12l[?25h[?25l[28;11H[?12l[?25h[?25l[11;21H[?12l[?25h[?25l[m{[28;11H}[11;22H[?12l[?25h /* [2C[2C[2C[2C[2C[?25l[29;1H[1m-- INSERT --[11;37H[?12l[?25h[?25l[m( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l[?12l[?25h[?25l[46m([m4[46m)[m */[?12l[?25h[?25l40[46m)[m */[?12l[?25h[?25l04[46m)[m */[?12l[?25h[?25l4行目[46m)[m */[?12l[?25h[?25lまで[46m)[m */[?12l[?25h[?25l[11;36H([11C)[12;38H[?12l[?25h[13;48H[12;38H[13;48H[14;35H[15;26H[16;35H[17;35H[?25l[54Cgg[18;1H[93m [m[19;29H[46m{[24;13H}[19;30H[?12l[?25h[?25l[m{[24;13H}[20;35H[?12l[?25h[22;35H[23;35H[?25l[19;29H[46m{[24;13H}[?12l[?25h[?25l[m[19;29H{[24;13H}[25;35H[?12l[?25h[26;31H[27;35H MAX_SENTENCE_LENGT[?25l[27;16H[46m([38C)[?12l[?25h[?25l)[?12l[?25h[?25l[m[27;16H([38C) [?12l[?25hbreak;[?25l /* 389行目からの無限ループ [28;1H[93m    [mから脱出 */[?12l[?25h[26;31H[25;41H[?25l[19;29H[46m{[24;13H}[?12l[?25h[?25l[m[19;29H{[24;13H}[23;72H[?12l[?25h[22;80H[?25l[20;80H[46m([m[8C  [21;1H[93m [m[14C[46m)[?12l[?25h[?25l[19;29H{[m[20;80H([8C  [21;1H[93m [m[14C)[24;13H[46m}[19;30H[?12l[?25h[?25l[m{[24;13H}[18;10H[?12l[?25h[16;72H[15;26H[16;72H[29;1H[K[16;71H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hbreak[?25l[27;57H[?12l[?25h[?25l

[1;28r[1;1H[7M[1;29r[22;1H[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;[29;1H[K[28;32H[?12l[?25h[27;23H[26;32H[25;32Hount > train_words / num_thread[?25l[25;25H[46m([38C)[?12l[?25h[?25l[25;12H([m[12C([38C)[46m)[?12l[?25h[?25l[m[25;12H([52C)[?12l[?25h [?25l[1;28r[1;1H[6M[1;29r[19;67H[46m{[m[23;1H[93m411 [m      word_count = 0;
[93m412 [m      last_word_count = 0;
[93m413 [m      sentence_length = 0;
[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m415 [m      continue;
[93m416 [m    [46m}[?12l[?25h[?25l[19;67H[?12l[?25h[?25l[28;9H[?12l[?25h[?25l[19;67H[?12l[?25h[?25l[28;9H[?12l[?25h[?25l[19;67H[?12l[?25h[?25l[28;9H[?12l[?25h[?25l[19;67H[?12l[?25h[?25l[28;9H[?12l[?25h[?25l[19;67H[?12l[?25h[?25l[28;9H[?12l[?25h[?25l[19;67H[?12l[?25h[?25l[28;9H[?12l[?25h[?25l[19;67H[?12l[?25h[?25l[28;9H[?12l[?25h[?25l[19;67H[?12l[?25h[?25l[28;9H[?12l[?25h[?25l[m[19;67H{[28;9H}[27;9H[?12l[?25h[26;9H[25;9H[24;9H[23;9H[22;9H[21;9H[20;9H[19;9H[18;9H[17;9H[16;9H[14;9H[13;9H[12;9H[11;9H[10;9H[9;9H[7;9H[6;9H[4;9H[3;9H[2;9H[1;9H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m390 [m[7C word = ReadWordIndex(fi);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m389 [m      while (1) { /* 無限ループ(404行目まで) */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m388 [m    if (sentence_length == 0) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m387 [m    }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[1;9H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[2;1H[93m    [m));[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m384 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m383 [m[7C fflush(stdout);[1;9H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[2;1H[93m    [m;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[28;1H[94m@                                                                                        [1;9H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m379 [m[7C now=clock();[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m378 [m      if ((debug_mode > 1)) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m377 [m      last_word_count = word_count;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m376 [m      word_count_actual += word_count - last_word_count;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m375 [m    if (word_count - last_word_count > 10000) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m374 [m  while (1) { /* 無限ループ(538行目まで) */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;1H[94m@                                                                                        [1;9H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m372 [m  FILE *fi = fopen(train_file, "rb");[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));[28;1H[94m@                                                                                        [1;9H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m369 [m  clock_t now;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m368 [m  real f, g;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m367 [m  unsigned long long next_random = (long long)id;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m362 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m361 [m}[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m360 [m  CreateBinaryTree(); /* 198行目で定義したCreateBinaryTree()でHuffman木を生成 */[1;9H[?12l[?25h[2;5H[3;5H[4;9H[5;9H[6;9H[7;9H[8;9H[9;9H[10;9H[11;9H[12;9H[13;9H[14;9H[15;9Hile[?25l [46m([m1[46m)[?12l[?25h[?25l[m(1)[?12l[?25h[?25l[46m([m1[46m)[?12l[?25h[?25l[m(1)[?12l[?25h [?25l[27m[m[H[2J[1;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [2;1H[93m    [m/ 2))]) * alpha;
[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
[93m528 [m[7C }
[93m529 [m[7C // Learn weights input -> hidden
[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
[93m531 [m      }
[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() {
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();[15;7H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[5;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");
[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) [46m{[m /* 無限ループ(538行目まで) */
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;
[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {
[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[21;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[23;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[27;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[14;17H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [2;1H[93m    [m/ 2))]) * alpha;
[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];
[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];
[93m528 [m[7C }
[93m529 [m[7C // Learn weights input -> hidden
[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[c];
[93m531 [m      }
[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() {
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();[15;7H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[5;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");
[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) [46m{[m /* 無限ループ(538行目まで) */
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;
[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {
[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[21;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[23;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[27;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[14;17H[?12l[?25h[?25l[29;1H/[?12l[?25hbreae[?25l[29;6H[K[29;6H[?12l[?25hk[?25l[1;28r[1;1H[5M[1;29r[9;17H{[24;1H[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) { /* 無限ループ(404行目まで) */
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[29;1H[K[28;27H[?12l[?25h[?25l
/break[1;28r[1;1H[3M[1;29r[26;1H[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */[29;1H[K[28;28H[?12l[?25h[?25l
/break[1;28r[1;1H[12M[1;29r[17;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[18;1H[93m    [m same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [21;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break; /* 389行目からの無限ループ [28;1H[93m    [mから脱出 */[29;1H[K[27;57H[?12l[?25h[?25l

/break[1;28r[1;1H[7M[1;29r[22;1H[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;[29;1H[K[28;32H[?12l[?25h[?25l
/break[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [2;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引[4;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[7;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[11;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [14;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;
[93m 86 [m    }
[93m 87 [m    word[a] = ch; /* 配列wordのa番目にint型chを代入 */
[93m 88 [m    a++;
[93m 89 [m    if (a >= MAX_STRING - 1) a--;   // Truncate too long words /* 長すぎる単語を削除  [25;1H[93m    [m*/
[93m 90 [m  }
[93m 91 [m  word[a] = 0;
[93m 92 [m}
[38;5;224msearch hit BOTTOM, continuing at TOP[15;13H[?12l[?25h[?25l[m[29;1H?break[29;7H[K[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[27m[m[H[2J[1;1H[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break; /* 389行目からの無限ループ [7;1H[93m    [mから脱出 */
[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;
[93m412 [m      last_word_count = 0;
[93m413 [m      sentence_length = 0;
[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m415 [m      continue;
[93m416 [m    }
[93m417 [m    word = sen[sentence_position];
[93m418 [m    if (word == -1) continue;
[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;
[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;
[93m422 [m    b = next_random % window;
[93m423 [m    if (cbow) {  //train the cbow architecture
[93m424 [m      // in -> hidden
[38;5;224msearch hit TOP, continuing at BOTTOM[14;32H[?12l[?25h[?25l[m[29;1H[K[29;1H:[?12l[?25h374[?25l[27m[m[H[2J[1;1H[93m361 [m}
[93m362 
363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */
[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[5;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];
[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;
[93m367 [m  unsigned long long next_random = (long long)id;
[93m368 [m  real f, g;
[93m369 [m  clock_t now;
[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));
[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));
[93m372 [m  FILE *fi = fopen(train_file, "rb");
[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m374 [m  while (1) { /* 無限ループ(538行目まで) */
[93m375 [m    if (word_count - last_word_count > 10000) {
[93m376 [m      word_count_actual += word_count - last_word_count;
[93m377 [m      last_word_count = word_count;
[93m378 [m      if ((debug_mode > 1)) {
[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[21;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[23;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[27;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[14;7H[?12l[?25h[?25l[29;1H/break[1;28r[1;1H[5M[1;29r[24;1H[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) { /* 無限ループ(404行目まで) */
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[29;1H[K[28;27H[?12l[?25h[?25l
/[?12l[?25hgo[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m  1 [m//  Copyright 2013 Google Inc. All Rights Reserved.
[93m  2 [m//
[93m  3 [m//  Licensed under the Apache License, Version 2.0 (the "License");
[93m  4 [m//  you may not use this file except in compliance with the License.
[93m  5 [m//  You may obtain a copy of the License at
[93m  6 [m//
[93m  7 [m//      http://www.apache.org/licenses/LICENSE-2.0
[93m  8 [m//
[93m  9 [m//  Unless required by applicable law or agreed to in writing, software
[93m 10 [m//  distributed under the License is distributed on an "AS IS" BASIS,
[93m 11 [m//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
[93m 12 [m//  See the License for the specific language governing permissions and
[93m 13 [m//  limitations under the License.
[93m 14 
 15 [m#include <stdio.h>
[93m 16 [m#include <stdlib.h>
[93m 17 [m#include <string.h>
[93m 18 [m#include <math.h>
[93m 19 [m#include <pthread.h>
[93m 20 
 21 [m#define MAX_STRING 100 /* 最大文字数は100字まで */
[93m 22 [m#define EXP_TABLE_SIZE 1000
[93m 23 [m#define MAX_EXP 6
[93m 24 [m#define MAX_SENTENCE_LENGTH 1000
[93m 25 [m#define MAX_CODE_LENGTH 40 /* 最大コード長は40字まで */
[93m 26 
 27 [mconst int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in the vocabull[28;1H[93m    [mary
[38;5;224msearch hit BOTTOM, continuing at TOP[12;51H[?12l[?25h[?25l[m[29;1H/go[29;4H[K[29;1H[27m[m[H[2J[1;1H[93m201 [m  long long *count = (long long *)calloc(vocab_size * 2 + 1, sizeof(long long)); /* ll[2;1H[93m    [mong long型ポインタcountに(vocab_size * 2 * 1) * (long long)分のメモリを確保 */
[93m202 [m  long long *binary = (long long *)calloc(vocab_size * 2 + 1, sizeof(long long)); /*  [4;1H[93m    [mlong long型ポインタbinaryに(vocab_size * 2 * 1) * (long long)分のメモリを確保 */
[93m203 [m  long long *parent_node = (long long *)calloc(vocab_size * 2 + 1, sizeof(long long)))[6;1H[93m    [m; /* long long型ポインタparent_nodeに(vocab_size * 2 * 1) * (long long)分のメモリを確[7;1H[93m    [m保 */
[93m204 [m  for (a = 0; a < vocab_size; a++) count[a] = vocab[a].cn; /* ポインタcountの0 <= a <<[9;1H[93m    [m vocab_size番目ににvocab[a].cnを代入 */
[93m205 [m  for (a = vocab_size; a < vocab_size * 2; a++) count[a] = 1e15; /* ポインタcountのvoo[11;1H[93m    [mcab_size <= a < vocab_size * 2番目ににvocab[a].cnを代入 */
[93m206 [m  pos1 = vocab_size - 1;
[93m207 [m  pos2 = vocab_size;
[93m208 [m  // Following algorithm constructs the Huffman tree by adding one node at a time /*  [15;1H[93m    [mノードをa回追加してHuffman木を構成するアルゴリズム */
[93m209 [m  for (a = 0; a < vocab_size - 1; a++) {
[93m210 [m    // First, find two smallest nodes 'min1, min2' /* まず2つの最小ノード'min1, min2''[18;1H[93m    [mを探す */
[93m211 [m    if (pos1 >= 0) { /* pos1(最初はvocab_size-1)が非負の時 */
[93m212 [m      if (count[pos1] < count[pos2]) { /* count[pos1] < count[pos2](最初はpos1 = vocaa[21;1H[93m    [mb_size - 1, pos2 = vocab_size)の時 */
[93m213 [m[7C min1i = pos1; /* long long型min1iにpos1を代入 */
[93m214 [m[7C pos1--;
[93m215 [m      } else { /* count[pos1] >= count[pos2]の時 */
[93m216 [m[7C min1i = pos2;
[93m217 [m[7C pos2++;
[93m218 [m      }
[93m219 [m    } else { /* pos1が負の時 */[14;22H[?12l[?25h[?25l[29;1H/go[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m  1 [m//  Copyright 2013 Google Inc. All Rights Reserved.
[93m  2 [m//
[93m  3 [m//  Licensed under the Apache License, Version 2.0 (the "License");
[93m  4 [m//  you may not use this file except in compliance with the License.
[93m  5 [m//  You may obtain a copy of the License at
[93m  6 [m//
[93m  7 [m//      http://www.apache.org/licenses/LICENSE-2.0
[93m  8 [m//
[93m  9 [m//  Unless required by applicable law or agreed to in writing, software
[93m 10 [m//  distributed under the License is distributed on an "AS IS" BASIS,
[93m 11 [m//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
[93m 12 [m//  See the License for the specific language governing permissions and
[93m 13 [m//  limitations under the License.
[93m 14 
 15 [m#include <stdio.h>
[93m 16 [m#include <stdlib.h>
[93m 17 [m#include <string.h>
[93m 18 [m#include <math.h>
[93m 19 [m#include <pthread.h>
[93m 20 
 21 [m#define MAX_STRING 100 /* 最大文字数は100字まで */
[93m 22 [m#define EXP_TABLE_SIZE 1000
[93m 23 [m#define MAX_EXP 6
[93m 24 [m#define MAX_SENTENCE_LENGTH 1000
[93m 25 [m#define MAX_CODE_LENGTH 40 /* 最大コード長は40字まで */
[93m 26 
 27 [mconst int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in the vocabull[28;1H[93m    [mary
[38;5;224msearch hit BOTTOM, continuing at TOP[12;51H[?12l[?25h[?25l[m[29;1H[K[29;1H/[?12l[?25hgo n[?25l[29;5H[K[29;5H[?12l[?25h[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[m[97m[41mE486: Pattern not found: go [m[29;29H[K[12;51H[?12l[?25h[12;5H[?25l[29;1H1 change; before #100  17:57:50[27m[m[H[2J[1;1H[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[5;1H[93m    [m same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [8;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break;
[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;
[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;
[93m411 [m      word_count = 0;
[93m412 [m      last_word_count = 0;
[93m413 [m      sentence_length = 0;
[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);
[93m415 [m      continue;
[93m416 [m    }
[93m417 [m    word = sen[sentence_position];[14;62H[?12l[?25h[?25l[29;1H1 change; after #100  17:57:50[15;28r[15;1H[L[1;29r[14;63H /* 389行目からの無限ループ [15;1H[93m    [mから脱出 */[29;1H[K[14;63H[?12l[?25h[?25l[29;1H/[?12l[?25hgoto[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[m[97m[41mE486: Pattern not found: goto[m[29;30H[K[14;63H[?12l[?25h[13;30H[12;40H[?25l[6;29H[46m{[11;13H}[?12l[?25h[?25l[m[6;29H{[11;13H}[10;63H[?12l[?25h[9;63H[7;63H[?25l[6;29H[46m{[11;13H}[6;29H[?12l[?25h[?25l[m{[11;13H}[4;63H[?12l[?25h[3;63H[2;25H[1;37H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[29;1H[K[1;62H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m390 [m[7C word = ReadWordIndex(fi);[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m389 [m      while (1) { /* 無限ループ(404行目まで) */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m388 [m    if (sentence_length == 0) [46m{[22;9H}[1;35H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m387 [m    }[2;35H{[23;9H}[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[1;63H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[2;1H[93m    [m));[1;63H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m384 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m383 [m[7C fflush(stdout);[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[2;1H[93m    [m;[1;63H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m381 [m[8C word_count_actual / (real)[46m([miter * train_words + 1[46m)[m * 100,[1;63H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[2;40H([22C)[28;1H[94m@                                                                                        [1;63H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m379 [m[7C now=clock();[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m378 [m      if ((debug_mode > 1)) [46m{[8;11H}[1;33H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m377 [m      last_word_count = word_count;[2;33H{[9;11H}[1;39H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m376 [m      word_count_actual += word_count - last_word_count;[?12l[?25h[2;39H[?25l[3;33H[46m{[10;11H}[3;33H[?12l[?25h[?25l[m{[10;11H}[4;24H[?12l[?25h[5;63H[?25l[6;40H[46m([22C)[?12l[?25h[?25l[m[6;40H([22C)[7;63H[?12l[?25h[9;27H[?25l[3;33H[46m{[10;11H}[?12l[?25h[?25l[m[3;33H{[10;11H}[11;63H[?12l[?25h[13;63H[14;9H[15;35H[16;51H[17;37H[18;62H[19;37H[20;25H[21;63H[22;63H[24;29H[25;63H[27;63H[28;63H[?25l[1;28r[28;1H
[1;29r[23;29H[46m{[m[28;1H[93m400 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[22;29H{[27;13H}
[93m401 [m[7C sen[sentence_length] = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m402 [m[7C sentence_length++;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break; /* 389行目からの無限ループ [28;1H[93m    [mから脱出 */[27;63H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[10;21H[46m{[m[28;1H[93m404 [m      [46m}[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[8;21H{[26;11H}
[93m405 [m      sentence_position = 0;
[93m406 [m    }[27;32H[?12l[?25h[?25l[7;35H[46m{[28;9H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[6;35H{[27;9H}
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m408 [m      word_count_actual += word_count - last_word_count;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;[27;23H[?12l[?25h[28;37H[?25l[1;28r[28;1H
[1;29r[28;1H[93m411 [m      word_count = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m412 [m      last_word_count = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m413 [m      sentence_length = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;63H[?12l[?25h[27;30H[26;30H[25;25H[24;37H[23;23H[22;60H[21;63H[?25l[21;25H[46m([38C)[?12l[?25h[?25l[21;12H([m[12C([38C)[46m)[?12l[?25h[?25l[m[21;12H([52C)[?12l[?25h [?25l[1;28r[1;1H[2M[1;29r[19;67H[46m{[m[27;1H[93m415 [m      continue;
[93m416 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;67H{[27;9H}
[93m417 [m    word = sen[sentence_position];[28;9H[?12l[?25h[?25l[18;67H[46m{[27;9H}[?12l[?25h[?25l[m[18;67H{[27;9H}[26;9H[?12l[?25h[25;9H[24;9H[23;9H[22;9H[21;9H[20;9H[19;9H[18;9H[17;9H[16;9H[15;9H[16;9H[17;9H[18;9H[19;9H[20;9H[21;9H[22;9H[23;9H[24;9H[25;9H[26;9H[?25l[18;67H[46m{[27;9H}[?12l[?25h[?25l[m[18;67H{[27;9H}[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m418 [m    if (word == -1) continue;[28;9H[?12l[?25h[27;9H[?25l[17;67H[46m{[26;9H}[?12l[?25h[?25l[m[17;67H{[26;9H}[25;9H[?12l[?25h[24;9H[23;9H[22;9H[21;9H[20;9H[19;9H[18;9H[19;9H[20;9H[21;9H[20;9H[19;9H[18;9H[17;9H[18;9H[19;9H[20;9H[21;9H[22;9H[23;9H[24;9H[25;9H[?25l[17;67H[46m{[26;9H}[?12l[?25h[?25l[m[17;67H{[26;9H}[27;9H[?12l[?25h[28;9H[?25l[1;28r[28;1H
[1;29r[28;1H[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;[28;9H[?12l[?25h[27;9H[26;9H[?25l[16;67H[46m{[25;9H}[?12l[?25h[?25l[m[16;67H{[25;9H}[26;9H[?12l[?25h[27;9H[28;9H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[27;9H[?12l[?25h[26;9H[25;9H[24;9H[?25l[14;67H[46m{[23;9H}[?12l[?25h[?25l[m[14;67H{[23;9H}[22;9H[?12l[?25h[21;9H[20;9H[19;9H[18;9H[17;9H[16;9H[15;9H[14;9H[15;9H[16;9H[17;9H[18;9H[19;9H[20;9H[19;9H[18;9H[17;9H[16;9H[15;9H[14;9H[13;9H[12;9H[11;9H[9;9H[8;9H[7;9H[6;9H[5;9H[4;9H[2;9H[1;9H[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[2;1H[93m    [m same[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m393 [m[7C word_count++;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m392 [m[7C if (word == -1) continue;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m390 [m[7C word = ReadWordIndex(fi);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m389 [m      while (1) { /* 無限ループ(404行目まで) */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m388 [m    if (sentence_length == 0) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m387 [m    }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[1;9H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[2;1H[93m    [m));[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m384 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m383 [m[7C fflush(stdout);[1;9H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[2;1H[93m    [m;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[28;1H[94m@                                                                                        [1;9H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m379 [m[7C now=clock();[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m378 [m      if ((debug_mode > 1)) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m377 [m      last_word_count = word_count;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m376 [m      word_count_actual += word_count - last_word_count;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m375 [m    if (word_count - last_word_count > 10000) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m374 [m  while (1) { /* 無限ループ(538行目まで) */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;1H[94m@                                                                                        [1;9H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m372 [m  FILE *fi = fopen(train_file, "rb");[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));[28;1H[94m@                                                                                        [1;9H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m369 [m  clock_t now;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m368 [m  real f, g;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m367 [m  unsigned long long next_random = (long long)id;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m362 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m361 [m}[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m360 [m  CreateBinaryTree(); /* 198行目で定義したCreateBinaryTree()でHuffman木を生成 */[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m359 [m  }[28;1H[94m@                                                                                        [1;7H[?12l[?25h[2;9H[3;5H[4;5H[5;9H[6;9H[7;9H[8;9H[9;9H[10;9H[11;9H[12;9H[13;9H[14;9H[15;9H[16;9H[17;9H[18;9H[19;9H[20;9H[21;9H[22;9H[23;9H[24;9H[26;9H[27;9H[?25l[1;28r[m[28;1H
[1;29r[27;1H[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[28;1H[93m    [m));[27;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[14;51H[46m{[m[28;1H[93m387 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[13;51H{[27;9H}
[93m388 [m    if (sentence_length == 0) {[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m389 [m      while (1) { /* 無限ループ(404行目まで) */[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m390 [m[7C word = ReadWordIndex(fi);[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m392 [m[7C if (word == -1) continue;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m393 [m[7C word_count++;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */[28;9H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[28;1H[93m    [m same[27;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m396 [m[7C if (sample > 0) {[28;9H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [28;1H[93m    [mtrain_words) / vocab[word].cn;[27;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m400 [m[7C }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m401 [m[7C sen[sentence_length] = word;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m402 [m[7C sentence_length++;[28;9H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break; /* 389行目からの無限ループ [28;1H[93m    [mから脱出 */[27;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m404 [m      }[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m405 [m      sentence_position = 0;
[93m406 [m    }[27;9H[?12l[?25h[?25l[7;35H[46m{[28;9H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[6;35H{[27;9H}
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m408 [m      word_count_actual += word_count - last_word_count;[28;9H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m409 [m      local_iter--;
[93m410 [m      if (local_iter == 0) break;[27;9H[?12l[?25h[28;9H[?25l[1;28r[28;1H
[1;29r[28;1H[93m411 [m      word_count = 0;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m412 [m      last_word_count = 0;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m413 [m      sentence_length = 0;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m415 [m      continue;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[19;67H[46m{[m[28;1H[93m416 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;67H{[27;9H}
[93m417 [m    word = sen[sentence_position];[28;9H[?12l[?25h[?25l[18;67H[46m{[27;9H}[?12l[?25h[?25l[m[18;67H{[27;9H}[26;9H[?12l[?25h[25;9H[24;9H[23;9H[22;9H[21;9H  if[?25l [46m([15C)[21;14H[?12l[?25h[?25l[m([15C)[21;15H[?12l[?25hlocal_iter == [?25l[21;14H[46m([15C)[?12l[?25h[?25l[m[21;14H([15C)[?12l[?25h break[?25l[29;1H[1m-- INSERT --[21;38H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l ここで */[?12l[?25h[?25l3 */[?12l[?25h[?25l37 */[?12l[?25h[?25l74 */[?12l[?25h[?25l4行目 */[?12l[?25h[?25lからの */[?12l[?25h[?25l無限ループから */[?12l[?25h[?25l脱出 */[?12l[?25h[?25l！ */[?12l[?25h[29;1H[K[21;79H[?25l[?12l[?25h[22;25H[23;30H[24;30H[25;79H[26;19H[?25l[18;67H[46m{[27;9H}[?12l[?25h[?25l[m[18;67H{[27;9H}[28;38H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m418 [m    if (word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[27;55H[?12l[?25h[28;73H[?25l[1;28r[28;1H
[1;29r[28;1H[93m422 [m    b = next_random % window;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m423 [m    if (cbow) {  //train the cbow architecture
[93m424 [m      // in -> hidden[27;50H[?12l[?25h[28;25H[?25l[1;28r[28;1H
[1;29r[28;1H[93m425 [m      cw = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m427 [m[7C c = sentence_position - window + a;[?12l[?25h[27;69H[26;17H[25;25H[24;50H[23;33H[22;73H[21;55H[20;54H[19;33H[18;38H[?25l[8;67H[46m{[17;9H}[?12l[?25h[?25l[m[8;67H{[17;9H}[16;19H[?12l[?25h[15;79H[14;30H[13;30H[12;25H[11;79H[10;23H[9;60H[?25l[8;67H[46m{[17;9H}[8;67H[?12l[?25h[?25l[m{[17;9H}[7;9H[?12l[?25h[6;32H[5;11H[3;78H[2;30H[1;40H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m400 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [2;1H[93m    [mtrain_words) / vocab[word].cn;[1;79H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m396 [m[7C if (sample > 0) [46m{[6;13H}[1;29H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[2;1H[93m    [m same[3;29H{[8;13H}[1;79H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m393 [m[7C word_count++;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m392 [m[7C if (word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m390 [m[7C word = ReadWordIndex(fi);[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m389 [m      while (1) { /* 無限ループ(404行目まで) */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m388 [m    if (sentence_length == 0) [46m{[22;9H}[1;35H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m387 [m    }[2;35H{[23;9H}[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[2;1H[93m    [m));[1;79H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m384 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m383 [m[7C fflush(stdout);[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[2;1H[93m    [m;[1;79H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[28;1H[94m@                                                                                        [1;79H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m379 [m[7C now=clock();[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m378 [m      if ((debug_mode > 1)) [46m{[8;11H}[1;33H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m377 [m      last_word_count = word_count;[2;33H{[9;11H}[1;39H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m376 [m      word_count_actual += word_count - last_word_count;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m375 [m    if (word_count - last_word_count > 10000) [46m{[15;9H}[1;51H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m374 [m  while (1) { /* 無限ループ(538行目まで) */[2;51H{[16;9H}[1;47H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m373 [m  fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[28;1H[94m@                                                                                        [1;78H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m372 [m  FILE *fi = fopen(train_file, "rb");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m371 [m  real *neu1e = (real *)calloc(layer1_size, sizeof(real));[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m370 [m  real *neu1 = (real *)calloc(layer1_size, sizeof(real));[28;1H[94m@                                                                                        [1;61H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m369 [m  clock_t now;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m368 [m  real f, g;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m367 [m  unsigned long long next_random = (long long)id;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m366 [m  long long l1, l2, c, target, label, local_iter = iter;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m365 [m  long long word_count = 0, last_word_count = 0, sen[MAX_SENTENCE_LENGTH + 1];[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m364 [m  long long a, b, d, cw, word, last_word, sentence_length = 0, sentence_position = 0;[1;79H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m363 [mvoid *TrainModelThread(void *id) { /* 543行目まである */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m362 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m361 [m}[?12l[?25h[2;5H[3;60H[4;79H[5;79H[6;60H[7;53H[8;16H[9;18H[10;61H[11;62H[12;41H[13;78H[14;47H[15;51H[14;47H[13;78H[12;41H[11;62H[12;41H[13;78H[14;47H[15;51H[?25l[29;1H[1m-- INSERT --[15;52H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l w */[?12l[?25h[?25lwo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25ld_ */[?12l[?25h[?25l_c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25l  */[?12l[?25h[?25l - */[?12l[?25h[?25l  */[?12l[?25h[?25l l */[?12l[?25h[?25lla */[?12l[?25h[?25las */[?12l[?25h[?25lst */[?12l[?25h[?25lt_ */[?12l[?25h[?25l_w */[?12l[?25h[?25lwo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25ld_ */[?12l[?25h[?25l_c */[?12l[?25h[?25lco */[?12l[?25h[?25lou */[?12l[?25h[?25lun */[?12l[?25h[?25lnt */[?12l[?25h[?25ltが */[?12l[?25h[?25l1 */[15;87H[?12l[?25h[?25l[16;28r[16;1H[L[1;29r[15;86H10 **[16;1H[93m    [m/[15;88H[?12l[?25h[?25l00  [16;1H[93m    [m*/[15;89H[?12l[?25h[?25l0 **[16;1H[93m    [m/[16;6H[K[15;88H[?12l[?25h[?25l[15;28r[28;1H
[1;29r[15;1H[93m375 [m    if (word_count - last_word_count > 10000) { /* word_count - last_word_countが1 */[28;1H[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;[15;87H[?12l[?25h[?25l */[15;89H[K[15;86H[?12l[?25h[?25lt */[15;87H[K[15;84H[?12l[?25h[?25ln */[15;86H[K[15;83H[?12l[?25h[?25lu */[15;85H[K[15;82H[?12l[?25h[?25lo */[15;84H[K[15;81H[?12l[?25h[?25lc */[15;83H[K[15;80H[?12l[?25h[?25l_ */[15;82H[K[15;79H[?12l[?25h[?25ld */[15;81H[K[15;78H[?12l[?25h[?25lr */[15;80H[K[15;77H[?12l[?25h[?25lo */[15;79H[K[15;76H[?12l[?25h[?25lw */[15;78H[K[15;75H[?12l[?25h[?25l_ */[15;77H[K[15;74H[?12l[?25h[?25lt */[15;76H[K[15;73H[?12l[?25h[?25ls */[15;75H[K[15;72H[?12l[?25h[?25la */[15;74H[K[15;71H[?12l[?25h[?25ll */[15;73H[K[15;70H[?12l[?25h[?25l  */[15;72H[K[15;69H[?12l[?25h[?25l */[15;71H[K[15;68H[?12l[?25h[?25l  */[15;70H[K[15;67H[?12l[?25h[?25l */[15;69H[K[15;66H[?12l[?25h[?25ln */[15;68H[K[15;65H[?12l[?25h[?25lu */[15;67H[K[15;64H[?12l[?25h[?25lo */[15;66H[K[15;63H[?12l[?25h[?25lc */[15;65H[K[15;62H[?12l[?25h[?25l_ */[15;64H[K[15;61H[?12l[?25h[?25ld */[15;63H[K[15;60H[?12l[?25h[?25lr */[15;62H[K[15;59H[?12l[?25h[?25lo */[15;61H[K[15;58H[?12l[?25h[?25lw */[15;60H[K[15;57H[?12l[?25h[?25l  */[15;59H[K[15;56H[?12l[?25h[?25l */[15;58H[K[15;55H[?12l[?25h[?25l/ */[15;57H[K[15;54H[?12l[?25h[?25l  */[15;56H[K[15;53H[?12l[?25h */[?25l[15;55H[K[15;55H[?12l[?25h[?25l[15;54H[K[15;54H[?12l[?25h[?25l[?12l[?25h[?25l[?12l[?25h[16;52Hrd_coun[17;40H[?25l[18;33H[46m{[25;11H}[18;34H[?12l[?25h[?25l[m{[25;11H}[19;25H[?12l[?25h[?25l[18;33H[46m{[25;11H}[18;34H[?12l[?25h[?25l[m{[25;11H}[17;40H[?12l[?25h[16;59H[?25l[15;52H[?12l[?25h[?25l{[?12l[?25h[?25l %{[?12l[?25h[?25l {[15;52H[K[15;51H[?12l[?25h[29;1H[K[15;50H[?25l[?12l[?25h [?25l[1;28r[28;1H
[1;29r[14;51H[46m{[m[28;1H[93m387 [m    [46m}[?12l[?25h[?25l[14;51H[?12l[?25h[?25l[28;9H[?12l[?25h[?25l[14;51H[?12l[?25h[?25l[m[29;1H[1m-- INSERT --[14;52H[?12l[?25h[?25l[m{[28;9H}[14;53H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 3 */[?12l[?25h[?25l38 */[?12l[?25h[?25l87 */[?12l[?25h[?25l7行目 */[?12l[?25h[?25lまで */[?12l[?25h[15;61H[16;40H[?25l[17;33H[46m{[24;11H}[17;34H[?12l[?25h[m[29;1H[K[17;33H[?25l[?12l[?25h[?25l[29;1H[1m-- INSERT --[17;34H[?12l[?25h[?25l[m{[24;11H}[17;35H[?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l**[?12l[?25h[?25l [?12l[?25h[?25l[?12l[?25h[?25l[17;37H[K[17;37H[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 3 */[?12l[?25h[?25l38 */[?12l[?25h[?25l87 */[?12l[?25h[?25l8 */[17;43H[K[17;40H[?12l[?25h[?25l84 */[?12l[?25h[?25l4行目 */[?12l[?25h[?25lまで */[?12l[?25h[18;25H[19;49H[20;49H[21;49H[23;28H[?25l[17;33H[46m{[24;11H}[?12l[?25h[?25l[m[17;33H{[24;11H}[25;49H[?12l[?25h[27;49H[?25l[14;51H[46m{[28;9H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[13;51H{[27;9H}
[93m388 [m    if (sentence_length == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m389 [m      while (1) { /* 無限ループ[46m([m404行目まで[46m)[m */[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;36H([11C)
[93m390 [m[7C word = ReadWordIndex(fi);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */[28;48H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m392 [m[7C if (word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m393 [m[7C word_count++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */[28;49H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[28;1H[93m    [m same[27;49H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m396 [m[7C if (sample > 0) {[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m397 [m[9C real ran = (sqrt(vocab[word].cn / [46m([msample * train_words[46m)[m) + 1) * (sample *  [28;1H[93m    [mtrain_words) / vocab[word].cn;[27;49H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[26;49H([20C)[18C  [27;1H[93m 
398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;[28;49H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;[28;49H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[23;29H[46m{[m[28;1H[93m400 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[22;29H{[27;13H}
[93m401 [m[7C sen[sentence_length] = word;[?12l[?25h[?25l[22;29H[46m{[27;13H}[?12l[?25h[?25l[m[22;29H{[27;13H}[26;49H[?12l[?25h[25;49H[?25l[23;49H[46m([20C)[m[18C  [24;1H[93m [23;49H[?12l[?25h[?25l[m[22;29H[46m{[m[23;49H([20C)[18C  [24;1H[93m [m[27;13H[46m}[22;30H[?12l[?25h[?25l[m{[27;13H}[20;49H[?12l[?25h[19;49H[18;26H[17;38H[16;48H[15;38H[?25l[14;36H[46m([11C)[?12l[?25h[?25l[m[14;36H([11C)[13;36H[?12l[?25h[?25l[14;36H[46m([11C)[?12l[?25h[?25l[m[14;36H([11C)[15;38H[?12l[?25h[16;48H[17;36H[18;26H[19;36H[20;36H[?25l[53Cgg[21;1H[93m [m[22;29H[46m{[27;13H}[22;30H[?12l[?25h[?25l[m{[27;13H}[23;36H[?12l[?25h[25;36H[26;36H[?25l[22;29H[46m{[27;13H}[?12l[?25h[?25l[m[22;29H{[27;13H}[26;36H[?12l[?25h[25;36H[23;36H[?25l[22;29H[46m{[27;13H}[22;30H[?12l[?25h[?25l[m{[27;13H}[20;36H[?12l[?25h[19;36H[18;26H[17;36H[16;36H[?25l[15;33H[46m([mfi[46m)[?12l[?25h[m[29;1H[K[15;35H[?25l(fi)[?12l[?25h[?25l[29;1H/[?12l[?25hReadWordIndex[?25l[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m105 [m  while (1) { /* 無限ループ */
[93m106 [m    if (vocab_hash[hash] == -1) return -1; /* vocab_hash[hash]が-1の時-1を返す */
[93m107 [m    if (!strcmp(word, vocab[vocab_hash[hash]].word)) return vocab_hash[hash]; /* 文字[4;1H[93m    [m列wordとvocab[vocab_hash[hash]].wordが等しい時vocab_hash[hash]を返す */
[93m108 [m    hash = (hash + 1) % vocab_hash_size; /* hashに(hash + 1) % vocab_hash_sizeを返す  [6;1H[93m    [m*/
[93m109 [m  }
[93m110 [m  return -1;
[93m111 [m}
[93m112 
113 [m// Reads a word and returns its index in the vocabulary /* 単語を読取り，語彙中での単 [12;1H[93m    [m語の番号を返す */
[93m114 [mint ReadWordIndex(FILE *fin) { /* ファイルポインタfinを引数に持つint型関数ReadWordIndd[14;1H[93m    [mex() */
[93m115 [m  char word[MAX_STRING]; /* MAX_STRINGを引数に持つchar型wordを宣言 */
[93m116 [m  ReadWord(word, fin); /* 先程定義したReadWordをchar型ポインタwordとファイルポインタff[17;1H[93m    [minを引数に計算 */
[93m117 [m  if (feof(fin)) return -1; /* ファイルポインタが終端に達した時-1を返す */
[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[24;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字 [26;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[28;1H[93m    [mlenghに最大文字数を代入 */
[38;5;224msearch hit BOTTOM, continuing at TOP[13;9H[?12l[?25h[?25l[m[29;1H/ReadWordIndex[29;15H[K[29;1H[13;79H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m379 [m[7C now=clock();
[93m380 [m[7C printf("%cAlpha: %f  Progress: %.2f%%  Words/thread/sec: %.2fk  ", 13, alpha,[3;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[5;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[9;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;
[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) { /* 無限ループ(404行目まで) */
[93m390 [m[7C word = ReadWordIndex(fi);
[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */
[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[20;1H[93m    [m same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [23;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;[14;20H[?12l[?25hReadWordInde[?25lx[46m([mfi[46m)[?12l[?25h[?25l[m(fi)[?12l[?25hf[?25l[46m([mfi[46m)[?12l[?25h[?25l[m(fi)[?12l[?25h[?25l[29;1H[1m-- INSERT --[14;38H[?12l[?25h[?25l[m [?12l[?25h[?25l /* 単語を読取り，語彙中での単    語[?12l[?25h[?25lの番号を返す */[?12l[?25h[?25l 語の番号を返す */[14;88H[K[14;71H[?12l[?25h[?25l 語の番号を返す */[14;87H[K[14;70H[?12l[?25h[?25l 語の番号を返す */[14;86H[K[14;69H[?12l[?25h[?25l語の番号を返す */[14;85H[K[14;68H[?12l[?25h[?25l 1単語を読取り，語彙中での単語の番号を返す */[14;43H[?12l[?25h[?25l11単語を読取り，語彙中での単語の番号を返す */[14;44H[?12l[?25h[?25l11単語を読取り，語彙中での単語の番号を返す */[14;45H[?12l[?25h[?25l1単語を読取り，語彙中での単語の番号を返す */[14;87H[K[14;44H[?12l[?25h[?25l14単語を読取り，語彙中での単語の番号を返す */[14;45H[?12l[?25h[?25l[15;28r[15;1H[L[1;29r[14;44H4行目単語を読取り，語彙中での単語の番号を返す  [15;1H[93m    [m*/[14;49H[?12l[?25h[?25lで単語を読取り，語彙中での単語の番号を返[94m>>[m[15;1H[93m    [mす */[14;51H[?12l[?25h[?25l定義単語を読取り，語彙中での単語の番号[94m>>[m[15;1H[93m [m[3Cを返す */[14;55H[?12l[?25h[?25lの単語を読取り，語彙中での単語の番[94m>>[m[15;1H[93m    [m号を返す */[14;57H[?12l[?25h[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[15;5H[2C[2C[2C[2C[2C[?25lR */[?12l[?25h[?25lRe */[?12l[?25h[?25lea */[?12l[?25h[?25lad */[?12l[?25h[?25ldW */[?12l[?25h[?25lWo */[?12l[?25h[?25lor */[?12l[?25h[?25lrd */[?12l[?25h[?25ldI */[?12l[?25h[?25lIn */[?12l[?25h[?25lnd */[?12l[?25h[?25lde */[?12l[?25h[?25lex */[?12l[?25h[16;71H[?25l[16;16H[46m([8C)[?12l[?25h[m[29;1H[K[16;25H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hfeof(fi[?25l[1;28r[1;1H[7M[1;29r[9;16H([8C)[22;1H[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break; /* 389行目からの無限ループ [24;1H[93m    [mから脱出 */
[93m404 [m      }
[93m405 [m      sentence_position = 0;
[93m406 [m    }
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {[29;1H[K[28;13H[?12l[?25h[?25l
?feof(fi[9;17H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m307 [m  long long a, i = 0;
[93m308 [m  char c;
[93m309 [m  char word[MAX_STRING];
[93m310 [m  FILE *fin = fopen(read_vocab_file, "rb"); /* 読込モードでread_vocab_fileを開く */
[93m311 [m  if (fin == NULL) {
[93m312 [m    printf("Vocabulary file not found\n");
[93m313 [m    exit(1);
[93m314 [m  }
[93m315 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1; /* 0 <= a < vocab_hash_sii[10;1H[93m    [mzeの時 */
[93m316 [m  vocab_size = 0;
[93m317 [m  while (1) { /* 無限ループ */
[93m318 [m    ReadWord(word, fin); /* 72行目で定義したReadWord関数 */
[93m319 [m    if (feof(fin)) break; /* ファイルポインタが終端に達した時無限ループから脱出 */
[93m320 [m    a = AddWordToVocab(word); /* 単語を語彙に加える関数AddWordToVocab */
[93m321 [m    fscanf(fin, "%lld%c", &vocab[a].cn, &c); /* ファイルポインタfinから読出した値をvoo[17;1H[93m    [mcab[a].cnに取込み， */
[93m322 [m    i++;
[93m323 [m  }
[93m324 [m  SortVocab();
[93m325 [m  if (debug_mode > 0) {
[93m326 [m    printf("Vocab size: %lld\n", vocab_size);
[93m327 [m    printf("Words in train file: %lld\n", train_words);
[93m328 [m  }
[93m329 [m  fin = fopen(train_file, "rb"); /* 読取モードでtrain_fileを開く */
[93m330 [m  if (fin == NULL) {
[93m331 [m    printf("ERROR: training data file not found!\n");
[93m332 [m    exit(1);[14;13H[?12l[?25h[?25l[29;1H/feof(fi[27m[m[H[2J[1;1H[93m381 [m[8C word_count_actual / (real)(iter * train_words + 1) * 100,
[93m382 [m[8C word_count_actual / ((real)(now - start + 1) / (real)CLOCKS_PER_SEC * 1000)))[3;1H[93m    [m;
[93m383 [m[7C fflush(stdout);
[93m384 [m      }
[93m385 [m      alpha = starting_alpha * (1 - word_count_actual / (real)(iter * train_words + 11[7;1H[93m    [m));
[93m386 [m      if (alpha < starting_alpha * 0.0001) alpha = starting_alpha * 0.0001;
[93m387 [m    }
[93m388 [m    if (sentence_length == 0) {
[93m389 [m      while (1) { /* 無限ループ(404行目まで) */
[93m390 [m[7C word = ReadWordIndex(fi); /* 114行目で定義の単語を読取り，語彙中での単語の番[94m>>[m[13;1H[93m    [m号を返すReadWordIndex */
[93m391 [m[7C if (feof(fi)) break; /* 389行目からの無限ループから脱出 */
[93m392 [m[7C if (word == -1) continue;
[93m393 [m[7C word_count++;
[93m394 [m[7C if (word == 0) break; /* 389行目からの無限ループから脱出 */
[93m395 [m[7C // The subsampling randomly discards frequent words while keeping the rankingg[19;1H[93m    [m same
[93m396 [m[7C if (sample > 0) {
[93m397 [m[9C real ran = (sqrt(vocab[word].cn / (sample * train_words)) + 1) * (sample *  [22;1H[93m    [mtrain_words) / vocab[word].cn;
[93m398 [m[9C next_random = next_random * (unsigned long long)25214903917 + 11;
[93m399 [m[9C if (ran < (next_random & 0xFFFF) / (real)65536) continue;
[93m400 [m[7C }
[93m401 [m[7C sen[sentence_length] = word;
[93m402 [m[7C sentence_length++;
[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break; /* 389行目からの無限ループ[28;1H[94m@                                                                                        [14;17H[?12l[?25h[mfeo[?25lf[46m([mfi[46m)[?12l[?25h[?25l[m(fi)[?12l[?25hf[?25l[46m([mfi[46m)[?12l[?25h[?25l[14;16H([mfeof(fi)[46m)[?12l[?25h[?25l[m[14;16H([8C)[?12l[?25h break; /* [?25l[29;1H[1m-- INSERT --[14;38H[?12l[?25h[?25l[15;28r[m[15;1H[L[1;29r[14;36H ファイルポインタが終端に達した時389行目からの無限ルー[15;1H[93m    [mプから脱出 */[14;69H[?12l[?25h[16;38H[17;26H[18;69H[19;69H[?25l[20Cgg[20;1H[93m [m[21;29H[46m{[26;13H}[21;30H[?12l[?25h[?25l[m{[26;13H}[22;69H[?12l[?25h[24;69H[25;69H[?25l[21;29H[46m{[26;13H}[?12l[?25h[?25l[m[21;29H{[26;13H}[27;41H[?12l[?25h[28;31H[?25l[1;28r[1;1H[3M[1;29r[26;1H[93m403 [m[7C if (sentence_length >= MAX_SENTENCE_LENGTH) break; /* 389行目からの無限ループ[27;1H[93m    [mから脱出 */
[93m404 [m      }[26;69H[?12l[?25h[?25l[8;21H[46m{[28;11H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[7;21H{[27;11H}
[93m405 [m      sentence_position = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[5;35H[46m{[m[28;1H[93m406 [m    [46m}[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[3;35H{[26;9H}
[93m407 [m    if (feof(fi) || (word_count > train_words / num_threads)) {
[93m408 [m      word_count_actual += word_count - last_word_count;[27;68H[?12l[?25h[28;61H[?25l[1;28r[28;1H
[1;29r[28;1H[93m409 [m      local_iter--;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m410 [m      if (local_iter == 0) break; /* ここで374行目からの無限ループから脱出！ */[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m411 [m      word_count = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m412 [m      last_word_count = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m413 [m      sentence_length = 0;
[93m414 [m      fseek(fi, file_size / (long long)num_threads * (long long)id, SEEK_SET);[27;31H[?12l[?25h[?25l[28;58H[46m([9C)[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[26;58H([9C)
[93m415 [m      continue;
[93m416 [m    }[27;20H[?12l[?25h[?25l[19;67H[46m{[28;9H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;67H{[27;9H}
[93m417 [m    word = sen[sentence_position];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m418 [m    if (word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m419 [m    for (c = 0; c < layer1_size; c++) neu1[c] = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m420 [m    for (c = 0; c < layer1_size; c++) neu1e[c] = 0;
[93m421 [m    next_random = next_random * (unsigned long long)25214903917 + 11;[27;56H[?12l[?25h[28;69H[?25l[1;28r[28;1H
[1;29r[28;1H[93m422 [m    b = next_random % window;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m423 [m    if (cbow) {  //train the cbow architecture
[93m424 [m      // in -> hidden[27;51H[?12l[?25h[28;26H[?25l[1;28r[28;1H
[1;29r[28;1H[93m425 [m      cw = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m426 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m427 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m428 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m429 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m430 [m[7C last_word = sen[c];
[93m431 [m[7C if (last_word == -1) continue;[27;32H[?12l[?25h[28;43H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m432 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] += syn0[c + last_word * layer1_sizee[28;1H[93m    [m];[27;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m433 [m[7C cw++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[19;69H[46m{[m[28;1H[93m434 [m      [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[18;69H{[27;11H}
[93m435 [m      if (cw) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m436 [m[7C for (c = 0; c < layer1_size; c++) neu1[c] /= cw;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m437 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m438 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m439 [m[9C l2 = vocab[word].point[d] * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m440 [m[9C // Propagate hidden -> output[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m441 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1[46m[[mc + l2[46m][m;[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;68H[c + l2]
[93m442 [m[9C if (f <= -MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m443 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m444 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m445 [m[9C // 'g' is the gradient multiplied by the learning rate[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m446 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m447 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m448 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[46m[[mc + l2[46m][m;[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;69H[c + l2]
[93m449 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m450 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * neu1[c];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[14;63H[46m{[m[28;1H[93m451 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[13;63H{[27;13H}
[93m452 [m[7C // NEGATIVE SAMPLING[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m453 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m454 [m[9C if (d == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m455 [m[11C target = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m456 [m[11C label = 1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m457 [m[9C } else {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m458 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[28;69H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m459 [m[11C target = table[(next_random >> 16) % table_size];
[93m460 [m[11C if (target == 0) target = next_random % (vocab_size - 1) + 1;[27;66H[?12l[?25h[28;69H[?25l[1;28r[28;1H
[1;29r[28;1H[93m461 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m462 [m[11C label = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;22H[46m{[m[28;1H[93m463 [m[9C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;22H{[27;15H}
[93m464 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m465 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m466 [m[9C for (c = 0; c < layer1_size; c++) f += neu1[c] * syn1neg[c + l2];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m467 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m468 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m469 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [28;1H[93m    [m/ 2))]) * alpha;[27;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m470 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m471 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * neu1[c];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[8;66H[46m{[m[28;1H[93m472 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[7;66H{[27;13H}
[93m473 [m[7C // hidden -> in[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m474 [m[7C for (a = b; a < window * 2 + 1 - b; a++) if [46m([ma != window[46m)[m {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;57H([11C)
[93m475 [m[9C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m476 [m[9C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m477 [m[9C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m478 [m[9C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m479 [m[9C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m480 [m[9C for (c = 0; c < layer1_size; c++) syn0[c + last_word * layer1_size] += neu11[28;1H[93m    [me[c];[27;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[20;71H[46m{[m[28;1H[93m481 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[19;71H{[27;13H}
[93m482 [m      }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m483 [m    } else {  //train skip-gram[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m484 [m      for (a = b; a < window * 2 + 1 - b; a++) if (a != window) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m485 [m[7C c = sentence_position - window + a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m486 [m[7C if (c < 0) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m487 [m[7C if (c >= sentence_length) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m488 [m[7C last_word = sen[c];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m489 [m[7C if (last_word == -1) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m490 [m[7C l1 = last_word * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m491 [m[7C for (c = 0; c < layer1_size; c++) neu1e[c] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m492 [m[7C // HIERARCHICAL SOFTMAX[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m493 [m[7C if (hs) for (d = 0; d < vocab[word].codelen; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m494 [m[9C f = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m495 [m[9C l2 = vocab[word].point[d] * layer1_size;
[93m496 [m[9C // Propagate hidden -> output[27;55H[?12l[?25h[28;44H[?25l[1;28r[28;1H
[1;29r[28;1H[93m497 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1[c + l2];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m498 [m[9C if (f <= -MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m499 [m[9C else if (f >= MAX_EXP) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m500 [m[9C else f = expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP / 2))];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m501 [m[9C // 'g' is the gradient multiplied by the learning rate[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m502 [m[9C g = (1 - vocab[word].code[d] - f) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m503 [m[9C // Propagate errors output -> hidden[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m504 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1[46m[[mc + l2[46m][m;[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;69H[c + l2]
[93m505 [m[9C // Learn weights hidden -> output[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m506 [m[9C for (c = 0; c < layer1_size; c++) syn1[c + l2] += g * syn0[c + l1];[28;69H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[13;63H[46m{[m[27;1H[93m507 [m[7C [46m}[m
[93m508 [m[7C // NEGATIVE SAMPLING[27;14H[?12l[?25h[?25l[13;63H{[27;13H}[28;33H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m509 [m[7C if (negative > 0) for (d = 0; d < negative + 1; d++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m510 [m[9C if (d == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m511 [m[11C target = word;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m512 [m[11C label = 1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m513 [m[9C } else {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m514 [m[11C next_random = next_random * (unsigned long long)25214903917 + 11;[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m515 [m[11C target = table[(next_random >> 16) % table_size];[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m516 [m[11C if (target == 0) target = next_random % (vocab_size - 1) + 1;[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m517 [m[11C if (target == word) continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m518 [m[11C label = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;22H[46m{[m[28;1H[93m519 [m[9C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[21;22H{[27;15H}
[93m520 [m[9C l2 = target * layer1_size;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m521 [m[9C f = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m522 [m[9C for (c = 0; c < layer1_size; c++) f += syn0[c + l1] * syn1neg[c + l2];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m523 [m[9C if (f > MAX_EXP) g = (label - 1) * alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m524 [m[9C else if (f < -MAX_EXP) g = (label - 0) * alpha;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m525 [m[9C else g = (label - expTable[(int)((f + MAX_EXP) * (EXP_TABLE_SIZE / MAX_EXP  [28;1H[93m    [m/ 2))]) * alpha;[27;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m526 [m[9C for (c = 0; c < layer1_size; c++) neu1e[c] += g * syn1neg[c + l2];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m527 [m[9C for (c = 0; c < layer1_size; c++) syn1neg[c + l2] += g * syn0[c + l1];[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[8;66H[46m{[m[28;1H[93m528 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[7;66H{[27;13H}
[93m529 [m[7C // Learn weights input -> hidden[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m530 [m[7C for (c = 0; c < layer1_size; c++) syn0[c + l1] += neu1e[46m[[mc[46m][m;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;68H[c]
[93m531 [m      }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m532 [m    }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m533 [m    sentence_position++;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m534 [m    if (sentence_position >= sentence_length) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m535 [m      sentence_length = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m536 [m      continue;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;51H[46m{[m


[93m537 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[24;51H{[27;9H}
[93m538 [m  }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m539 [m  fclose(fi);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m540 [m  free(neu1);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m541 [m  free(neu1e);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m542 [m  pthread_exit(NULL);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m543 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m544 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m545 [mvoid TrainModel() {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m546 [m  long a, b, c, d;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m547 [m  FILE *fo;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));[28;69H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m549 [m  printf("Starting training using file %s\n", train_file);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m550 [m  starting_alpha = alpha;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();[28;69H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m552 [m  if (save_vocab_file[0] != 0) SaveVocab();
[93m553 [m  if (output_file[0] == 0) return;[27;48H[?12l[?25h[28;39H[?25l[1;28r[28;1H
[1;29r[28;1H[93m554 [m  InitNet();[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m555 [m  if (negative > 0) InitUnigramTable();[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m556 [m  start = clock();[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m557 [m  for (a = 0; a < num_threads; a++) pthread_create(&pt[a], NULL, TrainModelThread, (vv[28;1H[93m    [moid *)a);[27;69H[?12l[?25h[26;23H[25;44H[24;17H[23;39H[22;48H[21;69H[20;30H[19;63H[18;69H[17;16H[16;23H[?25l[15;24H[?12l[?25h[29;1H[K[15;23H[?25l[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  }
[93m613 [m  fclose(fo);
[93m614 [m}
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) {[14;5H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() [46m{[m
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();
[93m552 [m  if (save_vocab_file[0] != 0) SaveVocab();
[93m553 [m  if (output_file[0] == 0) return;
[93m554 [m  InitNet();
[93m555 [m  if (negative > 0) InitUnigramTable();
[93m556 [m  start = clock();
[93m557 [m  for (a = 0; a < num_threads; a++) pthread_create(&pt[a], NULL, TrainModelThread, (vv[27;1H[93m    [moid *)a);
[93m558 [m  for (a = 0; a < num_threads; a++) pthread_join(pt[a], NULL);[14;23H[?12l[?25h[?25l[29;1H[1m-- INSERT --[m[14;23H{[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 6 */[?12l[?25h[?25l61 */[?12l[?25h[?25l14 */[?12l[?25h[?25l4行目 */[?12l[?25h[?25lまで */[?12l[?25h[15;23H[16;16H[17;39H[18;39H[19;30H[20;39H[21;39H[22;39H[23;17H[24;39H[25;23H[?25l[26;11H[46m([27C)[m[49Cvv[27;1H[93m [26;39H[?12l[?25h[?25l[m[26;11H([27C)[49Cvv[27;1H[93m [m[28;11H[46m([27C)[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;11H([27C)
[93m559 [m  fo = fopen(output_file, "wb");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m560 [m  if (classes == 0) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m561 [m    // Save the word vectors[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m562 [m    fprintf(fo, "%lld %lld\n", vocab_size, layer1_size);[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m563 [m    for (a = 0; a < vocab_size; a++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m564 [m      fprintf(fo, "%s ", vocab[a].word);[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m565 [m      if (binary) for (b = 0; b < layer1_size; b++) fwrite(&syn0[a * layer1_size + b]][28;1H[93m    [m, sizeof(real), 1, fo);[27;39H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m566 [m      else for (b = 0; b < layer1_size; b++) fprintf(fo, "%lf ", syn0[a * layer1_sizee[28;1H[93m    [m + b]);[27;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m567 [m      fprintf(fo, "\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[21;42H[46m{[m[28;1H[93m568 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[20;42H{[27;9H}
[93m569 [m  } else {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m570 [m    // Run K-means on the word vectors[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m571 [m    int clcn = classes, iter = 10, closeid;[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int));[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m574 [m    real closev, x;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m577 [m    for (a = 0; a < iter; a++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m580 [m      for (c = 0; c < vocab_size; c++) {[?12l[?25h[?25l[1;28r[1;1H[3M[1;29r[26;1H[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[27;1H[93m    [mayer1_size + d];
[93m582 [m[7C centcn[cl[c]]++;[26;39H[?12l[?25h[28;29H[?25l[1;28r[28;1H
[1;29r[24;44H[46m{[m[28;1H[93m583 [m      [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[23;44H{[27;11H}
[93m584 [m      for (b = 0; b < clcn; b++) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m585 [m[7C closev = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m586 [m[7C for (c = 0; c < layer1_size; c++) {[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m587 [m[9C cent[46m[[mlayer1_size * b + c[46m][m /= centcn[b];[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;19H[[19C]
[93m588 [m[9C closev += cent[layer1_size * b + c] * cent[layer1_size * b + c];[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;47H[46m{[m


[93m589 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[23;47H{[26;13H}
[93m590 [m[7C closev = sqrt(closev);
[93m591 [m[7C for (c = 0; c < layer1_size; c++) cent[layer1_size * b + c] /= closev;[27;35H[?12l[?25h[28;39H[?25l[1;28r[1;1H[2M[1;29r[19;38H[46m{[m[27;1H[93m592 [m      [46m}[m
[93m593 [m      for (c = 0; c < vocab_size; c++) {[27;12H[?12l[?25h[?25l[19;38H{[27;11H}[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m594 [m[7C closev = -10;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m595 [m[7C closeid = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m596 [m[7C for [46m([md = 0; d < clcn; d++[46m)[m {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;17H([20C)
[93m597 [m[9C x = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m598 [m[9C for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[28;1H[93m    [m layer1_size + b];[27;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m599 [m[9C if (x > closev) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m600 [m[11C closev = x;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m601 [m[11C closeid = d;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;31H[46m{[m


[93m602 [m[9C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[20;40H[46m{[m[24;31H{[27;15H}
[93m603 [m[7C [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[19;40H{[27;13H}
[93m604 [m[7C cl[c] = closeid;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[15;44H[46m{[m[28;1H[93m605 [m      [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[14;44H{[27;11H}
[93m606 [m    }[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);[27;36H[?12l[?25h[28;39H[?25l[1;28r[28;1H
[1;29r[28;1H[93m609 [m    free(centcn);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m610 [m    free(cent);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m611 [m    free(cl);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m612 [m  }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m613 [m  fclose(fo);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m614 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m615 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m616 [mint ArgPos(char *str, int argc, char **argv) {[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m617 [m  int a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m619 [m    if (a == argc - 1) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m620 [m      printf("Argument missing for %s\n", str);[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m621 [m      exit(1);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[25;28H[46m{[m


[93m622 [m    [46m}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[24;28H{[27;9H}
[93m623 [m    return a;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[22;61H[46m{[m[28;1H[93m624 [m  [46m}[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[20;61H{[26;7H}
[93m625 [m  return -1;
[93m626 [m}[27;17H[?12l[?25h[?25l[18;50H[46m{[28;5H}[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[17;50H{[27;5H}
[93m627 [?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[28;1H[93m628 [mint main(int argc, char **argv) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m629 [m  int i;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m630 [m  if (argc == 1) {[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m631 [m    printf("WORD VECTOR estimation toolkit v 0.1c\n\n");[28;39H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m632 [m    printf("Options:\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m633 [m    printf("Parameters for training:\n");[28;39H[?12l[?25h[27;30H[26;39H[?25l[25;23H[?12l[?25h[24;13H[?25l[23;38H[?12l[?25h[22;5H[?25l[11;50H[46m{[21;5H}[?12l[?25h[?25l[m[11;50H{[21;5H}[20;17H[?12l[?25h[?25l[13;61H[46m{[19;7H}[?12l[?25h[?25l[m[13;61H{[19;7H}[18;18H[?12l[?25h[?25l[14;28H[46m{[17;9H}[?12l[?25h[?25l[m[14;28H{[17;9H}[16;19H[?12l[?25h[15;39H[?25l[14;28H[46m{[17;9H}[14;29H[?12l[?25h[?25l[m{[17;9H}[13;39H[?12l[?25h[12;13H[11;39H[10;5H[11;39H[12;13H[13;39H[?25l[14;28H[46m{[17;9H}[14;29H[?12l[?25h[?25l[m{[17;9H}[15;39H[?12l[?25h[16;19H[?25l[14;28H[46m{[17;9H}[?12l[?25h[?25l[m[14;28H{[17;9H}[18;18H[?12l[?25h[29;1H[K[18;17H[?25l[?12l[?25h[?25l[13;61H[46m{[19;7H}[?12l[?25h[?25l[m[13;61H{[19;7H}[20;16H[?12l[?25h[?25l[11;50H[46m{[21;5H}[?12l[?25h[?25l[m[11;50H{[21;5H}[22;5H[?12l[?25h[23;17H[?25l[27m[m[H[2J[1;1H[93m682 [m  if ((i = ArgPos((char *)"-cbow", argc, argv)) > 0) cbow = atoi(argv[i + 1]);
[93m683 [m  if (cbow) alpha = 0.05;
[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);
[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[5;1H[93m    [m]);
[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);
[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);
[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argv[i + 1]))[10;1H[93m    [m;
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 11[12;1H[93m    [m]);
[93m691 [m  if ((i = ArgPos((char *)"-iter", argc, argv)) > 0) iter = atoi(argv[i + 1]);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 11[15;1H[93m    [m]);
[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[i + 1]);
[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word));
[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));
[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {
[93m698 [m    expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precompute thh[22;1H[93m    [me exp() table
[93m699 [m    expTable[i] = expTable[i] / (expTable[i] + 1);[18C // Precompute f(([24;1H[93m    [mx) = x / (x + 1)
[93m700 [m  }
[93m701 [m  TrainModel();
[93m702 [m  return 0;
[93m703 [m}[?12l[?25h[?25l
:[?12l[?25h614[?25l[27m[m[H[2J[1;1H[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  }
[93m613 [m  fclose(fo);
[93m614 [m}
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) {[14;5H[?12l[?25h[?25l[29;1H/feof(fi[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries  [10;1H[93m    [m/* ファイルから1単語読込み，スペース・タブ・行末を単語の切れ目と見なす */
[93m 72 [mvoid ReadWord(char *word, FILE *fin) { /* char型ポインタwordとファイルポインタfinが引 [12;1H[93m    [m数のvoid型関数ReadWord() */
[93m 73 [m  int a = 0, ch; /* int型aとch */
[93m 74 [m  while (!feof(fin)) { /* ファイルポインタfinがファイルの終端に達した時にループ終了 **[15;1H[93m    [m/
[93m 75 [m    ch = fgetc(fin); /* ファイルポインタfinから1文字読込んでint型で返す */
[93m 76 [m    if (ch == 13) continue;
[93m 77 [m    if ((ch == ' ') || (ch == '\t') || (ch == '\n')) {/* 空白・タブ・改行がある場合 **[19;1H[93m    [m/
[93m 78 [m      if (a > 0) { /* 最初は条件を満たさない */
[93m 79 [m[7C if (ch == '\n') ungetc(ch, fin); /* ファイルポインタfinに1文字返却しchを返す  [22;1H[93m    [m*/
[93m 80 [m[7C break;
[93m 81 [m      }
[93m 82 [m      if (ch == '\n') { /* 改行がある場合 */
[93m 83 [m[7C strcpy(word, (char *)"</s>"); /* 配列wordに文字列"</s>"をコピー */
[93m 84 [m[7C return;
[93m 85 [m      } else continue;
[38;5;224msearch hit BOTTOM, continuing at TOP[14;15H[?12l[?25h[?25l[m[29;1H[K[29;1H:[?12l[?25h614[?25l[27m[m[H[2J[1;1H[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  }
[93m613 [m  fclose(fo);
[93m614 [m}
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) {[14;5H[?12l[?25h[15;5H[16;5H[17;5H[18;5H[19;5H[20;5H[21;5H[22;5H[23;5H[24;5H[25;5H[?25l[16;50H[46m{[26;5H}[?12l[?25h[?25l[m[16;50H{[26;5H}[27;5H[?12l[?25h[28;5H[32C[?25l[27m[m[H[2J[1;1H[93m682 [m  if ((i = ArgPos((char *)"-cbow", argc, argv)) > 0) cbow = atoi(argv[i + 1]);
[93m683 [m  if (cbow) alpha = 0.05;
[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);
[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[5;1H[93m    [m]);
[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);
[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);
[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argv[i + 1]))[10;1H[93m    [m;
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 11[12;1H[93m    [m]);
[93m691 [m  if ((i = ArgPos((char *)"-iter", argc, argv)) > 0) iter = atoi(argv[i + 1]);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 11[15;1H[93m    [m]);
[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[i + 1]);
[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word));
[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));
[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {
[93m698 [m    expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precompute thh[22;1H[93m    [me exp() table
[93m699 [m    expTable[i] = expTable[i] / (expTable[i] + 1);[18C // Precompute f(([24;1H[93m    [mx) = x / (x + 1)
[93m700 [m  }
[93m701 [m  TrainModel();
[93m702 [m  return 0;
[93m703 [m}[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) [46m{[m
[93m629 [m  int i;
[93m630 [m  if (argc == 1) {
[93m631 [m    printf("WORD VECTOR estimation toolkit v 0.1c\n\n");
[93m632 [m    printf("Options:\n");
[93m633 [m    printf("Parameters for training:\n");
[93m634 [m    printf("\t-train <file>\n");
[93m635 [m    printf("\t\tUse text data from <file> to train the model\n");
[93m636 [m    printf("\t-output <file>\n");
[93m637 [m    printf("\t\tUse <file> to save the resulting word vectors / word clusters\n");
[93m638 [m    printf("\t-size <int>\n");
[93m639 [m    printf("\t\tSet size of word vectors; default is 100\n");
[93m640 [m    printf("\t-window <int>\n");
[93m641 [m    printf("\t\tSet max skip length between words; default is 5\n");
[93m642 [m    printf("\t-sample <float>\n");[14;37H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m682 [m  if ((i = ArgPos((char *)"-cbow", argc, argv)) > 0) cbow = atoi(argv[i + 1]);
[93m683 [m  if (cbow) alpha = 0.05;
[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);
[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[5;1H[93m    [m]);
[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);
[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);
[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argv[i + 1]))[10;1H[93m    [m;
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 11[12;1H[93m    [m]);
[93m691 [m  if ((i = ArgPos((char *)"-iter", argc, argv)) > 0) iter = atoi(argv[i + 1]);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 11[15;1H[93m    [m]);
[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[i + 1]);
[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word));
[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));
[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {
[93m698 [m    expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precompute thh[22;1H[93m    [me exp() table
[93m699 [m    expTable[i] = expTable[i] / (expTable[i] + 1);[18C // Precompute f(([24;1H[93m    [mx) = x / (x + 1)
[93m700 [m  }
[93m701 [m  TrainModel();
[93m702 [m  return 0;
[93m703 [m}[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) [46m{[m
[93m629 [m  int i;
[93m630 [m  if (argc == 1) {
[93m631 [m    printf("WORD VECTOR estimation toolkit v 0.1c\n\n");
[93m632 [m    printf("Options:\n");
[93m633 [m    printf("Parameters for training:\n");
[93m634 [m    printf("\t-train <file>\n");
[93m635 [m    printf("\t\tUse text data from <file> to train the model\n");
[93m636 [m    printf("\t-output <file>\n");
[93m637 [m    printf("\t\tUse <file> to save the resulting word vectors / word clusters\n");
[93m638 [m    printf("\t-size <int>\n");
[93m639 [m    printf("\t\tSet size of word vectors; default is 100\n");
[93m640 [m    printf("\t-window <int>\n");
[93m641 [m    printf("\t\tSet max skip length between words; default is 5\n");
[93m642 [m    printf("\t-sample <float>\n");[14;37H[?12l[?25h[?25l[29;1H[1m-- INSERT --[m[14;37H{[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 7 */[?12l[?25h[?25l70 */[?12l[?25h[?25l03 */[?12l[?25h[?25l3行目 */[?12l[?25h[?25lまで */[?12l[?25h[29;1H[K[14;51H[?25l[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m682 [m  if ((i = ArgPos((char *)"-cbow", argc, argv)) > 0) cbow = atoi(argv[i + 1]);
[93m683 [m  if (cbow) alpha = 0.05;
[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);
[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[5;1H[93m    [m]);
[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);
[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);
[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argv[i + 1]))[10;1H[93m    [m;
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 11[12;1H[93m    [m]);
[93m691 [m  if ((i = ArgPos((char *)"-iter", argc, argv)) > 0) iter = atoi(argv[i + 1]);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 11[15;1H[93m    [m]);
[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[i + 1]);
[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word));
[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));
[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {
[93m698 [m    expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precompute thh[22;1H[93m    [me exp() table
[93m699 [m    expTable[i] = expTable[i] / (expTable[i] + 1);[18C // Precompute f(([24;1H[93m    [mx) = x / (x + 1)
[93m700 [m  }
[93m701 [m  TrainModel();
[93m702 [m  return 0;
[93m703 [m}[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) [46m{[m /* 703行目まで */
[93m629 [m  int i;
[93m630 [m  if (argc == 1) {
[93m631 [m    printf("WORD VECTOR estimation toolkit v 0.1c\n\n");
[93m632 [m    printf("Options:\n");
[93m633 [m    printf("Parameters for training:\n");
[93m634 [m    printf("\t-train <file>\n");
[93m635 [m    printf("\t\tUse text data from <file> to train the model\n");
[93m636 [m    printf("\t-output <file>\n");
[93m637 [m    printf("\t\tUse <file> to save the resulting word vectors / word clusters\n");
[93m638 [m    printf("\t-size <int>\n");
[93m639 [m    printf("\t\tSet size of word vectors; default is 100\n");
[93m640 [m    printf("\t-window <int>\n");
[93m641 [m    printf("\t\tSet max skip length between words; default is 5\n");
[93m642 [m    printf("\t-sample <float>\n");[14;37H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m682 [m  if ((i = ArgPos((char *)"-cbow", argc, argv)) > 0) cbow = atoi(argv[i + 1]);
[93m683 [m  if (cbow) alpha = 0.05;
[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);
[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[5;1H[93m    [m]);
[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);
[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);
[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argv[i + 1]))[10;1H[93m    [m;
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 11[12;1H[93m    [m]);
[93m691 [m  if ((i = ArgPos((char *)"-iter", argc, argv)) > 0) iter = atoi(argv[i + 1]);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 11[15;1H[93m    [m]);
[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[i + 1]);
[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word));
[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));
[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));
[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {
[93m698 [m    expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precompute thh[22;1H[93m    [me exp() table
[93m699 [m    expTable[i] = expTable[i] / (expTable[i] + 1);[18C // Precompute f(([24;1H[93m    [mx) = x / (x + 1)
[93m700 [m  }
[93m701 [m  TrainModel();
[93m702 [m  return 0;
[93m703 [m}[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) [46m{[m /* 703行目まで */
[93m629 [m  int i;
[93m630 [m  if (argc == 1) {
[93m631 [m    printf("WORD VECTOR estimation toolkit v 0.1c\n\n");
[93m632 [m    printf("Options:\n");
[93m633 [m    printf("Parameters for training:\n");
[93m634 [m    printf("\t-train <file>\n");
[93m635 [m    printf("\t\tUse text data from <file> to train the model\n");
[93m636 [m    printf("\t-output <file>\n");
[93m637 [m    printf("\t\tUse <file> to save the resulting word vectors / word clusters\n");
[93m638 [m    printf("\t-size <int>\n");
[93m639 [m    printf("\t\tSet size of word vectors; default is 100\n");
[93m640 [m    printf("\t-window <int>\n");
[93m641 [m    printf("\t\tSet max skip length between words; default is 5\n");
[93m642 [m    printf("\t-sample <float>\n");[14;37H[?12l[?25h[?25l{[15;12H[?12l[?25h[16;22H[17;37H[18;29H[19;37H[20;36H[21;37H[22;37H[23;37H[24;34H[25;37H[26;36H[27;37H[?25l[28;15H[46m([21C)[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[26;15H([21C)
[93m643 [m    printf("\t\tSet threshold for occurrence of words. Those that appear with higher  [28;1H[93m    [mfrequency in the training data\n");[27;37H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m644 [m    printf("\t\twill be randomly down-sampled; default is 1e-3, useful range is (0, 11[28;1H[93m    [me-5)\n");[27;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m645 [m    printf("\t-hs <int>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m646 [m    printf("\t\tUse Hierarchical Softmax; default is 0 (not used)\n");[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m647 [m    printf[46m([m"\t-negative <int>\n"[46m)[m;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[26;15H([21C)
[93m648 [m    printf("\t\tNumber of negative examples; default is 5, common values are 3 - 10 (([28;1H[93m    [m0 = not used)\n");[27;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m649 [m    printf("\t-threads <int>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m650 [m    printf("\t\tUse <int> threads (default 12)\n");[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m651 [m    printf("\t-iter <int>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m652 [m    printf("\t\tRun more training iterations (default 5)\n");[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m653 [m    printf("\t-min-count <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m654 [m    printf("\t\tThis will discard words that appear less than <int> times; default iss[28;1H[93m    [m 5\n");[27;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m655 [m    printf("\t-alpha <float>\n");[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m656 [m    printf("\t\tSet the starting learning rate; default is 0.025 for skip-gram and 0..[28;1H[93m    [m05 for CBOW\n");[27;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m657 [m    printf("\t-classes <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m658 [m    printf("\t\tOutput word classes rather than word vectors; default number of classs[28;1H[93m    [mes is 0 (vectors are written)\n");[27;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m659 [m    printf("\t-debug <int>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m660 [m    printf("\t\tSet the debug mode (default = 2 = more info during training)\n");[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m661 [m    printf("\t-binary <int>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m662 [m    printf("\t\tSave the resulting vectors in binary moded; default is 0 (off)\n");[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m663 [m    printf("\t-save-vocab <file>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m664 [m    printf("\t\tThe vocabulary will be saved to <file>\n");[28;37H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m665 [m    printf("\t-read-vocab <file>\n");
[93m666 [m    printf("\t\tThe vocabulary will be read from <file>, not constructed from the tra[28;1H[94m@                                                                                        [27;37H[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[26;1H[93m666 [m    printf("\t\tThe vocabulary will be read from <file>, not constructed from the traa[27;1H[93m    [mining data\n");
[93m667 [m    printf("\t-cbow <int>\n");[26;37H[?12l[?25h[28;34H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m668 [m    printf("\t\tUse the continuous bag of words model; default is 1 (use 0 for skip-gg[28;1H[93m    [mram model)\n");[27;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m669 [m    printf("\nExamples:\n");[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m670 [m    printf("./word2vec -train data.txt -output vec.txt -size 200 -window 5 -sample 1ee[28;1H[93m    [m-4 -negative 5 -hs 0 -binary 0 -cbow 1 -iter 3\n\n");[27;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m671 [m    return 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m672 [m  }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m673 [m  output_file[0] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m674 [m  save_vocab_file[0] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m675 [m  read_vocab_file[0] = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m676 [m  if ((i = ArgPos((char *)"-size", argc, argv)) > 0) layer1_size = atoi(argv[i + 1]);[28;1H[93m677 [m  if ((i = ArgPos((char *)"-train", argc, argv)) > 0) strcpy(train_file, argv[i + 1])[28;1H[94m@                                                                                        [27;37H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;1H[93m677 [m  if ((i = ArgPos((char *)"-train", argc, argv)) > 0) strcpy(train_file, argv[i + 1]))[28;1H[93m    [m;[27;37H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m678 [m  if ((i = ArgPos((char *)"-save-vocab", argc, argv)) > 0) strcpy(save_vocab_file, arr[28;1H[93m    [mgv[i + 1]);[27;37H[?12l[?25h[?25l[1;28r[1;1H[3M[1;29r[26;1H[93m679 [m  if ((i = ArgPos((char *)"-read-vocab", argc, argv)) > 0) strcpy(read_vocab_file, arr[27;1H[93m    [mgv[i + 1]);
[93m680 [m  if ((i = ArgPos((char *)"-debug", argc, argv)) > 0) debug_mode = atoi(argv[i + 1]);[26;37H[?12l[?25h[28;37H[?25l[1;28r[28;1H
[1;29r[28;1H[93m681 [m  if ((i = ArgPos((char *)"-binary", argc, argv)) > 0) binary = atoi(argv[i + 1]);[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m682 [m  if ((i = ArgPos((char *)"-cbow", argc, argv)) > 0) cbow = atoi(argv[i + 1]);[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m683 [m  if (cbow) alpha = 0.05;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);[28;37H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[28;1H[93m    [m]);[27;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);[28;37H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);[27;37H[?12l[?25h[28;37H[?25l[1;28r[1;1H[3M[1;29r[26;1H[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argv[i + 1]))[27;1H[93m    [m;
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 1[28;1H[94m@                                                                                        [26;37H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;1H[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 11[28;1H[93m    [m]);[27;37H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m691 [m  if ((i = ArgPos((char *)"-iter", argc, argv)) > 0) iter = atoi(argv[i + 1]);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 1[28;1H[94m@                                                                                        [27;37H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;1H[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 11[28;1H[93m    [m]);[27;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[i + 1]);[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word));[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));[28;37H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {[28;37H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m698 [m    expTable[i] = exp((i / [46m([mreal[46m)[mEXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precompute thh[28;1H[93m    [me exp() table[27;37H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[25;32H(real)[51Chh[26;1H[93m 
699 [m    expTable[i] = expTable[i] / [46m([mexpTable[i] + 1[46m)[m;[18C // Precompute f(([28;1H[93m    [mx) = x / (x + 1)[27;37H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[22;44H[46m{[m[25;37H([15C)[35C(([26;1H[93m 
700 [m  [46m}[m
[93m701 [m  TrainModel();[27;7H[?12l[?25h[?25l[22;44H{[27;7H}[28;19H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m702 [m  return 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m703 [m}[?12l[?25h[27;15H[26;19H[?25l[20;44H[46m{[25;7H}[?12l[?25h[?25l[m[20;44H{[23;37H[46m([15C)[m[35C(([24;1H[93m [m[25;7H}[23;37H[?12l[?25h[?25l[21;32H[46m([mreal[46m)[m[51Chh[22;1H[93m [m[23;37H([15C)[35C(([24;1H[93m [21;37H[?12l[?25h[?25l[m(real)[51Chh[22;1H[93m [20;37H[?12l[?25h[19;37H[18;37H[17;37H[16;37H[14;37H[13;37H[11;37H[9;37H[8;37H[7;37H[6;37H[4;37H[3;37H[2;29H[1;37H[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m681 [m  if ((i = ArgPos((char *)"-binary", argc, argv)) > 0) binary = atoi(argv[i + 1]);[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m680 [m  if ((i = ArgPos((char *)"-debug", argc, argv)) > 0) debug_mode = atoi(argv[i + 1]);[1;37H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m679 [m  if ((i = ArgPos((char *)"-read-vocab", argc, argv)) > 0) strcpy(read_vocab_file, arr[2;1H[93m    [mgv[i + 1]);[1;37H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m678 [m  if ((i = ArgPos((char *)"-save-vocab", argc, argv)) > 0) strcpy(save_vocab_file, arr[2;1H[93m    [mgv[i + 1]);[1;37H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m677 [m  if ((i = ArgPos((char *)"-train", argc, argv)) > 0) strcpy(train_file, argv[i + 1]))[2;1H[93m    [m;[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m676 [m  if ((i = ArgPos((char *)"-size", argc, argv)) > 0) layer1_size = atoi(argv[i + 1]);[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m675 [m  read_vocab_file[0] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m674 [m  save_vocab_file[0] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m673 [m  output_file[0] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m672 [m  }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m671 [m    return 0;[28;1H[94m@                                                                                        [1;17H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m670 [m    printf("./word2vec -train data.txt -output vec.txt -size 200 -window 5 -sample 1ee[2;1H[93m    [m-4 -negative 5 -hs 0 -binary 0 -cbow 1 -iter 3\n\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m669 [m    printf("\nExamples:\n");[28;1H[94m@                                                                                        [1;32H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m668 [m    printf("\t\tUse the continuous bag of words model; default is 1 (use 0 for skip-gg[2;1H[93m    [mram model)\n");[28;1H[94m@                                                                                        [1;37H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m667 [m    printf("\t-cbow <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m666 [m    printf("\t\tThe vocabulary will be read from <file>, not constructed from the traa[2;1H[93m    [mining data\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m665 [m    printf("\t-read-vocab <file>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m664 [m    printf("\t\tThe vocabulary will be saved to <file>\n");[28;1H[94m@                                                                                        [1;37H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m663 [m    printf("\t-save-vocab <file>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m662 [m    printf("\t\tSave the resulting vectors in binary moded; default is 0 (off)\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m661 [m    printf("\t-binary <int>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m660 [m    printf("\t\tSet the debug mode (default = 2 = more info during training)\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m659 [m    printf("\t-debug <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m658 [m    printf("\t\tOutput word classes rather than word vectors; default number of classs[2;1H[93m    [mes is 0 (vectors are written)\n");[28;1H[94m@                                                                                        [1;37H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m657 [m    printf("\t-classes <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m656 [m    printf("\t\tSet the starting learning rate; default is 0.025 for skip-gram and 0..[2;1H[93m    [m05 for CBOW\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m655 [m    printf("\t-alpha <float>\n");[28;1H[94m@                                                                                        [1;37H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m654 [m    printf("\t\tThis will discard words that appear less than <int> times; default iss[2;1H[93m    [m 5\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m653 [m    printf("\t-min-count <int>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m652 [m    printf("\t\tRun more training iterations (default 5)\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m651 [m    printf("\t-iter <int>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m650 [m    printf("\t\tUse <int> threads (default 12)\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m649 [m    printf("\t-threads <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m648 [m    printf("\t\tNumber of negative examples; default is 5, common values are 3 - 10 (([2;1H[93m    [m0 = not used)\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m647 [m    printf[46m([m"\t-negative <int>\n"[46m)[m;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m646 [m    printf("\t\tUse Hierarchical Softmax; default is 0 (not used)\n");[2;15H([21C)[28;1H[94m@                                                                                        [1;37H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m645 [m    printf("\t-hs <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m644 [m    printf("\t\twill be randomly down-sampled; default is 1e-3, useful range is (0, 11[2;1H[93m    [me-5)\n");[28;1H[94m@                                                                                        [1;37H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m643 [m    printf("\t\tSet threshold for occurrence of words. Those that appear with higher  [2;1H[93m    [mfrequency in the training data\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m642 [m    printf[46m([m"\t-sample <float>\n"[46m)[m;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m641 [m    printf("\t\tSet max skip length between words; default is 5\n");[2;15H([21C)[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m640 [m    printf("\t-window <int>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m639 [m    printf("\t\tSet size of word vectors; default is 100\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m638 [m    printf("\t-size <int>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m637 [m    printf("\t\tUse <file> to save the resulting word vectors / word clusters\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m636 [m    printf("\t-output <file>\n");[28;1H[94m@                                                                                        [1;37H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m635 [m    printf("\t\tUse text data from <file> to train the model\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m634 [m    printf("\t-train <file>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m633 [m    printf("Parameters for training:\n");[28;1H[94m@                                                                                        [1;37H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m632 [m    printf("Options:\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m631 [m    printf("WORD VECTOR estimation toolkit v 0.1c\n\n");[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m630 [m  if (argc == 1) {[28;1H[94m@                                                                                        [1;22H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m629 [m  int i;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m628 [mint main(int argc, char **argv) { /* 703行目まで */[1;37H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m627 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m626 [m}[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m625 [m  return -1;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m624 [m  }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m623 [m    return a;[28;1H[94m@                                                                                        [1;17H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m622 [m    }[?12l[?25h[2;17H[3;7H[4;16H[5;5H[6;5H[7;37H[8;12H[9;22H[8;12H[7;37H{ /* [?25l[29;1H[1m-- INSERT --[7;43H[?12l[?25h[?25l[m m703行目まで */[7;43H[?12l[?25h[?25lma703行目まで */[7;44H[?12l[?25h[?25lai703行目まで */[7;45H[?12l[?25h[?25lin703行目まで */[7;46H[?12l[?25h[?25ln関数703行目まで */[7;50H[?12l[?25h[?25l，703行目まで */[7;52H[?12l[?25h[29;1H[K[7;50H[?25l[?12l[?25h[?25l[29;1H:[?12l[?25hw[?25l"word2vec.c" 703L, 34515C written[7;50H[?12l[?25h[8;12H[9;22H[10;50H[11;29H[12;45H[13;36H[14;50H[15;37H[16;50H[17;34H[18;50H[19;36H[20;50H[21;38H[22;50H[24;50H[26;32H[27;50H[28;38H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m648 [m    printf("\t\tNumber of negative examples; default is 5, common values are 3 - 10 (([28;1H[93m    [m0 = not used)\n");[29;1H[K[27;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m649 [m    printf("\t-threads <int>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m650 [m    printf("\t\tUse <int> threads [46m([mdefault 12[46m)[m\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;39H([10C)
[93m651 [m    printf("\t-iter <int>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m652 [m    printf("\t\tRun more training iterations [46m([mdefault 5[46m)[m\n");[28;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;50H([9C)
[93m653 [m    printf("\t-min-count <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m654 [m    printf("\t\tThis will discard words that appear less than <int> times; default iss[28;1H[93m    [m 5\n");[27;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m655 [m    printf("\t-alpha <float>\n");[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m656 [m    printf("\t\tSet the starting learning rate; default is 0.025 for skip-gram and 0..[28;1H[93m    [m05 for CBOW\n");[27;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m657 [m    printf("\t-classes <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m658 [m    printf("\t\tOutput word classes rather than word vectors; default number of classs[28;1H[93m    [mes is 0 (vectors are written)\n");[27;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m659 [m    printf("\t-debug <int>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m660 [m    printf("\t\tSet the debug mode (default = 2 = more info during training)\n");[28;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m661 [m    printf("\t-binary <int>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m662 [m    printf("\t\tSave the resulting vectors in binary moded; default is 0 (off)\n");[28;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m663 [m    printf("\t-save-vocab <file>\n");[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m664 [m    printf("\t\tThe vocabulary will be saved to <file>\n");[28;50H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m665 [m    printf("\t-read-vocab <file>\n");
[93m666 [m    printf("\t\tThe vocabulary will be read from <file>, not constructed from the tra[28;1H[94m@                                                                                        [27;41H[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[26;1H[93m666 [m    printf("\t\tThe vocabulary will be read from <file>, not constructed from the traa[27;1H[93m    [mining data\n");
[93m667 [m    printf("\t-cbow <int>\n");[26;50H[?12l[?25h[28;34H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m668 [m    printf("\t\tUse the continuous bag of words model; default is 1 (use 0 for skip-gg[28;1H[93m    [mram model)\n");[27;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m669 [m    printf("\nExamples:\n");[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m670 [m    printf("./word2vec -train data.txt -output vec.txt -size 200 -window 5 -sample 1ee[28;1H[93m    [m-4 -negative 5 -hs 0 -binary 0 -cbow 1 -iter 3\n\n");[27;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m671 [m    return 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m672 [m  }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m673 [m  output_file[0] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m674 [m  save_vocab_file[0] = 0;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m675 [m  read_vocab_file[0] = 0;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m676 [m  if ((i = ArgPos[46m([m(char *)"-size", argc, argv[46m)[m) > 0) layer1_size = atoi(argv[i + 1]);[28;1H[93m677 [m  if ((i = ArgPos((char *)"-train", argc, argv)) > 0) strcpy(train_file, argv[i + 1])[28;1H[94m@                                                                                        [27;50H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[26;22H([27C)
[93m677 [m  if ((i = ArgPos((char *)"-train", argc, argv)) > 0) strcpy(train_file, argv[i + 1]))[28;1H[93m    [m;[27;50H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m678 [m  if ((i = ArgPos((char *)"-save-vocab", argc, argv)) > 0) strcpy(save_vocab_file, arr[28;1H[93m    [mgv[i + 1]);[27;50H[?12l[?25h[?25l[1;28r[1;1H[3M[1;29r[26;1H[93m679 [m  if ((i = ArgPos((char *)"-read-vocab", argc, argv)) > 0) strcpy(read_vocab_file, arr[27;1H[93m    [mgv[i + 1]);
[93m680 [m  if ((i = ArgPos((char *)"-debug", argc, argv)) > 0) debug_mode = atoi(argv[i + 1]);[26;50H[?12l[?25h[28;50H[?25l[1;28r[28;1H
[1;29r[28;1H[93m681 [m  if ((i = ArgPos((char *)"-binary", argc, argv)) > 0) binary = atoi(argv[i + 1]);[28;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m682 [m  if ((i = ArgPos[46m([m(char *)"-cbow", argc, argv[46m)[m) > 0) cbow = atoi(argv[i + 1]);[28;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[27;22H([27C)
[93m683 [m  if (cbow) alpha = 0.05;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m684 [m  if ((i = ArgPos((char *)"-alpha", argc, argv)) > 0) alpha = atof(argv[i + 1]);[28;50H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m685 [m  if ((i = ArgPos((char *)"-output", argc, argv)) > 0) strcpy(output_file, argv[i + 11[28;1H[93m    [m]);[27;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m686 [m  if ((i = ArgPos((char *)"-window", argc, argv)) > 0) window = atoi(argv[i + 1]);[28;50H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m687 [m  if ((i = ArgPos((char *)"-sample", argc, argv)) > 0) sample = atof(argv[i + 1]);
[93m688 [m  if ((i = ArgPos((char *)"-hs", argc, argv)) > 0) hs = atoi(argv[i + 1]);[27;50H[?12l[?25h[28;50H[?25l[1;28r[1;1H[3M[1;29r[26;1H[93m689 [m  if ((i = ArgPos((char *)"-negative", argc, argv)) > 0) negative = atoi(argv[i + 1]))[27;1H[93m    [m;
[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 1[28;1H[94m@                                                                                        [26;50H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;1H[93m690 [m  if ((i = ArgPos((char *)"-threads", argc, argv)) > 0) num_threads = atoi(argv[i + 11[28;1H[93m    [m]);[27;50H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m691 [m  if ((i = ArgPos[46m([m(char *)"-iter", argc, argv[46m)[m) > 0) iter = atoi(argv[i + 1]);
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 1[28;1H[94m@                                                                                        [27;50H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[26;22H([27C)
[93m692 [m  if ((i = ArgPos((char *)"-min-count", argc, argv)) > 0) min_count = atoi(argv[i + 11[28;1H[93m    [m]);[27;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m693 [m  if ((i = ArgPos((char *)"-classes", argc, argv)) > 0) classes = atoi(argv[i + 1]);[28;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m694 [m  vocab = (struct vocab_word *)calloc(vocab_max_size, sizeof(struct vocab_word));[28;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m695 [m  vocab_hash = (int *)calloc(vocab_hash_size, sizeof(int));[28;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m696 [m  expTable = (real *)malloc((EXP_TABLE_SIZE + 1) * sizeof(real));[28;50H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m697 [m  for (i = 0; i < EXP_TABLE_SIZE; i++) {[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m698 [m    expTable[i] = exp((i / (real)EXP_TABLE_SIZE * 2 - 1) * MAX_EXP); // Precompute thh[28;1H[93m    [me exp() table[27;50H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m699 [m    expTable[i] = expTable[i] / (expTable[i] + 1);[18C // Precompute f(([28;1H[93m    [mx) = x / (x + 1)[27;50H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[22;44H[46m{[m[27;1H[93m700 [m  [46m}[m
[93m701 [m  TrainModel();[27;7H[?12l[?25h[?25l[22;44H{[27;7H}[28;19H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m702 [m  return 0;[?12l[?25h[27;19H[?25l[21;44H[46m{[26;7H}[?12l[?25h[?25l[m[21;44H{[26;7H}[24;50H[?12l[?25h[22;50H[?25l[21;44H[46m{[26;7H}[21;44H[?12l[?25h[?25l[m{[26;7H}[20;50H[?12l[?25h[19;50H[18;50H[17;50H[15;50H[?25l[14;22H[46m([27C)[?12l[?25h[?25l[m[14;22H([27C)[12;50H[?12l[?25h[10;50H[9;50H[8;50H[7;50H[5;50H[4;50H[3;29H[?25l[2;22H[46m([27C)[?12l[?25h[?25l[m[2;22H([27C)[1;50H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m680 [m  if ((i = ArgPos((char *)"-debug", argc, argv)) > 0) debug_mode = atoi(argv[i + 1]);[1;50H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m679 [m  if ((i = ArgPos((char *)"-read-vocab", argc, argv)) > 0) strcpy(read_vocab_file, arr[2;1H[93m    [mgv[i + 1]);[1;50H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m678 [m  if ((i = ArgPos((char *)"-save-vocab", argc, argv)) > 0) strcpy(save_vocab_file, arr[2;1H[93m    [mgv[i + 1]);[1;50H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m677 [m  if ((i = ArgPos((char *)"-train", argc, argv)) > 0) strcpy(train_file, argv[i + 1]))[2;1H[93m    [m;[1;50H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m676 [m  if ((i = ArgPos[46m([m(char *)"-size", argc, argv[46m)[m) > 0) layer1_size = atoi(argv[i + 1]);[1;50H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m675 [m  read_vocab_file[0] = 0;[2;22H([27C)[1;29H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m674 [m  save_vocab_file[0] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m673 [m  output_file[0] = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m672 [m  }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m671 [m    return 0;[28;1H[94m@                                                                                        [1;17H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m670 [m    printf("./word2vec -train data.txt -output vec.txt -size 200 -window 5 -sample 1ee[2;1H[93m    [m-4 -negative 5 -hs 0 -binary 0 -cbow 1 -iter 3\n\n");[1;50H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m669 [m    printf("\nExamples:\n");[28;1H[94m@                                                                                        [1;32H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m668 [m    printf("\t\tUse the continuous bag of words model; default is 1 (use 0 for skip-gg[2;1H[93m    [mram model)\n");[28;1H[94m@                                                                                        [1;50H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m667 [m    printf("\t-cbow <int>\n");[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m666 [m    printf("\t\tThe vocabulary will be read from <file>, not constructed from the traa[2;1H[93m    [mining data\n");[1;50H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m665 [m    printf("\t-read-vocab <file>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m664 [m    printf("\t\tThe vocabulary will be saved to <file>\n");[28;1H[94m@                                                                                        [1;50H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m663 [m    printf("\t-save-vocab <file>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m662 [m    printf("\t\tSave the resulting vectors in binary moded; default is 0 (off)\n");[1;50H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m661 [m    printf("\t-binary <int>\n");[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m660 [m    printf("\t\tSet the debug mode (default = 2 = more info during training)\n");[1;50H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m659 [m    printf("\t-debug <int>\n");[?12l[?25h[?25l[29;1H/[?12l[?25hArgPos[?25l[21;16H[?12l[?25h[?25l[29;1H?[27m[m[H[2J[1;1H[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  }
[93m613 [m  fclose(fo);
[93m614 [m}
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) { /* main関数，703行目まで */
[93m629 [m  int i;
[93m630 [m  if (argc == 1) {[14;9H[?12l[?25h[15;9H[16;9H[17;9H[18;9H[19;9H[?25l[17;28H[46m{[20;9H}[?12l[?25h[?25l[m[17;28H{[20;9H}[21;9H[?12l[?25h[?25l[16;61H[46m{[22;7H}[?12l[?25h[?25l[m[16;61H{[22;7H}[23;9H[?12l[?25h[?25l[14;50H[46m{[24;5H}[?12l[?25h[?25l[m[14;50H{[24;5H}[25;5H[?12l[?25h[26;9H[27;9H[28;9H[?25l[1;28r[28;1H
[1;29r[28;1H[93m631 [m    printf("WORD VECTOR estimation toolkit v 0.1c\n\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m632 [m    printf("Options:\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m633 [m    printf("Parameters for training:\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m634 [m    printf("\t-train <file>\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m635 [m    printf("\t\tUse text data from <file> to train the model\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m636 [m    printf("\t-output <file>\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m637 [m    printf("\t\tUse <file> to save the resulting word vectors / word clusters\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m638 [m    printf("\t-size <int>\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m639 [m    printf("\t\tSet size of word vectors; default is 100\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m640 [m    printf("\t-window <int>\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m641 [m    printf("\t\tSet max skip length between words; default is 5\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m642 [m    printf("\t-sample <float>\n");[28;9H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m643 [m    printf("\t\tSet threshold for occurrence of words. Those that appear with higher  [28;1H[93m    [mfrequency in the training data\n");[27;9H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m644 [m    printf("\t\twill be randomly down-sampled; default is 1e-3, useful range is (0, 11[28;1H[93m    [me-5)\n");[27;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m645 [m    printf("\t-hs <int>\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m646 [m    printf("\t\tUse Hierarchical Softmax; default is 0 (not used)\n");[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m647 [m    printf("\t-negative <int>\n");[28;9H[?12l[?25h[27;9H[26;9H[24;9H[22;9H[21;9H[20;9H[19;9H[18;9H[17;9H[16;9H[15;9H[14;9H[13;9H[12;9H[11;9H[10;9H[9;9H[8;9H[7;9H[6;5H[5;5H[4;9H[3;7H[2;9H[1;9H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m621 [m      exit(1);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m620 [m      printf("Argument missing for %s\n", str);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m619 [m    if (a == argc - 1) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {[28;1H[94m@                                                                                        [1;9H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m617 [m  int a;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m616 [mint ArgPos(char *str, int argc, char **argv) {[28;1H[94m@                                                                                        [1;9H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m615 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m614 [m}[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m613 [m  fclose(fo);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m612 [m  }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m611 [m    free(cl);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m610 [m    free(cent);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m609 [m    free(centcn);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m607 [m    // Save the K-means classes[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m606 [m    }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m605 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m604 [m[7C cl[c] = closeid;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m603 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m602 [m[9C }[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m601 [m[11C closeid = d;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m600 [m[11C closev = x;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m599 [m[9C if (x > closev) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m598 [m[9C for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[2;1H[93m    [m layer1_size + b];[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m597 [m[9C x = 0;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m596 [m[7C for (d = 0; d < clcn; d++) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m595 [m[7C closeid = 0;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m594 [m[7C closev = -10;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m593 [m      for (c = 0; c < vocab_size; c++) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m592 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m591 [m[7C for (c = 0; c < layer1_size; c++) cent[layer1_size * b + c] /= closev;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m590 [m[7C closev = sqrt(closev);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m589 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m588 [m[9C closev += cent[layer1_size * b + c] * cent[layer1_size * b + c];[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m587 [m[9C cent[layer1_size * b + c] /= centcn[b];[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m586 [m[7C for (c = 0; c < layer1_size; c++) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m585 [m[7C closev = 0;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m584 [m      for (b = 0; b < clcn; b++) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m583 [m      }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m582 [m[7C centcn[cl[c]]++;[1;9H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[2;1H[93m    [mayer1_size + d];[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m580 [m      for (c = 0; c < vocab_size; c++) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m577 [m    for (a = 0; a < iter; a++) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m574 [m    real closev, x;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int));[28;1H[94m@                                                                                        [1;9H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m571 [m    int clcn = classes, iter = 10, closeid;[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m570 [m    // Run K-means on the word vectors[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m569 [m  } else {[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m568 [m    }[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m567 [m      fprintf(fo, "\n");[1;9H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m566 [m      else for (b = 0; b < layer1_size; b++) fprintf(fo, "%lf ", syn0[a * layer1_sizee[2;1H[93m    [m + b]);[1;9H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m565 [m      if (binary) for (b = 0; b < layer1_size; b++) fwrite(&syn0[a * layer1_size + b]][2;1H[93m    [m, sizeof(real), 1, fo);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m564 [m      fprintf(fo, "%s ", vocab[a].word);[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m563 [m    for (a = 0; a < vocab_size; a++) {[1;9H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m562 [m    fprintf(fo, "%lld %lld\n", vocab_size, layer1_size);[1;9H[?12l[?25h[2;9H[3;9H[4;9H[6;9H[8;9H[?25l[2;42H[46m{[9;9H}[?12l[?25h[?25l[m[2;42H{[9;9H}[10;9H[?12l[?25h[11;9H[12;9H[13;9H[14;9H[15;9H[16;9H[17;9H[18;9H[19;9H[20;9H[21;9H[22;9H[24;9H[25;9H[26;9H[27;9H[28;9H[?25l[1;28r[28;1H
[1;29r[28;1H[93m587 [m[9C cent[layer1_size * b + c] /= centcn[b];[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m588 [m[9C closev += cent[layer1_size * b + c] * cent[layer1_size * b + c];[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m589 [m[7C }[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m590 [m[7C closev = sqrt(closev);
[93m591 [m[7C for (c = 0; c < layer1_size; c++) cent[layer1_size * b + c] /= closev;[27;9H[?12l[?25h[28;9H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m592 [m      }
[93m593 [m      for (c = 0; c < vocab_size; c++) {[27;9H[?12l[?25h[28;9H[?25l[1;28r[28;1H
[1;29r[28;1H[93m594 [m[7C closev = -10;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m595 [m[7C closeid = 0;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m596 [m[7C for (d = 0; d < clcn; d++) {[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m597 [m[9C x = 0;[28;9H[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m598 [m[9C for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[28;1H[93m    [m layer1_size + b];[27;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m599 [m[9C if (x > closev) {[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m600 [m[11C closev = x;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m601 [m[11C closeid = d;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m602 [m[9C }[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m603 [m[7C }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m604 [m[7C cl[c] = closeid;[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m605 [m      }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m606 [m    }[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);[27;9H[?12l[?25h[28;9H[?25l[1;28r[28;1H
[1;29r[28;1H[93m609 [m    free(centcn);[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m610 [m    free(cent);[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m611 [m    free(cl);[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m612 [m  }[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m613 [m  fclose(fo);[28;9H[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m614 [m}[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m615 [?12l[?25h[27;5H[?25l[27m[m[H[2J[1;1H[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() [46m{[m /* 614行目まで */
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();
[93m552 [m  if (save_vocab_file[0] != 0) SaveVocab();
[93m553 [m  if (output_file[0] == 0) return;
[93m554 [m  InitNet();
[93m555 [m  if (negative > 0) InitUnigramTable();
[93m556 [m  start = clock();
[93m557 [m  for (a = 0; a < num_threads; a++) pthread_create(&pt[a], NULL, TrainModelThread, (vv[27;1H[93m    [moid *)a);
[93m558 [m  for (a = 0; a < num_threads; a++) pthread_join(pt[a], NULL);[14;23H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  }
[93m613 [m  fclose(fo);
[93m614 [m}
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) { /* main関数，703行目まで */[14;5H[?12l[?25h[?25l[29;1H[1m-- INSERT --[14;6H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h [?25l v */[?12l[?25h[?25lvo */[?12l[?25h[?25loi */[?12l[?25h[?25lid */[?12l[?25h[?25l  */[?12l[?25h[?25l T */[?12l[?25h[?25lTr */[?12l[?25h[?25lra */[?12l[?25h[?25lai */[?12l[?25h[?25lin */[?12l[?25h[?25lnM */[?12l[?25h[?25lMo */[?12l[?25h[?25lod */[?12l[?25h[?25lde */[?12l[?25h[?25lel */[?12l[?25h[29;1H[K[14;9H[?25l[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m532 [m    }
[93m533 [m    sentence_position++;
[93m534 [m    if (sentence_position >= sentence_length) {
[93m535 [m      sentence_length = 0;
[93m536 [m      continue;
[93m537 [m    }
[93m538 [m  }
[93m539 [m  fclose(fi);
[93m540 [m  free(neu1);
[93m541 [m  free(neu1e);
[93m542 [m  pthread_exit(NULL);
[93m543 [m}
[93m544 
545 [mvoid TrainModel() [46m{[m /* 614行目まで */
[93m546 [m  long a, b, c, d;
[93m547 [m  FILE *fo;
[93m548 [m  pthread_t *pt = (pthread_t *)malloc(num_threads * sizeof(pthread_t));
[93m549 [m  printf("Starting training using file %s\n", train_file);
[93m550 [m  starting_alpha = alpha;
[93m551 [m  if (read_vocab_file[0] != 0) ReadVocab(); else LearnVocabFromTrainFile();
[93m552 [m  if (save_vocab_file[0] != 0) SaveVocab();
[93m553 [m  if (output_file[0] == 0) return;
[93m554 [m  InitNet();
[93m555 [m  if (negative > 0) InitUnigramTable();
[93m556 [m  start = clock();
[93m557 [m  for (a = 0; a < num_threads; a++) pthread_create(&pt[a], NULL, TrainModelThread, (vv[27;1H[93m    [moid *)a);
[93m558 [m  for (a = 0; a < num_threads; a++) pthread_join(pt[a], NULL);[14;23H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  }
[93m613 [m  fclose(fo);
[93m614 [m} /* void TrainModel */
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}
[93m627 
628 [mint main(int argc, char **argv) { /* main関数，703行目まで */[14;5H[?12l[?25h} /*[?25l[29;1H[1m-- INSERT --[14;10H[?12l[?25h[?25l[m*5 void TrainModel */[14;10H[?12l[?25h[?25l54 void TrainModel */[14;11H[?12l[?25h[?25l45 void TrainModel */[14;12H[?12l[?25h[?25l* 545 void TrainModel */[14;10H[?12l[?25h545[?25l5行目 void TrainModel */[14;17H[?12l[?25h [?25lvoid TrainModel */[14;35H[K[14;17H[?12l[?25hvoid TrainModel[?25ll( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l()[13;18H[?12l[?25h[?25l[12;8H[?12l[?25h[11;18H[?25l[12;8H[?12l[?25h[13;18H[?25l[14;32H[46m()[?12l[?25h[?25l[m()k */[?12l[?25h[?25lka */[?12l[?25h[?25lk */[14;38H[K[14;35H[?12l[?25h[?25l[46m()[m */[14;37H[K[14;34H[?12l[?25h[?25l()から */[?12l[?25h[13;18H[?25l[12;8H[?12l[?25h[29;1H[K[12;7H[?25l[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m558 [m  for (a = 0; a < num_threads; a++) pthread_join(pt[a], NULL);
[93m559 [m  fo = fopen(output_file, "wb");
[93m560 [m  if (classes == 0) {
[93m561 [m    // Save the word vectors
[93m562 [m    fprintf(fo, "%lld %lld\n", vocab_size, layer1_size);
[93m563 [m    for (a = 0; a < vocab_size; a++) {
[93m564 [m      fprintf(fo, "%s ", vocab[a].word);
[93m565 [m      if (binary) for (b = 0; b < layer1_size; b++) fwrite(&syn0[a * layer1_size + b]][9;1H[93m    [m, sizeof(real), 1, fo);
[93m566 [m      else for (b = 0; b < layer1_size; b++) fprintf(fo, "%lf ", syn0[a * layer1_sizee[11;1H[93m    [m + b]);
[93m567 [m      fprintf(fo, "\n");
[93m568 [m    }
[93m569 [m  } else [46m{[m
[93m570 [m    // Run K-means on the word vectors
[93m571 [m    int clcn = classes, iter = 10, closeid;
[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int));
[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));
[93m574 [m    real closev, x;
[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));
[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;
[93m577 [m    for (a = 0; a < iter; a++) {
[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;
[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;
[93m580 [m      for (c = 0; c < vocab_size; c++) {
[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[27;1H[93m    [mayer1_size + d];
[93m582 [m[7C centcn[cl[c]]++;[14;14H[?12l[?25h[?25l[27m[m[H[2J[1;1H[93m599 [m[9C if (x > closev) {
[93m600 [m[11C closev = x;
[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  }
[93m613 [m  fclose(fo);
[93m614 [m} /* 545行目void TrainModel()から */
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }
[93m625 [m  return -1;
[93m626 [m}[14;7H[?12l[?25h[?25l[29;1H[1m-- INSERT --[14;8H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 5 */[?12l[?25h[?25l56 */[?12l[?25h[?25l69 */[?12l[?25h[?25l9行目 */[?12l[?25h[?25ll */[?12l[?25h[?25lle */[?12l[?25h[?25ll */[14;23H[K[14;20H[?12l[?25h[?25l */[14;22H[K[14;19H[?12l[?25h[?25le */[?12l[?25h[?25lel */[?12l[?25h[?25lls */[?12l[?25h[?25lse */[?12l[?25h[?25leから */[?12l[?25h[13;18H[12;20H[11;22H[10;27H[9;27H[?25l[8;10H[?12l[?25h[?25l[7;12H[?12l[?25h[6;27H[?25l[5;14H[?12l[?25h[?25l[1;31H[46m{[4;15H}[?12l[?25h[?25l[m[1;31H{[4;15H}[3;27H[?12l[?25h[2;27H[1;27H[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m598 [m[9C for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[2;1H[93m    [m layer1_size + b];[1;27H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m597 [m[9C x = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m596 [m[7C for (d = 0; d < clcn; d++) {[1;27H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m595 [m[7C closeid = 0;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m594 [m[7C closev = -10;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m593 [m      for (c = 0; c < vocab_size; c++) {[1;27H[?12l[?25h[29;1H[K[1;26H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hcentcn[?25l[18;14H[?12l[?25h[?25l[29;1H?[1;28r[1;1H[6L[1;29r[1;1H[93m587 [m[9C cent[layer1_size * b + c] /= centcn[b];
[93m588 [m[9C closev += cent[layer1_size * b + c] * cent[layer1_size * b + c];
[93m589 [m[7C }
[93m590 [m[7C closev = sqrt(closev);
[93m591 [m[7C for (c = 0; c < layer1_size; c++) cent[layer1_size * b + c] /= closev;
[93m592 [m      }[29;1H[K[1;44H[?12l[?25h[?25l[29;1H?centcn[1;28r[1;1H[5L[1;29r[1;1H[93m582 [m[7C centcn[cl[c]]++;
[93m583 [m      }
[93m584 [m      for (b = 0; b < clcn; b++) {
[93m585 [m[7C closev = 0;
[93m586 [m[7C for (c = 0; c < layer1_size; c++) {[29;1H[K[1;13H[?12l[?25h[?25l[29;1H?centcn[1;28r[1;1H[4L[1;29r[1;1H[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;
[93m580 [m      for (c = 0; c < vocab_size; c++) {
[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[4;1H[93m    [mayer1_size + d];[29;1H[K[1;38H[?12l[?25h[?25l[29;1H?centcn[1;28r[1;1H[7L[1;29r[1;1H[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int));
[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));
[93m574 [m    real closev, x;
[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));
[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;
[93m577 [m    for (a = 0; a < iter; a++) {
[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;[28;1H[94m@                                                                                        [m[29;1H[K[1;14H[?12l[?25h[?25l[29;1H?centcn[38;5;224msearch hit TOP, continuing at BOTTOM[1;28r[m[1;1H[12M[1;29r[16;1H[93m598 [m          for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[17;1H[93m    [m layer1_size + b];
[93m599 [m[9C if (x > closev) {
[93m600 [m[11C closev = x;
[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);[29;1H[K[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[28;14H[?12l[?25h[?25l[m
/centcn[29;8H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[1;28r[m[1;1H[12L[1;29r[1;1H[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int));
[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));
[93m574 [m    real closev, x;
[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));
[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;
[93m577 [m    for (a = 0; a < iter; a++) {
[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;
[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;
[93m580 [m      for (c = 0; c < vocab_size; c++) {
[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[11;1H[93m    [mayer1_size + d];
[93m582 [m[7C centcn[cl[c]]++;[28;1H[94m@                                                                                        [m[29;1H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[1;14H[?12l[?25h[?25l[m[46C int *cl = (int *)calloc(vocabb[2;1H[93m    [m_size, sizeof(int));[2;25H[K[3;2H[93m73
574
575
576
577
578
579
580[m[85Cll[11;1H[93m 
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597 [m          for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c *[28;1H[94m@                                                                                        [1;60H[?12l[?25h[?25l[m[29;1H1 more line; before #131  2 seconds ago[1;61H[K[2;1H[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));[3;2H[93m74
575
576
577
578
579
580
581[m[85Cll[11;1H[93m 
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597[1;14H[?12l[?25h[?25l[m[29;1H?centcn[29;8H[K[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[1;28r[m[1;1H[12M[1;29r[16;1H[93m598 [m          for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[17;1H[93m    [m layer1_size + b];
[93m599 [m[9C if (x > closev) {
[93m600 [m[11C closev = x;
[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);[29;1H[K[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[28;14H[?12l[?25h[?25l[m
?centcn[29;8H[K[29;1H[5;44H[?12l[?25h[?25l[29;1H[1;28r[1;1H[L[1;29r[1;1H[93m582 [m[7C centcn[cl[c]]++;[29;1H[K[1;13H[?12l[?25h[?25l[29;1H?centcn[1;28r[1;1H[4L[1;29r[1;1H[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;
[93m580 [m      for (c = 0; c < vocab_size; c++) {
[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[4;1H[93m    [mayer1_size + d];[29;1H[K[1;38H[?12l[?25h[?25l[29;1H?centcn[1;28r[1;1H[7L[1;29r[1;1H[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int));
[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));
[93m574 [m    real closev, x;
[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));
[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;
[93m577 [m    for (a = 0; a < iter; a++) {
[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;[28;1H[94m@                                                                                        [m[29;1H[K[1;14H[?12l[?25h[?25l[29;1H?centcn[38;5;224msearch hit TOP, continuing at BOTTOM[1;28r[m[1;1H[12M[1;29r[16;1H[93m598 [m          for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[17;1H[93m    [m layer1_size + b];
[93m599 [m[9C if (x > closev) {
[93m600 [m[11C closev = x;
[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);[29;1H[K[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[28;14H[?12l[?25h[mcentc[?25l
/centcn[29;8H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[1;28r[m[1;1H[12L[1;29r[1;1H[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int));
[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));
[93m574 [m    real closev, x;
[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));
[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;
[93m577 [m    for (a = 0; a < iter; a++) {
[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;
[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;
[93m580 [m      for (c = 0; c < vocab_size; c++) {
[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[11;1H[93m    [mayer1_size + d];
[93m582 [m[7C centcn[cl[c]]++;[28;1H[94m@                                                                                        [m[29;1H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[1;14H[?12l[?25h[?25l[m[29;1H?centcn[29;8H[K[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[1;28r[m[1;1H[12M[1;29r[16;1H[93m598 [m          for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[17;1H[93m    [m layer1_size + b];
[93m599 [m[9C if (x > closev) {
[93m600 [m[11C closev = x;
[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn);[29;1H[K[29;1H[38;5;224msearch hit TOP, continuing at BOTTOM[28;14H[?12l[?25h[mcentc[?25l[46m([mcentcn[46m)[?12l[?25h[?25l[m[28;13H(centcn)[?12l[?25h[?25l
[1m-- INSERT --[m[29;13H[K[28;22H[?12l[?25h[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/:[?12l[?25h[?25l[28;24H[K[28;24H[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 5 */[?12l[?25h[?25l57 */[?12l[?25h[?25l72 */[?12l[?25h[?25l2行目 */[?12l[?25h[?25lで */[?12l[?25h[?25l確保sた */[?12l[?25h[?25ls */[28;43H[K[28;40H[?12l[?25h[?25l */[28;42H[K[28;39H[?12l[?25h[?25lした */[?12l[?25h[?25lc */[?12l[?25h[?25lce */[?12l[?25h[?25len */[?12l[?25h[?25lnt */[?12l[?25h[?25ltc */[?12l[?25h[?25lcn */[?12l[?25h[?25lnの */[?12l[?25h[?25lメモリ */[?12l[?25h[?25lを */[?12l[?25h[?25l解放 */[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m610 [m    free(cent);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m611 [m    free(cl);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m612 [m  } /* 569行目elseから */[?12l[?25h[27;18H[26;20H[25;63H[29;1H[K[25;61H[?25l[?12l[?25h[?25l[29;1H:[?12l[?25h572[?25l[27m[m[H[2J[1;1H[93m561 [m    // Save the word vectors
[93m562 [m    fprintf(fo, "%lld %lld\n", vocab_size, layer1_size);
[93m563 [m    for (a = 0; a < vocab_size; a++) {
[93m564 [m      fprintf(fo, "%s ", vocab[a].word);
[93m565 [m      if (binary) for (b = 0; b < layer1_size; b++) fwrite(&syn0[a * layer1_size + b]][6;1H[93m    [m, sizeof(real), 1, fo);
[93m566 [m      else for (b = 0; b < layer1_size; b++) fprintf(fo, "%lf ", syn0[a * layer1_sizee[8;1H[93m    [m + b]);
[93m567 [m      fprintf(fo, "\n");
[93m568 [m    }
[93m569 [m  } else {
[93m570 [m    // Run K-means on the word vectors
[93m571 [m    int clcn = classes, iter = 10, closeid;
[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int));
[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));
[93m574 [m    real closev, x;
[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));
[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;
[93m577 [m    for (a = 0; a < iter; a++) {
[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;
[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;
[93m580 [m      for (c = 0; c < vocab_size; c++) {
[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[24;1H[93m    [mayer1_size + d];
[93m582 [m[7C centcn[cl[c]]++;
[93m583 [m      }
[93m584 [m      for (b = 0; b < clcn; b++) {
[93m585 [m[7C closev = 0;[14;9H[?12l[?25hint *cen[42C[15;5H[14;5H[54C[?25l[29;1H[1m-- INSERT --[14;60H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l 6 */[?12l[?25h[?25l60 */[?12l[?25h[?25l09 */[?12l[?25h[?25l9行目 */[?12l[?25h[?25lで */[?12l[?25h[?25l解放 */[?12l[?25h[?25l *609行目で解放 */[14;65H[?12l[?25h[?25l*c609行目で解放 */[14;66H[?12l[?25h[?25lce609行目で解放 */[14;67H[?12l[?25h[?25len609行目で解放 */[14;68H[?12l[?25h[?25lnt609行目で解放 */[14;69H[?12l[?25h[?25ltc609行目で解放 */[14;70H[?12l[?25h[?25lcn609行目で解放 */[14;71H[?12l[?25h[?25lnに609行目で解放 */[14;73H[?12l[?25h[?25l[15;28r[15;1H[L[1;29r[14;73H動的に609行目で解[15;1H[93m    [m放 */[14;79H[?12l[?25h[?25lメモリ609行[15;4H[93m [m目で解放 */[14;85H[?12l[?25h[?25l割当66[15;1H[93m    [m09行目で解放 */[14;89H[?12l[?25h[?25l[94m>>[m[15;1H[93m    [m，609行目で解放 */[15;7H[?12l[?25h609[29;1H[K[15;9H[?25l[?12l[?25h[?25l[29;1H:[?12l[?25h610[?25l[27m[m[H[2J[1;1H[93m598 [m[9C for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[2;1H[93m    [m layer1_size + b];
[93m599 [m[9C if (x > closev) {
[93m600 [m[11C closev = x;
[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn); /* 572行目で確保したcentcnのメモリを解放 */
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  } /* 569行目elseから */
[93m613 [m  fclose(fo);
[93m614 [m} /* 545行目void TrainModel()から */
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }[14;9H[?12l[?25h[?25l[29;1H:[?12l[?25h572[?25l[27m[m[H[2J[1;1H[93m561 [m    // Save the word vectors
[93m562 [m    fprintf(fo, "%lld %lld\n", vocab_size, layer1_size);
[93m563 [m    for (a = 0; a < vocab_size; a++) {
[93m564 [m      fprintf(fo, "%s ", vocab[a].word);
[93m565 [m      if (binary) for (b = 0; b < layer1_size; b++) fwrite(&syn0[a * layer1_size + b]][6;1H[93m    [m, sizeof(real), 1, fo);
[93m566 [m      else for (b = 0; b < layer1_size; b++) fprintf(fo, "%lf ", syn0[a * layer1_sizee[8;1H[93m    [m + b]);
[93m567 [m      fprintf(fo, "\n");
[93m568 [m    }
[93m569 [m  } else {
[93m570 [m    // Run K-means on the word vectors
[93m571 [m    int clcn = classes, iter = 10, closeid;
[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int)); /* *centcnに動的にメモリ割当[94m>>[m[15;1H[93m    [m，609行目で解放 */
[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));
[93m574 [m    real closev, x;
[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));
[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;
[93m577 [m    for (a = 0; a < iter; a++) {
[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;
[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;
[93m580 [m      for (c = 0; c < vocab_size; c++) {
[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[25;1H[93m    [mayer1_size + d];
[93m582 [m[7C centcn[cl[c]]++;
[93m583 [m      }
[93m584 [m      for (b = 0; b < clcn; b++) {[14;9H[?12l[?25h[?25l[29;1H:[?12l[?25h610[?25l[27m[m[H[2J[1;1H[93m598 [m[9C for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[2;1H[93m    [m layer1_size + b];
[93m599 [m[9C if (x > closev) {
[93m600 [m[11C closev = x;
[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn); /* 572行目で確保したcentcnのメモリを解放 */
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  } /* 569行目elseから */
[93m613 [m  fclose(fo);
[93m614 [m} /* 545行目void TrainModel()から */
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }[14;9H[?12l[?25h[?25l[29;1H:[?12l[?25h [14;9H[?25l[29;1H/[?12l[?25hcent[?25l[14;14H[?12l[?25h[?25l[29;1H?[13;43H[?12l[?25h[?25l[29;1H[13;14H[?12l[?25h[?25l[29;1H[1;54H[?12l[?25h[?25l[29;1H[1;28r[1;1H[7L[1;29r[1;1H[93m591 [m[7C for (c = 0; c < layer1_size; c++) cent[layer1_size * b + c] /= closev;
[93m592 [m      }
[93m593 [m      for (c = 0; c < vocab_size; c++) {
[93m594 [m[7C closev = -10;
[93m595 [m[7C closeid = 0;
[93m596 [m[7C for (d = 0; d < clcn; d++) {
[93m597 [m[9C x = 0;[29;1H[K[1;47H[?12l[?25h[?25l[29;1H?cent[1;28r[1;1H[3L[1;29r[1;1H[93m588 [m[9C closev += cent[layer1_size * b + c] * cent[layer1_size * b + c];
[93m589 [m[7C }
[93m590 [m[7C closev = sqrt(closev);[29;1H[K[1;53H[?12l[?25h[?25l[29;1H?cent[1;25H[?12l[?25h[?25l[29;1H[1;28r[1;1H[L[1;29r[1;1H[93m587 [m[9C cent[layer1_size * b + c] /= centcn[b];[29;1H[K[1;44H[?12l[?25h[?25l[29;1H?cent[1;15H[?12l[?25h[?25l[29;1H[1;28r[1;1H[5L[1;29r[1;1H[93m582 [m[7C centcn[cl[c]]++;
[93m583 [m      }
[93m584 [m      for (b = 0; b < clcn; b++) {
[93m585 [m[7C closev = 0;
[93m586 [m[7C for (c = 0; c < layer1_size; c++) {[29;1H[K[1;13H[?12l[?25h[?25l[29;1H?cent[1;28r[1;1H[2L[1;29r[1;1H[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[2;1H[93m    [mayer1_size + d];[29;1H[K[1;47H[?12l[?25h[?25l[29;1H?cent[1;28r[1;1H[2L[1;29r[1;1H[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;
[93m580 [m      for (c = 0; c < vocab_size; c++) {[29;1H[K[1;38H[?12l[?25h[?25l[29;1H?cent[1;28r[1;1H[L[1;29r[1;1H[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;[29;1H[K[1;52H[?12l[?25h[?25l[29;1H?cent[1;28r[1;1H[3L[1;29r[1;1H[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real));
[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;
[93m577 [m    for (a = 0; a < iter; a++) {[29;1H[K[1;15H[?12l[?25hcent =[?25l [46m([mreal *[46m)[1;22H[?12l[?25h[?25l[m(real *)[1;23H[?12l[?25hrea[47C[2;5H[1;5H[68C[?25l[29;1H[1m-- INSERT --[1;74H[?12l[?25h[?25l[m [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l * */[?12l[?25h[?25l*c */[?12l[?25h[?25lce */[?12l[?25h[?25len */[?12l[?25h[?25lnt */[?12l[?25h[?25ltに */[?12l[?25h[?25l[2;28r[2;1H[L[1;29r[1;85Hメモ[94m>>[m[2;1H[93m    [mリ */[?12l[?25h[?25l割当 */[?12l[?25h[?25l， */[?12l[?25h[?25l6 */[?12l[?25h[?25l61 */[?12l[?25h[?25l10 */[?12l[?25h[?25l0行目 */[?12l[?25h[?25lで */[?12l[?25h[?25l解放 */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m574 [m    real closev, x;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int));[28;1H[94m@                                                                                        [1;58H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int)); /* *centcnに動的にメモリ割当[94m>>[m[2;1H[93m    [m，609行目で解放 */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m571 [m    int clcn = classes, iter = 10, closeid;[?12l[?25h[3;23H[4;58H[5;24H[7;26H[6;87Ht[2C[?25l動的[94m>>[m[7;1H[93m [m[3Cにメモリ割当，610行目で解放 */[7;7H[?12l[?25h[2C[2C[2C[2C[2C[2C[5;24H[4;58H[?25l[4;32H[46m([23C)[?12l[?25h[?25l[2;53H([mint[46m)[m[31C[94m>>[m[3;1H[93m [m[4;32H([23C)[2;57H[?12l[?25h[?25l(int)[31C[94m>>[m[3;1H[93m [2;56H[?12l[?25h[?25l[m[46m([mint[46m)[m[31C[94m>>[m[3;1H[93m [2;57H[?12l[?25h[?25l[m[2;36H[46m([m[16C(int)[46m)[m[30C[94m>>[m[3;1H[93m [2;58H[?12l[?25h[?25l[m[31C[94m>>[m[3;1H[93m [2;59H[?12l[?25h[?25l[m[2;36H([21C)[30C[94m>>[m[3;1H[93m [2;60H[?12l[?25h[m /* *ce[4;58H[?25l [?12l[?25h[?25l /[?12l[?25h[?25l/*[?12l[?25h[?25l [?12l[?25h[?25l *[?12l[?25h[?25l*/[?12l[?25h[?25l  */[?12l[?25h[?25l * */[?12l[?25h[?25l*c */[?12l[?25h[?25lcl */[?12l[?25h[?25llに */[?12l[?25h[?25l動的に */[?12l[?25h[?25lメモリ */[?12l[?25h[?25l割当 */[?12l[?25h[?25l， */[?12l[?25h[?25lf */[?12l[?25h[?25l */[4;88H[K[4;85H[?12l[?25h[29;1H[K[4;83H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hfee[?25l[29;4H[K[29;4H[?12l[?25h[?25l[29;3H[K[29;3H[?12l[?25hree(cl[?25l[27m[m[H[2J[1;1H[93m598 [m[9C for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[2;1H[93m    [m layer1_size + b];
[93m599 [m[9C if (x > closev) {
[93m600 [m[11C closev = x;
[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn); /* 572行目で確保したcentcnのメモリを解放 */
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  } /* 569行目elseから */
[93m613 [m  fclose(fo);
[93m614 [m} /* 545行目void TrainModel()から */
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;
[93m624 [m  }[15;9H[?12l[?25h[?25l[29;1H:[?12l[?25h575[?25l[27m[m[H[2J[1;1H[93m565 [m      if (binary) for (b = 0; b < layer1_size; b++) fwrite(&syn0[a * layer1_size + b]][2;1H[93m    [m, sizeof(real), 1, fo);
[93m566 [m      else for (b = 0; b < layer1_size; b++) fprintf(fo, "%lf ", syn0[a * layer1_sizee[4;1H[93m    [m + b]);
[93m567 [m      fprintf(fo, "\n");
[93m568 [m    }
[93m569 [m  } else {
[93m570 [m    // Run K-means on the word vectors
[93m571 [m    int clcn = classes, iter = 10, closeid;
[93m572 [m    int *centcn = (int *)malloc(classes * sizeof(int)); /* *centcnに動的にメモリ割当[94m>>[m[11;1H[93m    [m，609行目で解放 */
[93m573 [m    int *cl = (int *)calloc(vocab_size, sizeof(int)); /* *clに動的にメモリ割当， */
[93m574 [m    real closev, x;
[93m575 [m    real *cent = (real *)calloc(classes * layer1_size, sizeof(real)); /* *centに動的[94m>>[m[15;1H[93m    [mにメモリ割当，610行目で解放 */
[93m576 [m    for (a = 0; a < vocab_size; a++) cl[a] = a % clcn;
[93m577 [m    for (a = 0; a < iter; a++) {
[93m578 [m      for (b = 0; b < clcn * layer1_size; b++) cent[b] = 0;
[93m579 [m      for (b = 0; b < clcn; b++) centcn[b] = 1;
[93m580 [m      for (c = 0; c < vocab_size; c++) {
[93m581 [m[7C for (d = 0; d < layer1_size; d++) cent[layer1_size * cl[c] + d] += syn0[c * ll[22;1H[93m    [mayer1_size + d];
[93m582 [m[7C centcn[cl[c]]++;
[93m583 [m      }
[93m584 [m      for (b = 0; b < clcn; b++) {
[93m585 [m[7C closev = 0;
[93m586 [m[7C for (c = 0; c < layer1_size; c++) {
[93m587 [m[9C cent[layer1_size * b + c] /= centcn[b];[14;9H[?12l[?25h[13;9H[12;5H    int *cl =[?25l [46m([mint *[46m)[12;19H[?12l[?25h[?25l[m(int *)[?12l[?25hint [?25l[46m([mint *[46m)[?12l[?25h[?25l[m(int *)[?12l[?25hcallo[?25lc[46m([23C)[12;32H[?12l[?25h[?25l[m([23C)[12;33H[?12l[?25hvocab_size, sizeo[?25lf[46m([mint[46m)[?12l[?25h[?25l[m(int)[?12l[?25hin[?25l[46m([mint[46m)[?12l[?25h[?25l[12;32H([m[18C(int)[46m)[?12l[?25h[?25l[m[12;32H([23C)[?12l[?25h; /* *cl[2C[2C[2C[2C[2C[2C[2C[2C[2C[2C[?25l[29;1H[1m-- INSERT --[12;86H[?12l[?25h[?25l[m6 */[?12l[?25h[?25l61 */[12;87H[?12l[?25h[?25l[13;28r[13;1H[L[1;29r[12;86H11 **[13;1H[93m    [m/[12;88H[?12l[?25h[?25l1行 [13;1H[93m    [m目 */[?12l[?25h[?25lで */[?12l[?25h[?25l解放 */[?12l[?25h[29;1H[K[13;11H[?25l[?12l[?25h[?25l[29;1H:[?12l[?25h609[?25l[27m[m[H[2J[1;1H[93m597 [m[9C x = 0;
[93m598 [m[9C for (b = 0; b < layer1_size; b++) x += cent[layer1_size * d + b] * syn0[c **[3;1H[93m    [m layer1_size + b];
[93m599 [m[9C if (x > closev) {
[93m600 [m[11C closev = x;
[93m601 [m[11C closeid = d;
[93m602 [m[9C }
[93m603 [m[7C }
[93m604 [m[7C cl[c] = closeid;
[93m605 [m      }
[93m606 [m    }
[93m607 [m    // Save the K-means classes
[93m608 [m    for (a = 0; a < vocab_size; a++) fprintf(fo, "%s %d\n", vocab[a].word, cl[a]);
[93m609 [m    free(centcn); /* 572行目で確保したcentcnのメモリを解放 */
[93m610 [m    free(cent);
[93m611 [m    free(cl);
[93m612 [m  } /* 569行目elseから */
[93m613 [m  fclose(fo);
[93m614 [m} /* 545行目void TrainModel()から */
[93m615 
616 [mint ArgPos(char *str, int argc, char **argv) {
[93m617 [m  int a;
[93m618 [m  for (a = 1; a < argc; a++) if (!strcmp(str, argv[a])) {
[93m619 [m    if (a == argc - 1) {
[93m620 [m      printf("Argument missing for %s\n", str);
[93m621 [m      exit(1);
[93m622 [m    }
[93m623 [m    return a;[14;9H[?12l[?25h[15;9Hfre[?25le[46m([mcent[46m)[?12l[?25h[?25l[m(cent)[?12l[?25hcen[?25l[46m([mcent[46m)[?12l[?25h[?25l[m(cent)[?12l[?25h[?25l[29;1H[1m-- INSERT --[15;20H[?12l[?25h[?25l[m [?12l[?25h[?25l /* 572行目で確保したcentcnのメモリを解放 */[?12l[?25h[16;18H[?25l;/* 572行目で確保したcentcnのメモリを解放 */[?12l[?25h[29;1H[K[16;60H[?25l[?12l[?25h[?25l[29;1H1 change; before #144  2 seconds ago[16;18H[K[16;17H[?12l[?25h[?25l[29;1H[1m-- INSERT --[m[29;13H[K[16;18H[?12l[?25h[?25l [?12l[?25h[?25l /* 572行目で確保したcentcnのメモリを解放 */[?12l[?25h[15;62H[?25l7行目で確保したcentcnのメモリを解放 */[15;63H[K[15;26H[?12l[?25h[?25l75行目で確保したcentcnのメモリを解放 */[15;27H[?12l[?25h[16;27H[?25l7行目で確保したcentcnのメモリを解放 */[16;61H[K[16;24H[?12l[?25h[?25l73行目で確保したcentcnのメモリを解放 */[16;25H[?12l[?25h[2C[2C[2C[2C[2C[2C[2Ccentcn[?25lcのメモリを解放 */[16;61H[K[16;44H[?12l[?25h[?25ltのメモリを解放 */[16;60H[K[16;43H[?12l[?25h[?25lnのメモリを解放 */[16;59H[K[16;42H[?12l[?25h[?25leのメモリを解放 */[16;58H[K[16;41H[?12l[?25h[?25lcのメモリを解放 */[16;57H[K[16;40H[?12l[?25h[?25lclのメモリを解放 */[16;41H[?12l[?25h[15;41Hcentcn[?25lcのメモリを解放 */[15;63H[K[15;46H[?12l[?25h[?25ltのメモリを解放 */[15;62H[K[15;45H[?12l[?25h[?25lnのメモリを解放 */[15;61H[K[15;44H[?12l[?25h[?25lntのメモリを解放 */[15;45H[?12l[?25h[29;1H[K[15;44H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hfree[?25l[16;9H[?12l[?25h[?25l[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[27m[m[H[2J[1;1H[93m 45 [mreal alpha = 0.025, starting_alpha, sample = 1e-3;
[93m 46 [mreal *syn0, *syn1, *syn1neg, *expTable;
[93m 47 [mclock_t start;
[93m 48 
 49 [mint hs = 0, negative = 5; /* hsは344行目，negativeは350行目で初出 */
[93m 50 [mconst int table_size = 1e8;
[93m 51 [mint *table;
[93m 52 [m/* void型(値を返さない関数)InitUnigramTable()←かなり後に出てくる */
[93m 53 [mvoid InitUnigramTable() {
[93m 54 [m  int a, i;
[93m 55 [m  double train_words_pow = 0;
[93m 56 [m  double d1, power = 0.75;
[93m 57 [m  table = (int *)malloc(table_size * sizeof(int)); /* table_size * sizeof(int)分のメ[94m>>[m[14;1H[93m    [mモリを動的に割り当て(free()でメモリを解放) */
[93m 58 [m  for (a = 0; a < vocab_size; a++) train_words_pow += pow(vocab[a].cn, power);
[93m 59 [m  i = 0;
[93m 60 [m  d1 = pow(vocab[i].cn, power) / train_words_pow;
[93m 61 [m  for (a = 0; a < table_size; a++) {
[93m 62 [m    table[a] = i;
[93m 63 [m    if (a / (double)table_size > d1) {
[93m 64 [m      i++;
[93m 65 [m      d1 += pow(vocab[i].cn, power) / train_words_pow;
[93m 66 [m    }
[93m 67 [m    if (i >= vocab_size) i = vocab_size - 1;
[93m 68 [m  }
[93m 69 [m}
[93m 70 
 71 [m// Reads a single word from a file, assuming space + tab + EOL to be word boundaries[94m@                                                                                        [m[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[14;26H[?12l[?25h[?25l[m[29;1H/free[29;6H[K[29;1H[27m[m[H[2J[1;1H[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[2;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[4;1H[93m    [m1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[10;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが[12;1H[93m    [m0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /* ハッシュ[94m>>[m[17;1H[93m    [mを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }
[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struct vocab__[25;1H[93m    [mword));
[93m168 [m  // Allocate memory for the binary tree construction
[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));[14;11H[?12l[?25hfre[?25l[29;1H/[?12l[?25hvocab[a][?25l[38;5;224msearch hit BOTTOM, continuing at TOP[m[97m[41mE486: Pattern not found: vocab[a][m[29;34H[K[14;14H[?12l[?25h[?25l[29;1H/vocab[a][29;10H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[m[97m[41mE486: Pattern not found: vocab[a][m[29;34H[K[14;14H[?12l[?25h[?25l[29;1H/vocab[a][29;10H[K[29;1H[38;5;224msearch hit BOTTOM, continuing at TOP[m[97m[41mE486: Pattern not found: vocab[a][m[29;34H[K[14;14H[?12l[?25h[?25l[29;1H[K[29;1H/[?12l[?25hvocab[[?25l[14;16H[?12l[?25h[?25l[29;1H?[11;57H[?12l[?25h[?25l[29;1H[11;14H[?12l[?25h[?25l[29;1H[3;84H[?12l[?25h[?25l[29;1H[3;14H[?12l[?25h[?25l[29;1H[27m[m[H[2J[1;1H[93m118 [m  return SearchVocab(word); /* 単語wordの語彙中での位置を返す */
[93m119 [m}
[93m120 
121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */
[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[6;1H[93m    [mocab() */
[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字 [8;1H[93m    [m長+1を代入) */
[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[10;1H[93m    [mlenghに最大文字数を代入 */
[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[12;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */
[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコピー */
[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */
[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */
[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */
[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size以上の時 **[18;1H[93m    [m/
[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */
[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struct vocab__[21;1H[93m    [mword)); /*  */
[93m133 [m  }
[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m136 [m  vocab_hash[hash] = vocab_size - 1;
[93m137 [m  return vocab_size - 1;
[93m138 [m}
[93m139 [14;36H[?12l[?25h[?25l[m[29;1H?vocab[[14;7H[?12l[?25h[?25l[29;1H[13;48H[?12l[?25h[?25l[29;1H/[14;7H[?12l[?25h[?25l[29;1H[14;36H[?12l[?25h[?25l[29;1H[1;28r[1;1H[14M[1;29r[15;1H[93m140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */
[93m141 [mint VocabCompare(const void *a, const void *b) {
[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;
[93m143 [m}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[21;1H[93m    [mに並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[26;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[28;1H[93m    [m1]のアドレス，vocab_size -1， */[29;1H[K[27;14H[?12l[?25h[?25l

/vocab[[27;84H[?12l[?25h[?25l

[1;28r[1;1H[8M[1;29r[21;1H[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[26;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが [28;1H[93m    [m0でない時 */[29;1H[K[27;14H[?12l[?25h[?25l

/vocab[[27;57H[?12l[?25h[?25l

[1;28r[1;1H[2M[1;29r[27;1H[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */[29;1H[K[28;16H[?12l[?25h[?25l
?vocab[[25;57H[?12l[?25h[?25l[29;1H[25;14H[?12l[?25h[?25l[29;1H[17;84H[?12l[?25h[?25l[29;1H[17;14H[?12l[?25h[?25l[29;1H[1;28r[1;1H[11L[1;29r[1;1H[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */
[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */
[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */
[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size以上の時 **[5;1H[93m    [m/
[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */
[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struct vocab__[8;1H[93m    [mword)); /*  */
[93m133 [m  }
[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */
[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;[28;1H[94m@                                                                                        [m[29;1H[K[1;36H[?12l[?25h[?25l[29;1H?vocab[[1;7H[?12l[?25h[?25l[29;1H[1;28r[1;1H[L[1;29r[1;1H[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコピー */[29;1H[K[1;48H[?12l[?25h[?25l[29;1H?vocab[[1;14H[?12l[?25h[?25l[29;1H[1;28r[1;1H[2L[1;29r[1;1H[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[2;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入 */[29;1H[K[2;39H[?12l[?25hvoca[?25lb[46m[[10C][2;44H[?12l[?25h[?25l[m[[10C][2;45H[?12l[?25hvocab_siz[?25l[2;44H[46m[[10C][?12l[?25h[?25l[m[2;44H[[10C][?12l[?25h.word[2C[2C[2C [?25l[1;28r[1;1H[2L[1;29r[1;1H[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[2;1H[93m    [mlenghに最大文字数を代入 */[?12l[?25h[4;68H[?25l[29;1H[1m-- INSERT --[4;68H[?12l[?25h[?25l[m( */[?12l[?25h[?25l[46m()[m */[?12l[?25h[?25l[?12l[?25h[?25l[46m([m1[46m)[m */[?12l[?25h[?25l15[46m)[m */[?12l[?25h[?25l58[46m)[m */[?12l[?25h[?25l8行目[46m)[m */[?12l[?25h[?25lで[46m)[m */[?12l[?25h[?25l解放[46m)[m */[?12l[?25h[29;1H[K[4;79H[?25l[4;67H([13C)[?12l[?25h[?25l[29;1H:[?12l[?25h158[?25l[27m[m[H[2J[1;1H[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[2;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[4;1H[93m    [m1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[10;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが [12;1H[93m    [m0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* vocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /* ハッシュ[94m>>[m[17;1H[93m    [mを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }
[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struct vocab__[25;1H[93m    [mword));
[93m168 [m  // Allocate memory for the binary tree construction
[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));[14;11H[?12l[?25hfre[?25le[46m([13C)[14;15H[?12l[?25h[?25l[m([13C)[14;16H[?12l[?25hvoca[?25lb[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h.wor[?25l[14;15H[46m([13C)[?12l[?25h[?25l[m[14;15H([13C)[?12l[?25h; /* [?25l[29;1H[1m-- INSERT --[14;36H[?12l[?25h[?25l[m 1vocab[a].wordのメモリを解放 */[14;36H[?12l[?25h[?25l12vocab[a].wordのメモリを解放 */[14;37H[?12l[?25h[?25l25vocab[a].wordのメモリを解放 */[14;38H[?12l[?25h[?25l5行目vocab[a].wordのメモリを解放 */[14;42H[?12l[?25h[?25lでvocab[a].wordのメモリを解放 */[14;44H[?12l[?25h[?25l確保したvocab[a].wordのメモリを解放 */[14;52H[?12l[?25h[29;1H[K[14;50H[?25l[?12l[?25h[?25l[29;1H/[?12l[?25hfree[?25l[1;28r[1;1H[13M[1;29r[16;1H[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 
175 [m// Reduces the vocabulary by removing infrequent tokens
[93m176 [mvoid ReduceVocab() {
[93m177 [m  int a, b = 0;
[93m178 [m  unsigned int hash;
[93m179 [m  for (a = 0; a < vocab_size; a++) if (vocab[a].cn > min_reduce) {
[93m180 [m    vocab[b].cn = vocab[a].cn;
[93m181 [m    vocab[b].word = vocab[a].word;
[93m182 [m    b++;
[93m183 [m  } else free(vocab[a].word);[29;1H[K[28;14H[?12l[?25h[?25l
?free[1;11H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m157 [m      vocab_size--; /* vocab_sizeから1引く */[29;1H[K[1;11H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが[2;1H[93m    [m0でない時 */[1;11H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[2;1H[93m    [min_count以下の頻度の単語をvocabから除外する */[1;11H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m154 [m  for [46m([ma = 0; a < size; a++[46m)[m {[1;11H[?12l[?25h[?25l([20C)[2;11H[?12l[?25h[4;11H[6;11H[7;11H[8;11H[7;11H[6;11H[4;11H[?25l [46m([37C)[4;12H[?12l[?25h[?25l[m([46m([23C)[m[12C)[4;13H[?12l[?25h[?25l([23C)[4;14H[?12l[?25hvoca[?25lb[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h.cn < min_coun[?25l[4;13H[46m([23C)[?12l[?25h[?25l[m[4;13H([23C)[?12l[?25h &&[?25l [46m([ma != 0[46m)[4;42H[?12l[?25h[?25l[m(a != 0)[4;43H[?12l[?25ha != [?25l[46m([ma != 0[46m)[?12l[?25h[?25l[4;12H([m[29C(a != 0)[46m)[?12l[?25h[?25l[m[4;12H([37C)[?12l[?25h[?25l [46m{[8;9H}[4;52H[?12l[?25h[?25l[m{[8;9H}[6;49H[?12l[?25h[7;52H[?25l[8;16H[46m{[15;9H}[8;16H[?12l[?25h[?25l[m{[15;9H}[9;52H[?12l[?25h[11;42H[12;52H[13;31H[14;37H[?25l[8;16H[46m{[15;9H}[?12l[?25h[?25l[1;34H{[m[8;16H{[15;9H}[16;7H[46m}[?12l[?25h[?25l[m[1;34H{[8;16H[46m{[15;9H}[m[16;7H}[15;9H[?12l[?25h[?25l[8;16H{[15;9H}[14;37H[?12l[?25h[13;31H[12;52H[11;42H[9;52H[?25l[8;16H[46m{[15;9H}[8;16H[?12l[?25h[?25l[m{[15;9H}[7;52H[?12l[?25h[6;49H[?25l[4;52H[46m{[8;9H}[4;52H[?12l[?25h[?25l[m{[8;9H}[2;52H[?12l[?25h[?25l[1;34H[46m{[16;7H}[1;34H[?12l[?25h[?25l[m{[16;7H}[2;52H[?12l[?25h[?25l[37Cmm[3;1H[93m [m[4;52H[46m{[8;9H}[4;52H[?12l[?25h[?25l[m{[8;9H}[6;49H[?12l[?25h[7;52H[?25l[8;16H[46m{[15;9H}[8;16H[?12l[?25h[?25l[m{[15;9H}[9;52H[?12l[?25h[11;42H[12;52H[13;31H[14;37H[?25l[8;16H[46m{[15;9H}[?12l[?25h[?25l[1;34H{[m[8;16H{[15;9H}[16;7H[46m}[?12l[?25h[?25l[m[1;34H{[16;7H}[17;52H[?12l[?25h[19;52H[?25l[20;40H[46m{[23;7H}[20;40H[?12l[?25h[?25l[m{[23;7H}[21;52H[?12l[?25h[22;52H[?25l[20;40H[46m{[23;7H}[?12l[?25h[?25l[m[20;40H{[23;7H}[24;5H[?12l[?25h[25;5H[26;52H[27;24H[28;19H[?25l[1;28r[28;1H
[1;29r[28;1H[93m178 [m  unsigned int hash;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m179 [m  for (a = 0; a < vocab_size; a++) if (vocab[a].cn > min_reduce) {
[93m180 [m    vocab[b].cn = vocab[a].cn;[27;52H[?12l[?25h[28;34H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m181 [m    vocab[b].word = vocab[a].word;
[93m182 [m    b++;[27;38H[?12l[?25h[28;12H[?25l[1;28r[28;1H
[1;29r[28;1H[93m183 [m  } else free(vocab[a].word);[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m184 [m  vocab_size = b;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m185 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[28;52H[?12l[?25h[27;21H[26;33H[25;12H[24;38H[23;34H[22;52H[21;24H[20;19H[19;24H[18;52H[17;5H[16;5H[?25l[12;40H[46m{[15;7H}[?12l[?25h[?25l[m[12;40H{[15;7H}[14;52H[?12l[?25h[13;52H[?25l[12;40H[46m{[15;7H}[12;40H[?12l[?25h[?25l[m{[15;7H}[11;52H[?12l[?25h[9;52H[8;7H[7;9H[6;37H[5;31H[4;52H[3;42H[1;52H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m159 [m    } else [46m{[8;9H}[1;16H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m158 [m      free(vocab[a].word); /* 125行目で確保したvocab[a].wordのメモリを解放 */[2;16H{[9;9H}[1;52H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m157 [m      vocab_size--; /* vocab_sizeから1引く */[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) [46m{[m /* vocab[a].cnがmin_count未満かつaが[2;1H[93m    [m0でない時 */[5;9H[46m}[1;52H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[2;1H[93m    [min_count以下の頻度の単語をvocabから除外する */[3;52H{[7;9H}[1;52H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m154 [m  for (a = 0; a < size; a++) [46m{[16;7H}[1;34H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m153 [m  train_words = 0;[2;34H{[17;7H}[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m152 [m  size = vocab_size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[1;52H[?12l[?25h[2;24H[3;22H[?25l[4;34H[46m{[19;7H}[4;34H[?12l[?25h[?25l[m{[19;7H}[5;52H[?12l[?25h[?25l[37Cmm[6;1H[93m [m[7;52H[46m{[11;9H}[7;52H[?12l[?25h[?25l[m{[11;9H}[9;49H[?12l[?25h[10;52H[?25l[11;16H[46m{[18;9H}[11;16H[?12l[?25h[?25l[m{[18;9H}[10;52H[?12l[?25h[9;49H[?25l[7;52H[46m{[11;9H}[7;52H[?12l[?25h[?25l[m{[11;9H}[5;52H[?12l[?25h[?25l[4;34H[46m{[19;7H}[4;34H[?12l[?25h[?25l[m{[19;7H}[3;22H[?12l[?25h[2;24H[1;52H[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[2;1H[93m    [m1]のアドレス，vocab_size -1， */[1;52H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[2;1H[93m    [m/s>を先頭に保つ */[1;52H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m148 [m  unsigned int hash;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m147 [m  int a, size;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m146 [mvoid SortVocab() { /* void関数SortVocab() */[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[2;1H[93m    [mに並替え */[1;52H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m144 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m143 [m}[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;[1;52H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m141 [mint VocabCompare(const void *a, const void *b) [46m{[3;5H}[1;52H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */[2;52H{[4;5H}[1;51H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m139 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m138 [m}[28;1H[94m@                                                                                        [1;5H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m137 [m  return vocab_size - 1;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m136 [m  vocab_hash[hash] = vocab_size - 1;[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;[1;52H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */[1;52H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m133 [m  }[28;1H[94m@                                                                                        [1;7H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struct vocab__[2;1H[93m    [mword)); /*  */[28;1H[94m@                                                                                        [1;52H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */[1;52H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size以上の時 **[2;1H[93m    [m/[1;52H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */[1;51H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[46m[[mvocab_size[46m][m.cnに0を代入 */[28;1H[94m@                                                                                        [1;52H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコピー */[2;41H[[10C][1;52H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[2;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入(158行目で解放) */[1;52H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は [2;1H[93m    [mlenghに最大文字数を代入 */[1;52H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字 [2;1H[93m    [m長+1を代入) */[28;1H[94m@                                                                                        [1;52H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[2;1H[93m    [mocab() */[1;51H[?12l[?25h[3;52H[5;52H[7;52H[9;52H[7;52H[5;52H[3;52H[1;51H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */[1;51H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m120 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m119 [m}[?12l[?25h[2;5H[3;51H[4;51H[?25l[46m{[m[52CVV[5;1H[93m [m[26;5H[46m}[4;36H[?12l[?25h[?25l[m[53CVV[5;1H[93m [26;5H[?12l[?25h[?25l[4;36H[?12l[?25h[?25l[m[53CVV[5;1H[93m [26;5H[?12l[?25h[?25l[4;36H[?12l[?25h[?25l[m[53CVV[5;1H[93m [26;5H[?12l[?25h[?25l[4;36H[?12l[?25h[?25l[29;1H[m:[?12l[?25h158[?25l[27m[m[H[2J[1;1H[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[2;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[4;1H[93m    [m1]のアドレス，vocab_size -1， */
[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m152 [m  size = vocab_size;
[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {
[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[10;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが [12;1H[93m    [m0でない時 */
[93m157 [m      vocab_size--; /* vocab_sizeから1引く */
[93m158 [m      free(vocab[a].word); /* 125行目で確保したvocab[a].wordのメモリを解放 */
[93m159 [m    } else {
[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /* ハッシュ[94m>>[m[17;1H[93m    [mを */
[93m161 [m      hash=GetWordHash(vocab[a].word);
[93m162 [m      while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m163 [m      vocab_hash[hash] = a;
[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }
[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struct vocab__[25;1H[93m    [mword));
[93m168 [m  // Allocate memory for the binary tree construction
[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));[14;11H[?12l[?25h[13;11H[11;11H[9;11H[?25l[8;11H[46m([20C)[8;11H[?12l[?25h[?25l[m([20C)[7;11H[?12l[?25h[6;11H[?25l[5;11H[46m([31C)[5;11H[?12l[?25h[?25l[m([31C)[3;11H[?12l[?25h[1;11H[?25l[1;28r[1;1H[L[1;29r[1;1H[93m148 [m  unsigned int hash;[1;11H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m147 [m  int a, size;[1;11H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m146 [mvoid SortVocab() { /* void関数SortVocab() */[1;11H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[2;1H[93m    [mに並替え */[1;11H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m144 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m143 [m}[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;[1;11H[?12l[?25h[2;5H[3;5H[4;11H[6;11H[7;11Ha, size;[?25l[6;19H[46m()[?12l[?25h[?25l([?12l[?25h[?25l[m()[?12l[?25h [?25l[1;28r[1;1H[12M[1;29r[17;1H[93m164 [m      train_words += vocab[a].cn;
[93m165 [m    }
[93m166 [m  }
[93m167 [m  vocab = (struct vocab_word *)realloc(vocab, (vocab_size + 1) * sizeof(struct vocab__[21;1H[93m    [mword));
[93m168 [m  // Allocate memory for the binary tree construction
[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));
[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 [27;5H[?12l[?25h[?25l[1;28r[m[1;1H[7L[1;29r[1;1H[93m146 [mvoid SortVocab() [46m{[m /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[5;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[7;1H[93m    [m1]のアドレス，vocab_size -1， */[1;22H[?12l[?25h[?25l[1;28r[1;1H[7M[1;29r[22;1H[93m168 [m  // Allocate memory for the binary tree construction
[93m169 [m  for (a = 0; a < vocab_size; a++) {
[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));
[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 [27;5H[?12l[?25h[?25l[1;28r[m[1;1H[7L[1;29r[1;1H[93m146 [mvoid SortVocab() [46m{[m /* void関数SortVocab() */
[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;
[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[5;1H[93m    [m/s>を先頭に保つ */
[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[7;1H[93m    [m1]のアドレス，vocab_size -1， */[1;22H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[2;1H[93m    [mに並替え */[3;22H{[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m144 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m143 [m}[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m141 [mint VocabCompare(const void *a, const void *b) {[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m140 [m// Used later for sorting by word counts /* 単語数で並替えをする際に使用 */[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m139 [?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m138 [m}[28;1H[94m@                                                                                        [1;5H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m137 [m  return vocab_size - 1;[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m136 [m  vocab_hash[46m[[mhash[46m][m = vocab_size - 1;[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m135 [m  while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;[2;17H[hash][1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m134 [m  hash = GetWordHash(word); /* hashにwordのhashを代入 */[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m133 [m  }[28;1H[94m@                                                                                        [1;7H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m132 [m    vocab = (struct vocab_word *)realloc(vocab, vocab_max_size * sizeof(struct vocab__[2;1H[93m    [mword)); /*  */[28;1H[94m@                                                                                        [1;22H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m131 [m    vocab_max_size += 1000; /* vocab_max_sizeに1000を足す */[1;22H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m130 [m  if (vocab_size + 2 >= vocab_max_size) { /* vocab_size + 2がvocab_max_size以上の時 **[2;1H[93m    [m/[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m129 [m  // Reallocate memory if needed /* 必要時にメモリの割当を変更 */[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m128 [m  vocab_size++; /* vocab_sizeに1を足す */[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m127 [m  vocab[vocab_size].cn = 0; /* vocab[vocab_size].cnに0を代入 */[28;1H[94m@                                                                                        [1;22H[?12l[?25h[?25l[1;28r[m[1;1H[L[1;29r[1;1H[93m126 [m  strcpy(vocab[vocab_size].word, word); /* vocab[vocab_size].wordにwordをコピー */[1;22H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m125 [m  vocab[vocab_size].word = (char *)calloc(length, sizeof(char)); /* length個のcharサ[94m>>[m[2;1H[93m    [mイズのメモリを確保し，char型にしてvocab[vocab_size].wordに代入(158行目で解放) */[1;22H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m124 [m  if (length > MAX_STRING) length = MAX_STRING; /* lengthが最大文字数より大きい場合は[2;1H[93m    [mlenghに最大文字数を代入 */[1;22H[?12l[?25h[?25l[1;28r[1;1H[2L[1;29r[1;1H[93m123 [m  unsigned int hash, length = strlen(word) + 1; /* 符号無int型bash, length(wordの文字[2;1H[93m    [m長+1を代入) */[28;1H[94m@                                                                                        [1;22H[?12l[?25h[?25l[1;28r[m[1;1H[2L[1;29r[1;1H[93m122 [mint AddWordToVocab(char *word) { /* char型ポインタwordを引数に持つint型関数AddWordToVV[2;1H[93m    [mocab() */[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m121 [m// Adds a word to the vocabulary /* 単語を語彙に加える */[1;22H[?12l[?25h[?25l[1;28r[1;1H[L[1;29r[1;1H[93m120 [?12l[?25h[2;22H[3;22H[5;22H[7;22H[9;22H[11;22H[12;22H[13;22H[14;22H[15;22H[17;22H[18;22H[?25l[m[15;45H[46m{[m[43C**[16;1H[93m [m[20;7H[46m}[?12l[?25h[?25l[m[15;45H{[43C**[16;1H[93m [m[20;7H}[21;22H[?12l[?25h[22;22H[?25l[23;17H[46m[[mhash[46m][?12l[?25h[?25l[m[hash][24;22H[?12l[?25h[?25l[3;36H[46m{[m[52CVV[4;1H[93m [m[25;5H[46m}[?12l[?25h[?25l[m[3;36H{[52CVV[4;1H[93m [m[25;5H}[26;5H[?12l[?25h[27;22H[26;5H[?25l[3;36H[46m{[m[52CVV[4;1H[93m [m[25;5H[46m}[?12l[?25h[?25l[m[3;36H{[52CVV[4;1H[93m [m[25;5H}[24;22H[?12l[?25h[?25l[23;17H[46m[[mhash[46m][?12l[?25h[?25l[m[hash][22;22H[?12l[?25h[21;22H[?25l[15;45H[46m{[m[43C**[16;1H[93m [m[20;7H[46m}[?12l[?25h[?25l[m[15;45H{[43C**[16;1H[93m [m[20;7H}[18;22H[?12l[?25h[17;22H[15;22H[14;22H[13;22H[12;22H[11;22H[9;22H[?25l[9;12H[46m[[10C][m[65C[94m>>[m[10;1H[93m [9;23H[?12l[?25h[?25l[m[9;12H[[10C][65C[94m>>[m[10;1H[93m [9;24H[?12l[?25h[m.wor[11;28H[9;28Hd =[?25l [46m([mchar *[46m)[m[49C[94m>>[m[10;1H[93m [9;32H[?12l[?25h[?25l[m(char *)[49C[94m>>[m[10;1H[93m [9;33H[?12l[?25h[mch[10;84H[?25l[10;67H[46m([13C)[?12l[?25h[?25l[m[10;67H([13C)[?12l[?25h[?25l[46m([13C)[10;67H[?12l[?25h[?25l[m158行目で解放) */[10;84H[K[10;67H[?12l[?25h[?25l58行目で解放) */[10;83H[K[10;67H[?12l[?25h[?25l8行目で解放) */[10;82H[K[10;67H[?12l[?25h[?25l行目で解放) */[10;81H[K[10;67H[?12l[?25h[?25l目で解放) */[10;79H[K[10;67H[?12l[?25h[?25lで解放) */[10;77H[K[10;67H[?12l[?25h[?25l解放) */[10;75H[K[10;67H[?12l[?25h[?25l放) */[10;73H[K[10;67H[?12l[?25h[?25l) */[10;71H[K[10;67H[?12l[?25h[?25l */[10;70H[K[10;67H[?12l[?25h[11;86H[12;67H[13;45H[14;69H[16;5H[17;64H[19;18H[?25l[15;45H[46m{[m[43C**[16;1H[93m [m[20;7H[46m}[?12l[?25h[?25l[m[15;45H{[43C**[16;1H[93m [m[20;7H}[21;60H[?12l[?25h[22;73H[23;40H[24;28H[?25l[3;36H[46m{[m[52CVV[4;1H[93m [m[25;5H[46m}[?12l[?25h[?25l[m[3;36H{[52CVV[4;1H[93m [m[25;5H}[26;5H[?12l[?25h[27;79H[28;52H[?25l[1;28r[28;1H
[1;29r[28;1H[93m142 [m    return ((struct vocab_word *)b)->cn - ((struct vocab_word *)a)->cn;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[26;52H[46m{[m

[93m143 [m[46m}[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[24;52H{[26;5H}
[93m144 
145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>[28;1H@                                                                                        [27;5H[?12l[?25h[?25l[1;28r[m[1;1H[2M[1;29r[26;1H[93m145 [m// Sorts the vocabulary by frequency using word counts /* 語彙を単語数を用いて頻度順[94m>>[m[27;1H[93m    [mに並替え */
[93m146 [mvoid SortVocab() { /* void関数SortVocab() */[27;15H[?12l[?25h[28;48H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m147 [m  int a, size;
[93m148 [m  unsigned int hash;[27;19H[?12l[?25h[28;24H[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m149 [m  // Sort the vocabulary and keep </s> at the first position /* 語彙を並替えて文字列<<[28;1H[93m    [m/s>を先頭に保つ */[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m150 [m  qsort(&vocab[1], vocab_size - 1, sizeof(struct vocab_word), VocabCompare);/* vocab[[[28;1H[93m    [m1]のアドレス，vocab_size -1， */[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m151 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m152 [m  size = vocab_size;[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m153 [m  train_words = 0;
[93m154 [m  for (a = 0; a < size; a++) {[27;22H[?12l[?25h[28;34H[?25l[1;28r[1;1H[3M[1;29r[26;1H[93m155 [m    // Words occuring less than min_count times will be discarded from the vocab /* mm[27;1H[93m    [min_count以下の頻度の単語をvocabから除外する */
[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが[28;1H[94m@                                                                                        [27;50H[?12l[?25h[?25l[1;28r[m[28;1H
[1;29r[27;1H[93m156 [m    if ((vocab[a].cn < min_count) && (a != 0)) { /* vocab[a].cnがmin_count未満かつaが [28;1H[93m    [m0でない時 */[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m157 [m      vocab_size--; /* vocab_sizeから1引く */[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m158 [m      free(vocab[a].word); /* 125行目で確保したvocab[a].wordのメモリを解放 */[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m159 [m    } else {[?12l[?25h[?25l[1;28r[1;1H[2M[1;29r[27;1H[93m160 [m      // Hash will be re-computed, as after the sorting it is not actual /* ハッシュ[94m>>[m[28;1H[93m    [mを */[?12l[?25h[?25l[1;28r[28;1H
[1;29r[28;1H[93m161 [m      hash=GetWordHash(vocab[a].word);[?12l[?25h[27;9H[25;16H[24;81H[?25l[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h[?25l[46m[[ma[46m][?12l[?25h[?25l[m[a][?12l[?25h[?25l 25行目で確保したvocab[a].wordのメモリを解放 */[24;81H[K[24;35H[?12l[?25h[?25l 5行目で確保したvocab[a].wordのメモリを解放 */[24;80H[K[24;35H[?12l[?25h[?25l 行目で確保したvocab[a].wordのメモリを解放 */[24;79H[K[24;35H[?12l[?25h[?25l 目で確保したvocab[a].wordのメモリを解放 */[24;77H[K[24;35H[?12l[?25h[?25l で確保したvocab[a].wordのメモリを解放 */[24;75H[K[24;35H[?12l[?25h[?25l 確保したvocab[a].wordのメモリを解放 */[24;73H[K[24;35H[?12l[?25h[?25l 保したvocab[a].wordのメモリを解放 */[24;71H[K[24;35H[?12l[?25h[?25l したvocab[a].wordのメモリを解放 */[24;69H[K[24;35H[?12l[?25h[?25lたvocab[a].wordのメモリを解放 */[24;67H[K[24;35H[?12l[?25h[?25l vocab[a].wordのメモリを解放 */[24;65H[K[24;35H[?12l[?25h[?25l[29;1H/[?12l[?25hfree([?25l[27m[m[H[2J[1;1H[93m170 [m    vocab[a].code = (char *)calloc(MAX_CODE_LENGTH, sizeof(char));
[93m171 [m    vocab[a].point = (int *)calloc(MAX_CODE_LENGTH, sizeof(int));
[93m172 [m  }
[93m173 [m}
[93m174 
175 [m// Reduces the vocabulary by removing infrequent tokens
[93m176 [mvoid ReduceVocab() {
[93m177 [m  int a, b = 0;
[93m178 [m  unsigned int hash;
[93m179 [m  for (a = 0; a < vocab_size; a++) if (vocab[a].cn > min_reduce) {
[93m180 [m    vocab[b].cn = vocab[a].cn;
[93m181 [m    vocab[b].word = vocab[a].word;
[93m182 [m    b++;
[93m183 [m  } else free(vocab[a].word);
[93m184 [m  vocab_size = b;
[93m185 [m  for (a = 0; a < vocab_hash_size; a++) vocab_hash[a] = -1;
[93m186 [m  for (a = 0; a < vocab_size; a++) {
[93m187 [m    // Hash will be re-computed, as it is not actual
[93m188 [m    hash = GetWordHash(vocab[a].word);
[93m189 [m    while (vocab_hash[hash] != -1) hash = (hash + 1) % vocab_hash_size;
[93m190 [m    vocab_hash[hash] = a;
[93m191 [m  }
[93m192 [m  fflush(stdout);
[93m193 [m  min_reduce++;
[93m194 [m}
[93m195 
196 [m// Create binary Huffman tree using the word counts /* 語数を用いて2値Huffman木を作成[28;1H[93m    [m */[14;14H[?12l[?25h[?25l[29;1H:[?12l[?25hw[?25l"word2vec.c" 703L, 34928C written[14;14H[?12l[?25h[?25l[29;1H[K[29;1H:[?12l[?25hq[?25l[29;1H[K[29;1H[?1l>[?12l[?25h[?1049lbash-3.2$ exit
exit

Script done on Wed Oct 21 20:07:00 2015
